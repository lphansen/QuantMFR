{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Finite-State Markov Chains\n",
    "\n",
    "Suppose that $\\mathcal{X}$ consists of $n$ possible states. We can label these states in a variety of ways, but for now we suppose that state $x_j$ is the coordinate vector consisting entirely of zeros except in position $j$, where there is a one. Let $\\mathbb{P}$ be an $n$ by $n$ transition matrix, where entry $i, j$ is the probability of moving from state $i$ to state $j$ in a single period. Thus, the entries of $\\mathbb{P}$ are all nonnegative and\n",
    "$$\n",
    "\\mathbb{P} \\mathbf{1}_n=\\mathbf{1}_n,\n",
    "$$\n",
    "where $\\mathbf{1}_n$ is an $n$-dimensional vector of ones.\n",
    "Let $\\mathbf{q}$ be an $n$-dimensional vector of probabilities. Stationarity requires that\n",
    "$$\n",
    "\\mathbf{q}^{\\prime} \\mathbb{P}=\\mathbf{q}^{\\prime},\n",
    "$$\n",
    "where $\\mathbf{q}$ is a row eigenvector (also called a left eigenvector) of $\\mathbb{P}$ associated with a unit eigenvalue.\n",
    "\n",
    "We use a vector $\\mathbf{f}$ to represent a function from the state space to the real line. Each coordinate of $\\mathbf{f}$ gives the value of the function at the corresponding coordinate vector. Then the conditional expectation operator $\\mathbb{T}$ can be represented in terms of the transition matrix $\\mathbb{P}$ :\n",
    "$$\n",
    "E\\left(\\mathbf{f} \\cdot X_{t+1} \\mid X_t=x\\right)=(\\mathbb{T} \\mathbf{f}) \\cdot x=x^{\\prime} \\mathbb{P} \\mathbf{f} .\n",
    "$$\n",
    "\n",
    "Now consider column eigenvectors called \"right eigenvectors\" of $\\mathbb{P}$ that are associated with a unit eigenvalue.\n",
    "\n",
    "Proposition 3.6.1. Suppose that the only solutions to\n",
    "$$\n",
    "\\mathbb{T} f=f\n",
    "$$\n",
    "are of the form $\\boldsymbol{f} \\propto \\mathbf{1}_n$, where $\\propto$ means 'proportional to'. Then we can construct a process that is stationary and ergodic by initializing the process with density $\\boldsymbol{q}$ determined by equation (3.8).\n",
    "\n",
    "We can weaken the Proposition 3.6.1 sufficient condition for stationarity and ergodicity to allow nonconstant right eigenvectors. This weakening is of interest when there are multiple stationary distributions.\n",
    "\n",
    "Proposition 3.6.2. Assume that there exists a real number $\\boldsymbol{r}$ such that the right eigenvector $\\boldsymbol{f}$ and a stationary distribution $\\boldsymbol{q}$ satisfy\n",
    "$$\n",
    "\\min _{\\mathbf{r}} \\sum_{i=1}^n\\left(\\mathbf{f}_i-\\mathbf{r}\\right)^2 \\mathbf{q}_i=0 .\n",
    "$$\n",
    "\n",
    "Then the process is stationary and ergodic.\n",
    "Notice that if $\\mathbf{q}_i$ is zero, the contribution of $\\mathbf{f}_i$ to the least squares objective can be neglected. This allows for non-constant $\\mathbf{f}^{\\prime}$ 's, albeit in a limited way.\n",
    "Three examples illustrate ideas in these propositions.\n",
    "\n",
    "Example 3.6.3. Recast Example 1.4 .3 as a Markov chain with transition matrix $\\mathbb{P}=\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]$. This chain has a unique stationary distribution $q=$ $\\left[\\begin{array}{ll}.5 & .5\\end{array}\\right]^{\\prime}$ and the invariant functions are $\\left[\\begin{array}{ll}\\mathbf{r} & \\mathbf{r}\\end{array}\\right]^{\\prime}$ for any scalar $\\mathbf{r}$. Therefore, the process initiated from the stationary distribution is ergodic. The process is periodic with period two since the matrix $\\mathbb{P}^2$ is an identity matrix and all two dimensional vectors are eigenvectors associated with a unit eigenvalue.\n",
    "\n",
    "Example 3.6.4. Recast Example 1.4.4 as a Markov chain with transition matrix $\\mathbb{P}=\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right]$. This chain has a continuum of stationary distributions $\\pi\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]+(1-\\pi)\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]$ for any $\\pi \\in[0,1]$ and invariant functions $\\left[\\begin{array}{l}\\mathbf{r}_1 \\\\ \\mathbf{r}_2\\end{array}\\right]$ for any scalars $\\mathbf{r}_1, \\mathbf{r}_2$. Therefore, when $\\pi \\in(0,1)$ the process is not ergodic because if $\\mathbf{r}_1 \\neq \\mathbf{r}_2$ the resulting invariant function fails to be constant across states that have positive probability under the stationary distribution associated with $\\pi \\in(0,1)$. When $\\pi \\in(0,1)$, nature chooses state $i=1$ or $i=2$ with probabilities $\\pi, 1-\\pi$, respectively, at time 0 . Thereafter, the chain remains stuck in the realized time 0 state. Its failure ever to visit the unrealized state prevents the sample average from converging to the population mean of an arbitrary function of the state.\n",
    "Example 3.6.5. A Markov chain with transition matrix $\\mathbb{P}=\\left[\\begin{array}{ccc}.8 & .2 & 0 \\\\ .1 & .9 & 0 \\\\ 0 & 0 & 1\\end{array}\\right]$ has a continuum of stationary distributions $\\pi\\left[\\begin{array}{ccc}\\frac{1}{3} & \\frac{2}{3} & 0\\end{array}\\right]^{\\prime}+(1-\\pi)\\left[\\begin{array}{lll}0 & 0 & 1\\end{array}\\right]^{\\prime}$ for $\\pi \\in[0,1]$ and invariant functions $\\left[\\begin{array}{lll}\\mathbf{r}_1 & \\mathbf{r}_1 & \\mathbf{r}_2\\end{array}\\right]^{\\prime}$ for any scalars $\\mathbf{r}_1, \\mathbf{r}_2$. Under any stationary distribution associated with $\\pi \\in(0,1)$, the chain is not ergodic because some invariant functions are not constant with probability one. But under stationary distributions associated with $\\pi=1$ or $\\pi=0$, the chain is ergodic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
