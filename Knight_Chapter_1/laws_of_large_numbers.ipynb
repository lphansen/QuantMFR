{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 Law of Large Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An elementary Law of Large Numbers asserts that the limit of an average over time of a sequence of independent and identically distributed random vectors equals the unconditional expectation of the random vector. We want a more general Law of Large Numbers that applies to averages over time of sequences of observations that are intertemporally dependent. To do this, we use a notion of probabilistic invariance that is expressed in terms of the measure-preserving restriction and that implies a Law of Large Numbers applicable to stochastic processes. The following theorem asserts two senses in which averages of intertemporally dependent processes converge to mathematical expectations conditioned on invariant events.\n",
    "\n",
    "Theorem 1.6.1. (Birkhoff) Suppose that $\\mathbb{S}$ is measure preserving relative to the probability space $(\\Omega, \\mathfrak{F}, \\operatorname{Pr}) \\cdot \\sqrt{6}$\n",
    "i) For any $X$ such that $E|X|<\\infty$,\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{t=1}^N X_t(\\omega) \\rightarrow E(X \\mid \\mathfrak{I})(\\omega)\n",
    "$$\n",
    "with probability one;\n",
    "ii) For any $X(\\omega)$ such that $E|X(\\omega)|^2<\\infty$,\n",
    "$$\n",
    "E\\left[\\left|\\frac{1}{N} \\sum_{t=1}^N X_t-E(X \\mid \\mathfrak{I})\\right|^2\\right] \\rightarrow 0\n",
    "$$\n",
    "\n",
    "Part (i) asserts almost-sure convergence; part (i) asserts mean-square convergence.\n",
    "\n",
    "We have ample flexibility to specify a measurement function $\\varphi\\left(X^{\\ell}\\right)$, where $\\varphi$ is a Borel measurable function from $\\mathbb{R}^{n(\\ell+1)}$ into $\\mathbb{R}$. In particular, an indicator functions for event $\\Lambda=\\left\\{X^{\\ell} \\in \\mathfrak{b}\\right\\}$ can be used as a measurement function where:\n",
    "$$\n",
    "\\mathbf{1}_{\\Lambda}(\\omega)=\\left\\{\\begin{array}{lll}\n",
    "1 & \\text { if } & \\omega \\in \\Lambda \\\\\n",
    "0 & \\text { if } \\omega \\notin \\Lambda .\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "The Law of Large Numbers applies to limits of\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{t=1}^N \\varphi\\left[X_t^{\\ell}\\right]\n",
    "$$\n",
    "for alternative $\\varphi$ 's, so choosing $\\varphi$ 's to be indicator functions shows how the Law of Large Numbers uncovers event probabilities of interest.\n",
    "\n",
    "Definition 1.6.2. A transformation $\\mathbb{S}$ that is measure-preserving relative to $\\mathrm{Pr}$ is said to be ergodic under probability measure $\\mathrm{Pr}$ if all invariant events have probability zero or one.\n",
    "\n",
    "Thus, when a transformation $\\mathbb{S}$ is ergodic under measure $\\mathrm{Pr}$, the invariant events have either the same probability measure as the entire sample space $\\Omega$ (whose probability measure is one), or the same probability measure as the empty set $\\varnothing$ (whose probability measure is zero).\n",
    "\n",
    "Proposition 1.6.3. Suppose that the measure preserving transformation $\\mathbb{S}$ is ergodic under measure $\\operatorname{Pr}$. Then $E(X \\mid \\mathfrak{I})=E(X)$.\n",
    "\n",
    "Theorem 1.6.1 describes conditions for convergence in the general case that $\\mathbb{S}$ is measure preserving under $\\operatorname{Pr}$ but in which $\\mathbb{S}$ is not necessarily ergodic under Pr. Proposition 1.6 .3 describes a situation in which probabilities assigned to invariant events are degenerate in the sense that all invariant events have the same probability as either $\\Omega$ (probability one) or the null set (probability zero). When $\\mathbb{S}$ is ergodic under measure Pr, limit points of time series averages equal corresponding unconditional expectations, an outcome we can call a standard Law of Large Numbers. When $\\mathbb{S}$ is not ergodic under $P r$, limit points of time series averages equal expectations conditioned on invariant events.\n",
    "The following examples remind us how ergodicity restricts $\\mathbb{S}$ and $\\operatorname{Pr}$.\n",
    "\n",
    "Example 1.6.4. Consider example 1.4.3 again. $\\Omega$ contains two points and $\\mathbb{S}$ maps $\\omega_1$ into $\\omega_2$ and $\\omega_2$ into $\\omega_1: \\mathbb{S}\\left(\\omega_1\\right)=\\omega_2$ and $\\mathbb{S}\\left(\\omega_2\\right)=\\omega_1$. Suppose that the measurement vector is\n",
    "$$\n",
    "X(\\omega)= \\begin{cases}1 & \\text { if } \\omega=\\omega_1 \\\\ 0 & \\text { if } \\omega=\\omega_2 .\\end{cases}\n",
    "$$\n",
    "\n",
    "Then it follows directly from the specification of $\\mathbb{S}$ that\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{t=1}^N X_t(\\omega) \\rightarrow \\frac{1}{2}\n",
    "$$\n",
    "for both values of $\\omega$. The limit point is the average across sample points.\n",
    "Example 1.6.5. Return to example 1.4.4. $\\Omega$ contains two points, $\\Omega=$ $\\left\\{\\omega_1, \\omega_2\\right\\}$ and that $\\mathbb{S}\\left(\\omega_1\\right)=\\omega_1$ and $\\mathbb{S}\\left(\\omega_2\\right)=\\omega_2 . X_t(\\omega)=X(\\omega)$ so that the sequence is time invariant and equal to its time-series average. A timeseries average of $X_t(\\omega)$ equals the average across sample points only when $\\operatorname{Pr}$ assigns probability 1 to either $\\omega_1$ or $\\omega_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
