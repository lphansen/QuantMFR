{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Stationary Stochastic Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a probabilistic notion of invariance. We call a stochastic process stationary if any finite integer $\\ell$, the joint probability distribution induced by the composite random vector $\\left[X_t^{\\prime}, X_{t+1}{ }^{\\prime}, \\ldots, X_{t+\\ell}{ }^{\\prime}\\right]^{\\prime}$ is the same for all $t \\geq 0.3$ This notion of stationarity can be thought of as a stochastic version of a steady state of a dynamical system.\n",
    "\n",
    "We now use the objects $(\\mathbb{S}, X)$ to build a stationary stochastic process by restricting construction 1.2 .3 . Consider the set $\\{\\omega \\in \\Omega: X(\\omega) \\in \\mathfrak{b}\\} \\doteq \\Lambda$ and its successors\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\left\\{\\omega \\in \\Omega: X_1(\\omega) \\in \\mathfrak{b}\\right\\}=\\{\\omega \\in \\Omega: X[\\mathbb{S}(\\omega)] \\in \\mathfrak{b}\\}=\\mathbb{S}^{-1}(\\Lambda) \\\\\n",
    "& \\left\\{\\omega \\in \\Omega: X_t(\\omega) \\in \\mathfrak{b}\\right\\}=\\left\\{\\omega \\in \\Omega: X\\left[\\mathbb{S}^t(\\omega)\\right] \\in \\mathfrak{b}\\right\\}=\\mathbb{S}^{-t}(\\Lambda) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Evidently, if $\\operatorname{Pr}(\\Lambda)=\\operatorname{Pr}\\left[\\mathbb{S}^{-1}(\\Lambda)\\right]$ for all $\\Lambda \\in \\mathfrak{F}$, then the probability distribution induced by $X_t$ equals the probability distribution of $X$ for all $t$. This fact motivates the following definition and proposition.\n",
    "\n",
    "Definition 1.4.1. The pair $(\\mathbb{S}, \\operatorname{Pr})$ is said to be measure-preserving if\n",
    "$$\n",
    "\\operatorname{Pr}(\\Lambda)=\\operatorname{Pr}\\left\\{\\mathbb{S}^{-1}(\\Lambda)\\right\\}\n",
    "$$\n",
    "for all $\\Lambda \\in \\mathfrak{F}$.\n",
    "Proposition 1.4.2. When $(\\mathbb{S}, \\operatorname{Pr})$ is measure-preserving, probability distributions induced by the random vectors $X_t$ are identical for all $t \\geq 0$.\n",
    "\n",
    "The measure preserving property restricts the probability measure $\\mathrm{Pr}$ for a given transformation $\\mathbb{S}$. Some probability measures $\\operatorname{Pr}$ used in conjunction with $\\mathbb{S}$ will be measure preserving and others not, a fact that will play an important role at several places below.\n",
    "\n",
    "Suppose that $(\\mathbb{S}, \\operatorname{Pr})$ is measure preserving relative to probability measure $\\operatorname{Pr}$. Given $X$ and an integer $\\ell>1$, form a vector\n",
    "$$\n",
    "X^{[\\ell]}(\\omega) \\doteq\\left[\\begin{array}{c}\n",
    "X_0(\\omega) \\\\\n",
    "X_1(\\omega) \\\\\n",
    "\\ldots \\\\\n",
    "X_{\\ell}(\\omega)\n",
    "\\end{array}\\right] .\n",
    "$$\n",
    "\n",
    "We can apply Proposition 1.4.2 to $X^{[\\ell]}$ to conclude that the joint distribution function of $\\left(X_t, X_{t+1}, \\ldots, X_{t+\\ell}\\right)$ is independent of $t$ for $t=0,1, \\ldots$ That this property holds for any choice of $\\ell$ implying that the stochastic process $\\left\\{X_t: t=1,2, \\ldots\\right\\}$ is stationary. Moreover, $f\\left(X^{\\ell}\\right)$ where $f$ is a Borel measurable function from $\\mathbb{R}^{n(\\ell+1)}$ into $\\mathbb{R}$ is also a valid measurement function. Such $f$ 's include indicator functions of interesting events defined in terms of $X^{\\ell}$.\n",
    "\n",
    "For a given $\\mathbb{S}$, we now present examples that illustrate how to construct a probability measure $\\operatorname{Pr}$ that makes $\\mathbb{S}$ measure preserving and thereby brings stationarity. In example 1.4.3, only one $\\operatorname{Pr}$ makes $\\mathbb{S}$ measure preserving, while in example 1.4 .4 there are many.\n",
    "\n",
    "Example 1.4.3. Suppose that $\\Omega$ contains two points, $\\Omega=\\left\\{\\omega_1, \\omega_2\\right\\}$. Consider a transformation $\\mathbb{S}$ that maps $\\omega_1$ into $\\omega_2$ and $\\omega_2$ into $\\omega_1: \\mathbb{S}\\left(\\omega_1\\right)=\\omega_2$ and $\\mathbb{S}\\left(\\omega_2\\right)=\\omega_1$. Since $\\mathbb{S}^{-1}\\left(\\left\\{\\omega_2\\right\\}\\right)=\\left\\{\\omega_1\\right\\}$ and $\\mathbb{S}^{-1}\\left(\\left\\{\\omega_1\\right\\}\\right)=\\left\\{\\omega_2\\right\\}$, for $\\mathbb{S}$ to be measure preserving, we must have $\\operatorname{Pr}\\left(\\left\\{\\omega_1\\right\\}\\right)=\\operatorname{Pr}\\left(\\left\\{\\omega_2\\right\\}\\right)=1 / 2$.\n",
    "\n",
    "Example 1.4.4. Suppose that $\\Omega$ contains two points, $\\Omega=\\left\\{\\omega_1, \\omega_2\\right\\}$ and that $\\mathbb{S}\\left(\\omega_1\\right)=\\omega_1$ and $\\mathbb{S}\\left(\\omega_2\\right)=\\omega_2$. Since $\\mathbb{S}^{-1}\\left(\\left\\{\\omega_2\\right\\}\\right)=\\left\\{\\omega_2\\right\\}$ and $\\mathbb{S}^{-1}\\left(\\left\\{\\omega_1\\right\\}\\right)=$ $\\left\\{\\omega_1\\right\\}$, $\\mathbb{S}$ is measure preserving for any $\\operatorname{Pr}$ that satisfies $\\operatorname{Pr}\\left(\\left\\{\\omega_1\\right\\}\\right) \\geqslant 0$ and $\\operatorname{Pr}\\left(\\left\\{\\omega_2\\right\\}\\right)=1-\\operatorname{Pr}\\left(\\left\\{\\omega_1\\right\\}\\right)$.\n",
    "\n",
    "The next example illustrates how to represent an i.i.d. sequence of zeros and ones in terms of an $\\Omega, \\operatorname{Pr}$ and an $\\mathbb{S}$.\n",
    "\n",
    "Example 1.4.5. Suppose that $\\Omega=[0,1)$ and that $P r$ is the uniform measure on $[0,1)$. Let\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{S}(\\omega) & =\\left\\{\\begin{array}{cc}\n",
    "2 \\omega & \\text { if } \\omega \\in[0,1 / 2) \\\\\n",
    "2 \\omega-1 & \\text { if } \\omega \\in[1 / 2,1),\n",
    "\\end{array}\\right. \\\\\n",
    "X(\\omega) & = \\begin{cases}1 & \\text { if } \\omega \\in[0,1 / 2) \\\\\n",
    "0 & \\text { if } \\omega \\in[1 / 2,1) .\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Calculate $\\operatorname{Pr}\\left\\{X_1=1 \\mid X_0=1\\right\\}=\\operatorname{Pr}\\left\\{X_1=1 \\mid X_0=0\\right\\}=\\operatorname{Pr}\\left\\{X_1=1\\right\\}=$ $1 / 2$ and $\\operatorname{Pr}\\left\\{X_1=0 \\mid X_0=1\\right\\}=\\operatorname{Pr}\\left\\{X_1=0 \\mid X_0=0\\right\\}=\\operatorname{Pr}\\left\\{X_1=0\\right\\}=$ 1/2. So $X_1$ is statistically independent of $X_0$. By extending these calculations, it can be verified that $\\left\\{X_t: t=0,1, \\ldots\\right\\}$ is a sequence of independent random variables. 1 We can alter $\\operatorname{Pr}$ to obtain other stationary distributions. For instance, suppose that $\\operatorname{Pr}\\left\\{\\frac{1}{3}\\right\\}=\\operatorname{Pr}\\left\\{\\frac{2}{3}\\right\\}=.5$. Then the process $\\left\\{X_t: t=0,1, \\ldots\\right\\}$ alternates in a deterministic fashion between zero and one. This provides a version of Example 1.4.3 in which $\\omega_1=\\frac{1}{3}$ and $\\omega_2=\\frac{2}{3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
