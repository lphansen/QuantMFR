
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7. Risk, Ambiguity, and Misspecification: Decision Theory, Robust Control, and Statistics &#8212; Quant Macro Finance</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=82c7aad8" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'decision_theory/Decision';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Shock Elasticities: Continuous Time" href="../continuous_global_solution/shockelasticitycontinuous.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/mfr.png" class="logo__image only-light" alt="Quant Macro Finance - Home"/>
    <script>document.write(`<img src="../_static/mfr.png" class="logo__image only-dark" alt="Quant Macro Finance - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Risk, Uncertainty, and Value</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../book/example_out_c1_v2.html">1. Stochastic Processes and Laws of Large Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../book/example_out_c2_v2.html">2. Markov Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../book/example_out_c3_v2.html">3. Stationary Increments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../book/example_out_c4_v2.html">4. Processes with Markovian increments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../book/example_out_c5_v2.html">5. Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../book/example_out_c6_v2.html">6. Likelihoods</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Uncertainty Expansion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../theory/uncertainexpansion_update.html">Uncertain Expansion Theory</a></li>





<li class="toctree-l1"><a class="reference internal" href="../theory/quickguide_update.html">Numerical Solution: Expansion Suite</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Shock Elasticity</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../continuous_global_solution/shockelasticity.html">Shock Elasticity: Discrete Time</a></li>




<li class="toctree-l1"><a class="reference internal" href="../continuous_global_solution/shockelasticitycontinuous.html">Shock Elasticities: Continuous Time</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Decision Theory</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. Risk, Ambiguity, and Misspecification: Decision Theory, Robust Control, and Statistics</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/decision_theory/Decision.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Risk, Ambiguity, and Misspecification: Decision Theory, Robust Control, and Statistics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7. Risk, Ambiguity, and Misspecification: Decision Theory, Robust Control, and Statistics</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">7.1. Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">7.2. Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preliminaries">7.3. Preliminaries</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preferences">7.3.1. Preferences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#objective-probability">7.3.2. Objective probability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subjective-probability">7.3.3. Subjective probability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#max-min-expected-utility">7.3.4. Max-min Expected Utility</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-preferences">7.4. Variational preferences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scaled-statistical-divergences-as-c-functions">7.5. Scaled statistical divergences as <span class="math notranslate nohighlight">\(c\)</span> functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-formulation">7.6. Basic formulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-prior">7.6.1. Not knowing a prior</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-prior-i">7.6.1.1. Not knowing a prior, I</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-prior-ii">7.6.2. Not knowing a prior, II</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-likelihood">7.7. Not knowing a likelihood</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-misspecified-model">7.7.1. A misspecified model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-misspecified-likelihood-function">7.8. A misspecified likelihood function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robustness-reconsidered">7.9. Robustness reconsidered</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-examples">7.10. Two examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-preferences">7.10.1. Robust preferences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-forecasting">7.10.2. Robust forecasting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hybrid-models">7.11. Hybrid models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#first-hybrid-model">7.11.1. First hybrid model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#second-hybrid-model">7.12. Second hybrid model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-extension">7.13. Dynamic extension</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-deterministic-warm-up">7.13.1. A deterministic warm up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introducing-uncertainty">7.13.2. Introducing uncertainty</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shadow-valuation">7.13.3. Shadow valuation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-approach-to-uncertainty-quantification">7.14. An approach to uncertainty quantification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relation-to-statistical-learning">7.15. Relation to statistical learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concluding-remarks">7.16. Concluding remarks</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">8. Appendix</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convexity-of-composite-divergence">8.1. Convexity of composite divergence</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="risk-ambiguity-and-misspecification-decision-theory-robust-control-and-statistics">
<h1><span class="section-number">7. </span>Risk, Ambiguity, and Misspecification: Decision Theory, Robust Control, and Statistics<a class="headerlink" href="#risk-ambiguity-and-misspecification-decision-theory-robust-control-and-statistics" title="Link to this heading">#</a></h1>
<p><em>Authors: Lars Peter Hansen<a class="footnote-reference brackets" href="#lhansen" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> and Thomas J. Sargent<a class="footnote-reference brackets" href="#tsargent" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></em></p>
<hr class="docutils" />
<section id="abstract">
<h2><span class="section-number">7.1. </span>Abstract<a class="headerlink" href="#abstract" title="Link to this heading">#</a></h2>
<p>What are “deep uncertainties” and how should their presence influence prudent decisions? To address these questions, we bring ideas from robust control theory into statistical decision theory. Decision theory has its origins in axiomatic formulations by von Neumann and Morgenstern, Wald, and Savage. After Savage, decision theorists constructed axioms that formalize a notion of ambiguity aversion. Meanwhile, control theorists constructed decision rules that are robust to some model misspecifications. We reinterpret axiomatic foundations of decision theories to express ambiguity about a prior over a family of models along with concerns about misspecifications of the corresponding likelihood functions.</p>
<p><em>Keywords: deep uncertainty, ambiguity, misspecification, variational preferences, statistical divergence, relative entropy</em></p>
<p><em>JEL Codes: C10, C14, C18</em></p>
<hr class="docutils" />
</section>
<section id="introduction">
<span id="sec-intro"></span><h2><span class="section-number">7.2. </span>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>Climate scientists confront “deep uncertainties.”<a class="footnote-reference brackets" href="#deepuncertainties" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> Practicing econometricians also often struggle with uncertainty about their statistical models, but usually with scant guidance from significant advances in decision theory made after <span id="id4">[<a class="reference internal" href="../book/cite.html#id295" title="Abraham Wald. An essentially complete class of admissible decision functions. The Annals of Mathematical Statistics, pages 549–555, 1947.">Wald, 1947</a>, <a class="reference internal" href="../book/cite.html#id294" title="Abraham Wald. Statistical decision functions. The Annals of Mathematical Statistics, pages 165–205, 1949.">Wald, 1949</a>, <a class="reference internal" href="../book/cite.html#id293" title="Abraham Wald. Statistical Decision Functions. John Wiley and Sons, Inc, New York, 1950.">Wald, 1950</a>]</span>, <span id="id5">[]</span>, and <span id="id6">[<a class="reference internal" href="../book/cite.html#id290" title="Daniel Ellsberg. Risk, ambiguity, and the savage axioms. The Quarterly Journal of Economics, pages 643–669, 1961.">Ellsberg, 1961</a>]</span> because so much recent formal theory of decision making under uncertainty in economics is not cast explicitly in terms of the likelihoods and priors that are the foundations of statistics and econometrics.<a class="footnote-reference brackets" href="#econometricians" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> Likelihoods are probability distributions conditioned on parameters while priors describe a decision maker’s subjective belief about parameters.<a class="footnote-reference brackets" href="#likelihoodspriors" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a> By distinguishing roles played by likelihood functions and subjective priors over parameters, this paper aims to bring contributions to decision theory after Wald and Savage into closer contact with statistics and econometrics in ways that can address practical econometric concerns about model misspecifications and selections of prior probabilities.</p>
<p>Although they proceeded differently than we do, <span id="id9">[]</span>, <span id="id10">[]</span>, and <span id="id11">[]</span> studied related issues. <span id="id12">[]</span> emphasized that likelihoods and priors are both vulnerable to uncertainties. His ultimate focus was on uncertainty about predictive distributions that are constructed by integrating likelihoods with respect to priors. Our paper instead formulates a decision theory with distinct uncertainties about priors and likelihoods. <span id="id13">[]</span> (section 4.2) provide a rationalization of the smooth ambiguity preferences proposed by <span id="id14">[]</span> that includes likelihoods and priors as components. <span id="id15">[]</span> extend this approach by using an axiomatic revealed preference approach to deduce an implied parameterization of a likelihood function. But neither of those papers sharply distinguishes prior uncertainty from concerns about possible model misspecifications, something that we want to do. We formulate concerns about model misspecifications as uncertainty about likelihoods.</p>
<p>We assemble concepts and practical ways of modeling risks and concerns about model misspecifications from statistics, robust control theory, economics, and decision theory. We align definitions of statistical models, uncertainty, and ambiguity with ideas from decision theories that build on <span id="id16">[]</span>’s way of representing subjective and objective uncertainties. We connect our analysis to econometrics and robust control theory by using <span id="id17">[]</span> states as parameters that index alternative statistical models of random variables that affect outcomes that a decision maker cares about. By modifying <span id="id18">[]</span>, <span id="id19">[]</span>, and <span id="id20">[]</span>, we show how to use variational preferences to represent uncertainty about priors and concerns about statistical model misspecifications.</p>
<p>Some “behavioral” models in economics and finance assume expected utility preferences in which an agent’s subjective probability differs systematically from probabilities that govern the data.<a class="footnote-reference brackets" href="#behavioral" id="id21" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a> This literature also contains discussions of differences among agents in their confidence in their view of the world. Lack of confidence can take different forms under different notions of uncertainty. Preference structures that we describe in this paper allow us to formalize different degrees of “confidence” both about details of specifications of particular statistical models and about subjective probabilities to attach to alternative statistical models. Our representations of preferences provide ways to characterize degrees of confidence in terms of perceived statistical plausibilities.<a class="footnote-reference brackets" href="#confidence" id="id22" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a></p>
<p><strong>Objects and Interpretations</strong></p>
<p>Our decision maker knows a parameterized family of probability distributions <span class="math notranslate nohighlight">\(\tau(w | \theta)d\upsilon(w),\)</span> where <span class="math notranslate nohighlight">\(w \in W\)</span> is a realization of a random vector or “repercussion” that he cares about, <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span> is a vector of parameters, and <span class="math notranslate nohighlight">\(d\upsilon(w)\)</span> is a measure over <span class="math notranslate nohighlight">\(W.\)</span> A realization of <span class="math notranslate nohighlight">\(w\)</span> can play two possible roles. It can represent an outcome over which the decision maker has preferences, and it can capture data available to help the decision maker shape decisions. The decision maker has preferences over a set of prize rules, each of which we represent as a function <span class="math notranslate nohighlight">\(\gamma: W \times \Theta \rightarrow X\)</span>, where <span class="math notranslate nohighlight">\(x \in X\)</span> is a “prize” that he cares about. In our featured examples, for parameter vector <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>, the prize rule <span class="math notranslate nohighlight">\(\gamma(w | \theta)\)</span> determines the decision maker’s exposure to an uncertain random vector that has a realization expressible in terms of <span class="math notranslate nohighlight">\(w \in W\)</span> A set of <span class="math notranslate nohighlight">\(\gamma\)</span>’s describes prize rules under consideration. In forecasting problems of a type common in time series statistics and econometrics, the prize can depend directly on the error in forecasting a component of <span class="math notranslate nohighlight">\(w\)</span> and the forecast rule depends on another component of <span class="math notranslate nohighlight">\(w.\)</span> While forecasting problems are interesting in their own right, in many applications, forecasts are intermediate inputs into outcomes of ultimate interest to the decision maker. Examples that appear in <a class="reference internal" href="#sec-prelim"><span class="std std-ref">Preliminaries</span></a> illustrate a range of applications.</p>
<div class="proof remark admonition" id="rmk:robuststat">
<p class="admonition-title"><span class="caption-number">Remark 7.1 </span></p>
<section class="remark-content" id="proof-content">
<p>We use three components from decision theory, namely, i) states, ii) acts, and iii) prizes, in some new ways. We follow <span id="id23">[]</span> by defining consequences as lotteries over prizes. An act maps states into consequences. Preferences are defined over acts. In the static setup of this paper, we take the state to be parameters of a statistical model. That distinguishes our formulation from many other applications of <span id="id24">[]</span>. For example, decision theorists who connect their work to revealed preference theory typically want states that are “verifiable”. We are instead interested in a typical econometric situation in which parameters of statistical models remain hidden forever. For us, parameter uncertainty is central, so it is important that parameter vector <span class="math notranslate nohighlight">\(theta\)</span> be included as a component of the state.<a class="footnote-reference brackets" href="#paramimportance" id="id25" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a></p>
<p><span id="id26">[]</span> and <span id="id27">[]</span> introduced parameterized models as a family of primitive probabilities that a decision maker cares about. <span id="id28">[]</span> in effect consider an expanded state space <span class="math notranslate nohighlight">\((w, theta)\)</span> that includes both repercussions with realization <span class="math notranslate nohighlight">\(w\)</span> and parameters <span class="math notranslate nohighlight">\(theta\)</span> and then take a <em>model</em> to be a conditional distribution over <span class="math notranslate nohighlight">\((W, {\mathfrak W})\)</span> given <span class="math notranslate nohighlight">\(theta\)</span>.<a class="footnote-reference brackets" href="#dynkinspace" id="id29" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a> Consistent with the framework of <span id="id30">[]</span>, <span id="id31">[]</span> showed that a family of models induces a partial ordering according to which an act is preferred to another act if it is preferred under all models in the family.</p>
<p>Relative to <span id="id32">[]</span> and many other applications of the <span id="id33">[]</span> framework, we use lotteries in a more essential way. <span id="id34">[]</span> interpret lotteries as “roulette wheels” with known (objective) probabilities, in contrast to “horse races” with unknown (subjective) probabilities. Many authors used an <span id="id35">[]</span> setup as a vehicle to extend <span id="id36">[]</span> preferences defined over lotteries to more general settings that can include subjective uncertainty. In our formulation, the random vector <span class="math notranslate nohighlight">\(W\)</span> induces a probability distribution that according to a particular <span id="id37">[]</span> act implies a particular lottery that can depend on parameters of a statistical model. We represent a family of models as a family of probability distributions indexed by an unknown parameter vector. Parameter vectors can reside in a finite set, a manifold of possible values, or even an infinite dimensional set. With correct statistical models (i.e., likelihoods), each model induces a “roulette wheel” lottery. The possibility of misspecified likelihoods leads us to want a counterpart to an Anscombe-Aumann lottery with unknown probabilities. Our extension of the <span id="id38">[]</span> framework lets us distinguish robustness to misspecification of each member of a collection of substantively motivated “structured” statistical models from robustness to the choice of a prior distribution to put over those statistical models. We formulate preferences that express distinct concerns about both types of robustness.</p>
<p>To motivate their axioms, <span id="id39">[]</span> and <span id="id40">[]</span> used <span id="id41">[]</span>’s stochastic formulation of a robust control problem. We use our <span id="id42">[]</span> formulation to show that the axioms of <span id="id43">[]</span> and <span id="id44">[]</span> actually express prior uncertainty and not the model misspecification concerns that had originally motivated <span id="id45">[]</span>. We go on to show how, by using an appropriate ambiguity index or “cost” function, we can use the variational preferences of <span id="id46">[]</span> to express concerns about robustness both to statistical model misspecification and to prior selection, including priors meant to represent “nonparametric Bayesian” methods.</p>
</section>
</div></section>
<section id="preliminaries">
<span id="sec-prelim"></span><h2><span class="section-number">7.3. </span>Preliminaries<a class="headerlink" href="#preliminaries" title="Link to this heading">#</a></h2>
<p>Following <span id="id47">[]</span> and <span id="id48">[]</span>, we adopt a version of the framework of
<span id="id49">[]</span> described by <span id="id50">[]</span>: <span class="math notranslate nohighlight">\((\Theta, {\mathfrak G})\)</span> is a measurable space of potential <em>states</em>, <span class="math notranslate nohighlight">\((X, {\mathfrak X})\)</span> is a measurable space of potential <em>prizes</em>, <span class="math notranslate nohighlight">\(\Pi\)</span>
is a set of probability measures over states, and <span class="math notranslate nohighlight">\(\Lambda\)</span> is a set of probability measures over prizes.<a class="footnote-reference brackets" href="#anscombeaumann" id="id51" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a> For each
<span class="math notranslate nohighlight">\(\pi \in \Pi\)</span>, <span class="math notranslate nohighlight">\((\Theta, {\mathfrak G}, \pi )\)</span> is a probability space and for each <span class="math notranslate nohighlight">\(\lambda \in \Lambda\)</span>, <span class="math notranslate nohighlight">\((X, {\mathfrak X}, \lambda)\)</span> is a probability space. Let <span class="math notranslate nohighlight">\({\mathcal X}\)</span> denote an event in <span class="math notranslate nohighlight">\({\mathfrak X}\)</span> and <span class="math notranslate nohighlight">\({\mathcal G}\)</span> denote an event in <span class="math notranslate nohighlight">\({\mathfrak G}\)</span>.</p>
<div class="proof definition admonition" id="definition-1">
<p class="admonition-title"><span class="caption-number">Definition 7.1 </span></p>
<section class="definition-content" id="proof-content">
<p>An <strong>act</strong> is a <span class="math notranslate nohighlight">\({{\mathfrak G}}\)</span> measurable function <span class="math notranslate nohighlight">\(f : \Theta \rightarrow \Lambda\)</span>.</p>
</section>
</div><p>For a given <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(df(x | \theta)\)</span> denotes integration with respect to the probability measure <span class="math notranslate nohighlight">\(f(\theta) \in \Lambda,\)</span> which is a lottery over possible prizes <span class="math notranslate nohighlight">\(x \in X\)</span>.<a class="footnote-reference brackets" href="#basicsetup" id="id52" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a> For a <strong>given</strong> probability measure <span class="math notranslate nohighlight">\(\pi \in \Pi\)</span>, <span class="math notranslate nohighlight">\(\int_\Theta df(x | \theta) d\pi(\theta)\)</span> is a two-stage lottery over prizes, with a lottery over states <span class="math notranslate nohighlight">\(\theta\)</span> being described by <span class="math notranslate nohighlight">\(\pi\)</span> and another lottery over prizes <span class="math notranslate nohighlight">\(x \in X\)</span> being described by <span class="math notranslate nohighlight">\(df(x | \theta)\)</span>, which depends on the outcome <span class="math notranslate nohighlight">\(\theta\)</span> from the other lottery. We shall introduce uncertainty about the probability measure <span class="math notranslate nohighlight">\(\pi.\)</span></p>
<p>As mentioned in <a class="reference internal" href="#sec-intro"><span class="std std-ref">section</span></a>, we interpret objects in the <span id="id53">[]</span> formulation in ways that help us as statisticians/econometricians. We interpret a state <span class="math notranslate nohighlight">\(\theta\)</span> as pinning down one among a set <span class="math notranslate nohighlight">\(\Theta\)</span> of probability models that a decision maker regards as possible. A decision maker makes a decision (i.e., “chooses an <span id="id54">[]</span> act”) that generates a probability distribution over outcomes that he/she cares about, i.e., over <span id="id55">[]</span> prizes <span class="math notranslate nohighlight">\(x \in X\)</span>.</p>
<p>We use <span id="id56">[]</span> acts to represent alternative conditional distributions of repercussions and prize rules. An action or decision <span class="math notranslate nohighlight">\(\delta \in \Delta\)</span>, which is distinct from an <span id="id57">[]</span> act, can be a vector of real numbers or, more generally, a function that is defined on appropriate spaces. A choice of <span class="math notranslate nohighlight">\(\delta\)</span> can influence the distribution of repercussions conditioned on the parameter vector. It can also alter the exposure of the prize to repercussions. We represent a decision maker’s exposure to repercussions with prize rules <span class="math notranslate nohighlight">\(\gamma_\delta\)</span> that are Borel measurable functions that map <span class="math notranslate nohighlight">\(W\)</span> into prizes in <span class="math notranslate nohighlight">\(X\)</span>. We represent the influence of <span class="math notranslate nohighlight">\(\delta\)</span> on the distribution of repercussions by a conditional probability measure represented as a density <span class="math notranslate nohighlight">\(\tau_\delta( \cdot | \theta)\)</span> with respect to a Borel measure <span class="math notranslate nohighlight">\(\upsilon\)</span> on <span class="math notranslate nohighlight">\((W, {\mathcal W}).\)</span> A <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span> implies a probability measure</p>
<div class="math notranslate nohighlight">
\[\tau_\delta(w | \theta) d\upsilon(w).\]</div>
<p>This formulation is convenient for applied statisticians because for each <span class="math notranslate nohighlight">\(\delta,\)</span> a parameterized family <span class="math notranslate nohighlight">\(\tau_\delta( \cdot | \theta)\)</span> can define a manifold of likelihoods indexed by a vector of unknown parameters <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>. For a given decision <span class="math notranslate nohighlight">\(\delta\)</span>, <span class="math notranslate nohighlight">\((\gamma_\delta, \tau_\delta)\)</span><br />
induces a lottery over <span class="math notranslate nohighlight">\(X\)</span> conditioned on <span class="math notranslate nohighlight">\(\theta,\)</span> and hence an <span id="id58">[]</span> act that can be represented with <span class="math notranslate nohighlight">\(df(x | \theta).\)</span> As we vary decisions <span class="math notranslate nohighlight">\(\delta \in \Delta\)</span>, we trace out a collection of such acts. A particular decision problem defines both conditional distributions <span class="math notranslate nohighlight">\(\tau_\delta d\upsilon\)</span> and prize rules <span class="math notranslate nohighlight">\(\gamma_\delta\)</span> for alternative decisions <span class="math notranslate nohighlight">\(\delta\)</span>. Together, they delineate a collection of <span id="id59">[]</span> acts.</p>
<div class="proof remark admonition" id="remark-2">
<p class="admonition-title"><span class="caption-number">Remark 7.2 </span></p>
<section class="remark-content" id="proof-content">
<p>We can expand the collection of acts by randomizing decisions. Given two decisions <span class="math notranslate nohighlight">\(\delta_1\)</span> and <span class="math notranslate nohighlight">\(\delta_2,\)</span> a randomized rule chooses decision <span class="math notranslate nohighlight">\(\delta_1\)</span> with probability <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\delta_2\)</span> with probability <span class="math notranslate nohighlight">\(1 - \alpha.\)</span> Since each decision induces an <span id="id60">[]</span> act, the randomized decision is a convex combination of the two induced acts.<a class="footnote-reference brackets" href="#randomization" id="id61" role="doc-noteref"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></a></p>
</section>
</div><p>We consider several canonical examples.</p>
<div class="proof example admonition" id="remark:motivation">
<p class="admonition-title"><span class="caption-number">Example 7.1 </span></p>
<section class="example-content" id="proof-content">
<p>For some situations, it suffices to let <span class="math notranslate nohighlight">\(Delta\)</span> be a Borel set of a finite-dimensional Euclidean space and for the conditional distribution <span class="math notranslate nohighlight">\(tau\)</span> not to depend on <span class="math notranslate nohighlight">\(delta\)</span>. For example,
<span class="math notranslate nohighlight">\(delta\)</span> could be a particular portfolio of assets whose random return is exposed to a repercussion vector in a particular way. A choice of a portfolio does not affect the joint distribution of returns on individual assets, but it does influence the return on a portfolio of those component assets.</p>
</section>
</div><div class="proof example admonition" id="example:motivation2">
<p class="admonition-title"><span class="caption-number">Example 7.2 </span></p>
<section class="example-content" id="proof-content">
<p>In stochastic optimal control problems like those studied by <span id="id62">[]</span>, a decision maker chooses a “control” that affects the distribution of a repercussion, which in this example takes the form of a next-period state vector. For instance, in linear-quadratic Gaussian optimal control problems, often referred to as “linear regulator” problems, this effect shows up in a mean conditioned on a current state. For example, a repercussion vector <span class="math notranslate nohighlight">\(w\)</span> obeys:</p>
<div class="math notranslate nohighlight">
\[w = {\mathbb A} + {\mathbb B} \delta + {\mathbb C} \epsilon,\]</div>
<p>where the probability distribution over <span class="math notranslate nohighlight">\(\epsilon\)</span>’s is a standard, multivariate normal. The vector <span class="math notranslate nohighlight">\({\mathbb A}\)</span> and the matrices <span class="math notranslate nohighlight">\({\mathbb B}\)</span> and <span class="math notranslate nohighlight">\({\mathbb C}\)</span> depend on parameters in <span class="math notranslate nohighlight">\(\Theta\)</span>.^<a class="footnote-reference brackets" href="#current-state" id="id63" role="doc-noteref"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></a> Suppose that a controller who chooses <span class="math notranslate nohighlight">\(\delta\)</span> knows parameters only up to an uncertain subjective distribution.^<a class="footnote-reference brackets" href="#subjective-distribution" id="id64" role="doc-noteref"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></a> Think of decision <span class="math notranslate nohighlight">\(\delta\)</span> as a current period control vector in the sense of <span id="id65">[]</span>. The conditional distribution <span class="math notranslate nohighlight">\(\tau\)</span> depends on <span class="math notranslate nohighlight">\(\delta\)</span>: <span class="math notranslate nohighlight">\(w\)</span> is distributed as multivariate normal with conditional mean <span class="math notranslate nohighlight">\({\mathbb A} + {\mathbb B} \delta \)</span> and conditional variance <span class="math notranslate nohighlight">\({\mathbb C} {\mathbb C}^\top.\)</span> In typical optimal linear regulator control theory problems, prize rules depend on the vector <span class="math notranslate nohighlight">\((w^\top, \delta^\top)\)</span> with a utility function that is the negative of the quadratic form in this vector, for example,  <span class="math notranslate nohighlight">\(- w^\top {\mathbb R} w - \delta^\top {\mathbb Q} \delta\)</span> where <span class="math notranslate nohighlight">\(R\)</span> and <span class="math notranslate nohighlight">\(Q\)</span> are positive semidefinite matrices. The linear regular problem is an example of a much larger class of stochastic control problems. For simplicity, we formulate it as a static problem.^<a class="footnote-reference brackets" href="#recursive-formulation" id="id66" role="doc-noteref"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></a> The <a class="reference internal" href="#remark:motivation">Example 7.1</a> portfolio choice problem is a special case of this stochastic control problem in which repercussions are the returns and a control vector of portfolio weights does not influence repercussions.</p>
</section>
</div><div class="proof example admonition" id="remark:Ferguson">
<p class="admonition-title"><span class="caption-number">Example 7.3 </span></p>
<section class="example-content" id="proof-content">
<p>To build bridges to mathematical statistics, we extend a setup that <span id="id67">[]</span> used to analyze learning from data. We again posit a family of densities <span class="math notranslate nohighlight">\(tau(w | \theta)\)</span> for a repercussion vector whose realizations are denoted by <span class="math notranslate nohighlight">\(w\)</span>’s, and where a parameter vector <span class="math notranslate nohighlight">\(\theta\)</span> is a “true state of nature”. In this example, the decision <span class="math notranslate nohighlight">\(\delta\)</span> does not affect <span class="math notranslate nohighlight">\(\tau\)</span>. We can represent the outcome of what <span id="id68">[]</span> calls a statistical experiment as a realization of a random vector <span class="math notranslate nohighlight">\(y = \zeta(w)\)</span> that contains information about <span class="math notranslate nohighlight">\(w\)</span>. This information can be a signal that is correlated with the “prize” of ultimate interest. Let a decision <span class="math notranslate nohighlight">\(\delta\)</span> be a measurable function that maps observations <span class="math notranslate nohighlight">\(y\)</span> from the statistical experiment into a set of what <span id="id69">[]</span> calls <em>actions</em>.^<a class="footnote-reference brackets" href="#footnote-decision-rule" id="id70" role="doc-noteref"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></a> In this way <span id="id71">[]</span> allows what he calls an “action” – our decision <span class="math notranslate nohighlight">\(\delta\)</span> – to depend on an observation <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>We constrain a prize rule <span class="math notranslate nohighlight">\(\gamma_\delta\)</span> to satisfy:^<a class="footnote-reference brackets" href="#footnote-prize-rule" id="id72" role="doc-noteref"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight" id="equation-prize-rule">
<span class="eqno">(7.1)<a class="headerlink" href="#equation-prize-rule" title="Link to this equation">#</a></span>\[\gamma_\delta (w ) = \Psi[ \delta \circ \zeta (w), w ] .\]</div>
<p><span id="id73">[]</span>’s actions are not <span id="id74">[]</span> <em>acts</em>. To capture <span id="id75">[]</span>’s setup, each prize rule <span class="math notranslate nohighlight">\(\gamma_\delta\)</span> implies a probability distribution for a prize conditioned on <span class="math notranslate nohighlight">\(\theta\)</span> that is induced by <span class="math notranslate nohighlight">\(\tau(w | \theta) d\upsilon(w).\)</span> This probability distribution for a prize conditioned on <span class="math notranslate nohighlight">\(\theta\)</span> is an <span id="id76">[]</span> act.</p>
<p>By allowing decisions to depend on data that is observed at an intermediate date, the <span id="id77">[]</span> formulation allows a richer collection of possible decisions and nests our Remark <a class="reference internal" href="#remark:motivation">Example 7.1</a> formulation as a special case. It can include problems that seek to construct robustly optimal forecasts from historical data. More generally, we are interested in decision problems for which forecasting is an input but not the ultimate goal.</p>
</section>
</div><p>Although the problem posed in Example <a class="reference internal" href="#remark:Ferguson">Example 7.3</a> is static, it can be reinterpreted as a three-stage or three-period decision problem. A decision rule that is chosen at an initial period zero depends on information about the repercussion that will be revealed in a first stage. The decision maker can condition on this information when choosing his exposure to the repercussion with realization <span class="math notranslate nohighlight">\(w\)</span>. The repercussion itself is fully realized at the end of stage two. In this formulation, potential likelihood misspecifications affect the decision maker’s inferences about the prize distribution in stage one. As posed, this is an <em>ex-ante</em> decision problem in which a decision rule, <span class="math notranslate nohighlight">\(\delta\)</span>, is chosen at period <span class="math notranslate nohighlight">\(0\)</span>. In contrast, we can view Examples <a class="reference internal" href="#remark:motivation">Example 7.1</a> and <a class="reference internal" href="#example:motivation2">Example 7.2</a> as <em>ex post</em> problems in which the “prior” implicitly conditions on current and past data as does the “decision”. As often happens, the timing protocol matters. When a decision maker chooses sequentially, the distinction between priors and posteriors can become obscured when an end of period <span class="math notranslate nohighlight">\(j-1\)</span> posterior becomes a period <span class="math notranslate nohighlight">\(j\)</span> prior. In a recursive formulation of a dynamic decision problem, concerns about robustness of priors-posteriors can recur in stage-specific components within a multi-stage interpretation of a decision problem. By design, our general formulation invites dynamic extensions.</p>
<div class="proof example admonition" id="ex:estimation">
<p class="admonition-title"><span class="caption-number">Example 7.4 </span></p>
<section class="example-content" id="proof-content">
<p>It is common in econometrics and statistics to pose a decision problem as a parameter estimation problem that supposes that prizes are deviations between an estimator <span class="math notranslate nohighlight">\(\delta(y)\)</span> and a function <span class="math notranslate nohighlight">\(\chi(\theta)\)</span> of the parameter vector. To capture this, we can let</p>
<div class="math notranslate nohighlight">
\[\begin{split}w = \begin{bmatrix} \chi(\theta) \\ y \end{bmatrix}\end{split}\]</div>
<p>and add a degenerate equation to the <span class="math notranslate nohighlight">\(\tau\)</span> dynamics that describes how we construct the first component of <span class="math notranslate nohighlight">\(w\)</span>. This approach seems to be shorthand for something deeper. Typically, decisions of interest can be expressed in terms of outcomes with probability distributions that depend on the unknown parameter as in the other examples that we mention.</p>
</section>
</div><p>In what follows, a decision maker’s <em>prior</em> over possible statistical models indexed by <span class="math notranslate nohighlight">\(\theta\)</span> is a probability measure <span class="math notranslate nohighlight">\(\pi \in \Pi\)</span>.</p>
<div class="proof remark admonition" id="remark-7">
<p class="admonition-title"><span class="caption-number">Remark 7.3 </span></p>
<section class="remark-content" id="proof-content">
<p>The collection of <span id="id78">[]</span> acts is typically much larger than the set of acts that can be induced by an available pair, <span class="math notranslate nohighlight">\((\gamma_\delta, \tau_\delta)\)</span> for <span class="math notranslate nohighlight">\(\delta \in \Delta\)</span> as implied by alternative decisions. We know that the axioms invoked in this paper apply to preferences over the full collection of <span id="id79">[]</span> acts. While the randomization of decisions described previously enlarges the set of <span id="id80">[]</span> acts by including the convex hull of the set of acts induced by prize rules, in general that device does not construct the full set of <span id="id81">[]</span> acts. We recognize that judging the plausibility or “self-evident quality” of the axioms that we impose would require extending the set of the acts to be studied beyond the set of induced by the potential actions within a “substantive decision model” even if allow randomization of the decisions.</p>
</section>
</div><div class="proof remark admonition" id="remark-8">
<p class="admonition-title"><span class="caption-number">Remark 7.4 </span></p>
<section class="remark-content" id="proof-content">
<p>This is a note of us but will eventually have to be clarified. Alternatively, we might start with a set of acts of the form <span class="math notranslate nohighlight">\(f_h\)</span> defined as below that are convex. Thus form <span class="math notranslate nohighlight">\(f_h\)</span> and <span class="math notranslate nohighlight">\(g_k\)</span> as two such acts. Then <span class="math notranslate nohighlight">\(f_{\alpha h + (1-\alpha) k}\)</span> is another act, apparently distinct from the convex combination described previously. What do we say about the preferences between this apparently distinct objects? We will have to say something.</p>
</section>
</div><p>Let <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> be the set of all acts. Each act <span class="math notranslate nohighlight">\(f \in \mathcal{A}\)</span> implies lotteries <span class="math notranslate nohighlight">\(f(\theta)\)</span> for each <span class="math notranslate nohighlight">\(\theta \in \Theta.\)</span> Two collections of acts will interest us, a set <span class="math notranslate nohighlight">\(\mathcal{A}_o\)</span> that lets us represent objective uncertainty and another set <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span> that <span id="id82">[]</span> used to express subjective uncertainty. Formally, let <span class="math notranslate nohighlight">\(\mathcal{A}_o \subset \mathcal{A}\)</span> denote the collection of all <em>constant</em> acts where a constant act maps all <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span> into a unique lottery over prizes <span class="math notranslate nohighlight">\(x \in X\)</span>. Constant acts express objective uncertainty because they do not depend on the parameter <span class="math notranslate nohighlight">\(\theta\)</span>. Absence of dependence means that the probability distribution <span class="math notranslate nohighlight">\(\pi \in \Pi\)</span> over states plays no role in shaping an ultimate probability distribution over prizes. A constant act constructed from a prize rule <span class="math notranslate nohighlight">\(\gamma\)</span> could emerge as follows. Suppose that some component of <span class="math notranslate nohighlight">\(W\)</span> has a known distribution independent of <span class="math notranslate nohighlight">\(\theta\)</span> and that <span class="math notranslate nohighlight">\(\gamma\)</span> depends only on this component. Such limited dependence implies an act that is independent of <span class="math notranslate nohighlight">\(\theta\)</span>. The collection <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span> consists of acts, each of which delivers a unique prize for each <span class="math notranslate nohighlight">\(\theta\)</span>. We let <span class="math notranslate nohighlight">\(s(\theta) \in X\)</span> denote an act in <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span>.<a class="footnote-reference brackets" href="#acts-footnote" id="id83" role="doc-noteref"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></a> We use a probability distribution <span class="math notranslate nohighlight">\(\pi \in \Pi\)</span> over states in conjunction with <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span> to express subjective uncertainty.</p>
<div class="proof remark admonition" id="remark-9">
<p class="admonition-title"><span class="caption-number">Remark 7.5 </span></p>
<section class="remark-content" id="proof-content">
<p><span id="id84">[]</span> distinguished “horse race lotteries,” represented by acts in <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span>, from “roulette lotteries,” represented by acts in <span class="math notranslate nohighlight">\(\mathcal{A}_o\)</span>. <a class="footnote-reference brackets" href="#kreps-notes" id="id85" role="doc-noteref"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></a> <span id="id86">[]</span> used roulette lotteries with known probabilities to construct subjective probabilities over horse race events.</p>
</section>
</div><div class="proof remark admonition" id="remark-10">
<p class="admonition-title"><span class="caption-number">Remark 7.6 </span></p>
<section class="remark-content" id="proof-content">
<p>While <span id="id87">[]</span> did not include “objective” lotteries when he rationalized subjective expected utility, his framework allows flexibility in defining both a state and an act. <span id="id88">[<a class="reference internal" href="../book/cite.html#id288" title="Itzhak Gilboa, Stefania Minardi, Larry Samuelson, and David Schmeidler. States and contingencies: how to understand savage without anyone being hanged. Revue Economique, 71:365-385, 2020. doi:10.3917/reco.712.0365.">Gilboa <em>et al.</em>, 2020</a>]</span> exhibit the flexibility of a Savage-style state space with a variety of applications and discuss benefits and challenges that this flexibility brings.<a class="footnote-reference brackets" href="#flexibility" id="id89" role="doc-noteref"><span class="fn-bracket">[</span>20<span class="fn-bracket">]</span></a> There is also flexibility in constructing an act. <span id="id90">[<a class="reference internal" href="../book/cite.html#id287" title="Simone Cerreia-Vioglio, Fabio Maccheroni, Massimo Marinacci, and Luigi Montrucchio. Probabilistic sophistication, second order stochastic dominance and uncertainty aversion. Journal of Mathematical Economics, 48:271-283, 2012. doi:10.1016/j.jmateco.2012.05.005.">Cerreia-Vioglio <em>et al.</em>, 2012</a>]</span> take advantage of this flexibility to produce a preference representation for <span id="id91">[]</span> acts under <span id="id92">[]</span> axioms augmented with risk independence. This representation coincides with the familiar <span id="id93">[]</span> representation for acts in <span class="math notranslate nohighlight">\(mathcal{A}_s\)</span> with unique prizes for each state.<a class="footnote-reference brackets" href="#representation" id="id94" role="doc-noteref"><span class="fn-bracket">[</span>21<span class="fn-bracket">]</span></a></p>
</section>
</div><div class="proof remark admonition" id="remark-11">
<p class="admonition-title"><span class="caption-number">Remark 7.7 </span></p>
<section class="remark-content" id="proof-content">
<p>Though not in ours, in other applications of <span id="id95">[]</span>, the state is <span class="math notranslate nohighlight">\(w\)</span>, and uncertainty is about a probability distribution to assign to the space <span class="math notranslate nohighlight">\(W\)</span>. A lottery conditioned on a state adds additional randomness with known probabilities. Preferences are cast in terms of lotteries conditioned on <span class="math notranslate nohighlight">\(w\)</span> as well as uncertainty over <span class="math notranslate nohighlight">\(W\)</span>.</p>
</section>
</div><p><span id="id96">[]</span> wrote:</p>
<blockquote>
<div><p>“… anyone who wishes to avoid a concept of physical chance distinct from probability may reinterpret our construction as a method of defining more difficult probabilities in terms of easier ones.”</p>
</div></blockquote>
<p>This environment is often interpreted as containing both “subjective” and “objective” uncertainties (for example, see <span id="id97">[]</span>).<a class="footnote-reference brackets" href="#anscombeaumannfootnote" id="id98" role="doc-noteref"><span class="fn-bracket">[</span>22<span class="fn-bracket">]</span></a></p>
<ul class="simple">
<li><p>Purely objective uncertainty that takes the form of a constant act, an act that delivers the <strong>same</strong> lottery <span class="math notranslate nohighlight">\(\lambda \in \Lambda\)</span> for all <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>.</p></li>
<li><p>Purely subjective uncertainty that takes the form of an act, <span class="math notranslate nohighlight">\(f\)</span>, that for each <span class="math notranslate nohighlight">\(\theta\)</span>, for which <span class="math notranslate nohighlight">\(f(dx | \theta)\)</span> is a degenerate Dirac lottery that pays prize <span class="math notranslate nohighlight">\(h(\theta) \in X\)</span> with probability one and the prize  <span class="math notranslate nohighlight">\(h(\theta)\)</span>  can depend on <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
</ul>
<p>We shall often construct a new act from initial acts <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span> by using a probability <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span> to form a mixture</p>
<div class="math notranslate nohighlight">
\[\left[ \alpha f + (1 - \alpha) g \right] (\theta) = \alpha f(\theta) + (1 - \alpha) g(\theta) \in \Lambda \hspace{.5cm} \forall \theta \in \Theta .\]</div>
<p>We shall use instances of our <span id="id99">[]</span> framework to describe a) a Bayesian decision maker with a unique prior over a set <span class="math notranslate nohighlight">\(\Theta\)</span> of statistical models, b) a decision maker who knows a set <span class="math notranslate nohighlight">\(\Theta\)</span> of statistical models and who copes with <strong>ambiguity</strong> about those models by considering prospective outcomes under a set of priors <span class="math notranslate nohighlight">\(\Pi\)</span> over those statistical models, c) a decision maker with concerns that a single known statistical model <span class="math notranslate nohighlight">\(\theta\)</span> is <strong>misspecified</strong> by using a statistical discrepancy measure to delineate unknown models surrounding that known model, and d) a decision maker with ambiguity and concerns about model misspecifications.</p>
<section id="preferences">
<h3><span class="section-number">7.3.1. </span>Preferences<a class="headerlink" href="#preferences" title="Link to this heading">#</a></h3>
<p>To represent a decision maker’s preferences over acts, we use <span class="math notranslate nohighlight">\(\sim\)</span> to mean indifference, <span class="math notranslate nohighlight">\(\succsim\)</span> a weak preference, and <span class="math notranslate nohighlight">\(\succ\)</span> a strict preference. Throughout, we assume that preferences are non-degenerate (there is a strict ranking between two acts), complete (we can compare any pair of acts), and transitive (<span class="math notranslate nohighlight">\(f \succsim g\)</span> and <span class="math notranslate nohighlight">\(g \succsim h\)</span> imply <span class="math notranslate nohighlight">\(f \succsim h\)</span>). We also impose an Archimedean axiom that provides a form of continuity.<a class="footnote-reference brackets" href="#footnotearch" id="id100" role="doc-noteref"><span class="fn-bracket">[</span>23<span class="fn-bracket">]</span></a></p>
<p>A <strong>finite signed measure</strong> on the measurable space <span class="math notranslate nohighlight">\((X, \mathfrak{X})\)</span> is a finite linear combination of probability measures that resides in a linear space <span class="math notranslate nohighlight">\({\widehat \Lambda}\)</span> that contains <span class="math notranslate nohighlight">\(\Lambda\)</span>.</p>
</section>
<section id="objective-probability">
<h3><span class="section-number">7.3.2. </span>Objective probability<a class="headerlink" href="#objective-probability" title="Link to this heading">#</a></h3>
<p>By analyzing preferences over the constant acts <span class="math notranslate nohighlight">\({\mathcal A}_o\)</span>, we temporarily put aside attitudes about ambiguity and model misspecification and focus on objective uncertainty (sometimes called “risk”). There is a unique probability <span class="math notranslate nohighlight">\(\lambda \in \Lambda\)</span> associated with every act <span class="math notranslate nohighlight">\(f \in {\mathcal A}_o\)</span> and a unique act in <span class="math notranslate nohighlight">\( {\mathcal A}_o\)</span> associated with every <span class="math notranslate nohighlight">\(\lambda \in \Lambda\)</span>. We define a restriction <span class="math notranslate nohighlight">\( \succ_\Lambda\)</span> of the preference order <span class="math notranslate nohighlight">\( \succ\)</span> to the space of constant acts <span class="math notranslate nohighlight">\(f \in {\mathcal A}_o\)</span> by</p>
<div class="math notranslate nohighlight">
\[\lambda \succ_\Lambda  \kappa \iff f \succ g\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda\)</span> is the probability generated by act <span class="math notranslate nohighlight">\(f \in {\mathcal A}_o\)</span> and <span class="math notranslate nohighlight">\(\kappa\)</span> is the probability distribution generated by act <span class="math notranslate nohighlight">\(g \in {\mathcal A}_o\)</span>.</p>
<p>To represent preferences <span class="math notranslate nohighlight">\(\succ_\Lambda\)</span>, we follow <span id="id101">[]</span>, who imposed the following restriction:<a class="footnote-reference brackets" href="#footnotenondeg" id="id102" role="doc-noteref"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></a></p>
<div class="proof axiom admonition" id="ax:ind0">
<p class="admonition-title"><span class="caption-number">Axiom 7.1 </span></p>
<section class="axiom-content" id="proof-content">
<p>(Independence) If <span class="math notranslate nohighlight">\(f, g, h \in {\mathcal A}_o\)</span> and <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span>, then</p>
<div class="math notranslate nohighlight">
\[f \succsim g \Rightarrow \alpha f + (1-\alpha) h \succsim  \alpha g + (1 - \alpha) h .\]</div>
</section>
</div><p>The approach delivers an expected utility representation of preferences over constant acts: there exists a utility function <span class="math notranslate nohighlight">\(u: X \rightarrow \mathbb{R}\)</span> such that for <span class="math notranslate nohighlight">\(f, g \in {\mathcal A}_o\)</span></p>
<div class="math notranslate nohighlight">
\[f \succsim g \iff  U(f) \ge U(g)\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[U(f) = \int_X u(x) d \lambda(x)\]</div>
<p>and <span class="math notranslate nohighlight">\(\lambda \in \Lambda\)</span> is the probability distribution generated by constant act <span class="math notranslate nohighlight">\(f\)</span>.</p>
</section>
<section id="subjective-probability">
<h3><span class="section-number">7.3.3. </span>Subjective probability<a class="headerlink" href="#subjective-probability" title="Link to this heading">#</a></h3>
<p>To construct subjective expected utility preferences, we extend an expected utility representation of <span class="math notranslate nohighlight">\(\succ_\Lambda\)</span> to a representation of preferences <span class="math notranslate nohighlight">\(\succ\)</span> on the set <span class="math notranslate nohighlight">\({\mathcal A}\)</span> of all acts. We impose restrictions on <span class="math notranslate nohighlight">\(\succ\)</span> in the form of two axioms.</p>
<p>The first extends the independence axiom to the set of all acts:</p>
<div class="proof axiom admonition" id="ax:ind">
<p class="admonition-title"><span class="caption-number">Axiom 7.2 </span></p>
<section class="axiom-content" id="proof-content">
<p>(Independence) If <span class="math notranslate nohighlight">\(f, g, h \in {\mathcal A}\)</span> and <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[f \succsim g \Rightarrow \alpha f + (1-\alpha) h \succsim  \alpha g + (1 - \alpha) h .\]</div>
</section>
</div><p>The second is:</p>
<div class="proof axiom admonition" id="ax:postive">
<p class="admonition-title"><span class="caption-number">Axiom 7.3 </span></p>
<section class="axiom-content" id="proof-content">
<p>(Monotonicity) For any <span class="math notranslate nohighlight">\(f, g \in {\mathcal A}\)</span> such that <span class="math notranslate nohighlight">\(f(\theta) \succsim_\Lambda g(\theta)\)</span> for each <span class="math notranslate nohighlight">\(\theta in \Theta\)</span>, <span class="math notranslate nohighlight">\(f \succsim g\)</span>.</p>
</section>
</div><p>This approach leads to the following representation of preferences over acts <span class="math notranslate nohighlight">\(f \in {\mathcal A}\)</span></p>
<div class="math notranslate nohighlight">
\[f \succsim g \iff \int_{\Theta} \left[\int_X u(x) d f(x | \theta) \right] d \pi(\theta) \ge \int_\Theta \left[ \int_X u(x) d g(x | \theta) \right] d \pi(\theta),\]</div>
<p>where the probability measure <span class="math notranslate nohighlight">\(\pi\)</span> describes subjective probabilities.</p>
</section>
<section id="max-min-expected-utility">
<h3><span class="section-number">7.3.4. </span>Max-min Expected Utility<a class="headerlink" href="#max-min-expected-utility" title="Link to this heading">#</a></h3>
<p>To construct a decision maker who has max-min expected utility preferences, <span id="id103">[]</span> replaced Axiom <a class="reference internal" href="#ax:ind">Axiom 7.2</a> with the following two axioms:</p>
<div class="proof axiom admonition" id="ax:gs1">
<p class="admonition-title"><span class="caption-number">Axiom 7.4 </span></p>
<section class="axiom-content" id="proof-content">
<p>(Certainty Independence) If <span class="math notranslate nohighlight">\(f, g \in {\mathcal A}\)</span>, <span class="math notranslate nohighlight">\(h \in {\mathcal A}_o\)</span>, and <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[f \succsim g \iff \alpha f + (1-\alpha) h \succsim  \alpha g + (1 - \alpha) h.\]</div>
</section>
</div><div class="proof axiom admonition" id="ax:gs2">
<p class="admonition-title"><span class="caption-number">Axiom 7.5 </span></p>
<section class="axiom-content" id="proof-content">
<p>(Uncertainty Aversion) If <span class="math notranslate nohighlight">\(f, g \in {\mathcal A}\)</span> and <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[f \sim g \Rightarrow  \alpha f + (1-\alpha)g \succsim f.\]</div>
</section>
</div><div class="proof example admonition" id="example-17">
<p class="admonition-title"><span class="caption-number">Example 7.5 </span></p>
<section class="example-content" id="proof-content">
<p>Suppose that <span class="math notranslate nohighlight">\(\Theta = \{\theta_1, \theta_2\}\)</span> and consider lotteries <span class="math notranslate nohighlight">\(\lambda_1\)</span> and <span class="math notranslate nohighlight">\(\lambda_2\)</span>. Let act <span class="math notranslate nohighlight">\(f\)</span> be lottery <span class="math notranslate nohighlight">\(\lambda_1\)</span> if <span class="math notranslate nohighlight">\(\theta = \theta_1\)</span> and lottery <span class="math notranslate nohighlight">\(\lambda_2\)</span> if <span class="math notranslate nohighlight">\(\theta = \theta_2\)</span>. Let act <span class="math notranslate nohighlight">\(g\)</span> be lottery <span class="math notranslate nohighlight">\(\lambda_2\)</span> if <span class="math notranslate nohighlight">\(\theta = \theta_1\)</span> and lottery <span class="math notranslate nohighlight">\(\lambda_1\)</span> if <span class="math notranslate nohighlight">\(\theta = \theta_2\)</span>. Suppose that <span class="math notranslate nohighlight">\(f \sim g\)</span>. Axiom <a class="reference internal" href="#ax:gs2">Axiom 7.5</a> allows a preference for mixing the two acts. If, for instance, <span class="math notranslate nohighlight">\(\alpha = \frac{1}{2}\)</span>, the mixture is a constant act with a lottery <span class="math notranslate nohighlight">\(\frac{1}{2} \lambda_1 + \frac{1}{2} \lambda_2\)</span> that is independent of <span class="math notranslate nohighlight">\(\theta\)</span>. We think of mixing as reducing the exposure to <span class="math notranslate nohighlight">\(\theta\)</span> uncertainty. In the extreme case, setting <span class="math notranslate nohighlight">\(\alpha = \frac{1}{2}\)</span>, for example, completely eliminates effects of exposure to <span class="math notranslate nohighlight">\(\theta\)</span> uncertainty.</p>
</section>
</div><p>By replacing Axiom <a class="reference internal" href="#ax:ind">Axiom 7.2</a> with Axioms <a class="reference internal" href="#ax:gs1">Axiom 7.4</a> and <a class="reference internal" href="#ax:gs2">Axiom 7.5</a>, <span id="id104">[]</span> obtained preferences described by</p>
<div class="math notranslate nohighlight">
\[f \succsim g \iff \min_{\pi \in \Pi_c} \int_\Theta \left[\int_X u(x) df(x \mid \theta)\right] d\pi(\theta) \ge \min_{\pi \in \Pi_c} \int_\Theta \left[\int_X u(x) dg(x \mid \theta)\right] d\pi(\theta)\]</div>
<p>for a convex set <span class="math notranslate nohighlight">\(\Pi_c \subset \Pi\)</span> of probability measures. An act <span class="math notranslate nohighlight">\(f(\theta)\)</span> is still a lottery over prizes <span class="math notranslate nohighlight">\(x \in X\)</span> and, as in representation \eqref{representation}, for each <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(\int_X u(x) df(x \mid \theta)\)</span> is an expected utility over prizes <span class="math notranslate nohighlight">\(x\)</span>.
Evidently, expected utility preferences \eqref{representationfishburn} are a special case of max-min expected utility preferences <code class="xref eq docutils literal notranslate"><span class="pre">eq:GS101</span></code> in which <span class="math notranslate nohighlight">\(\Pi_c\)</span> is a set with a single member.</p>
</section>
</section>
<section id="variational-preferences">
<span id="sec-varpref1"></span><h2><span class="section-number">7.4. </span>Variational preferences<a class="headerlink" href="#variational-preferences" title="Link to this heading">#</a></h2>
<p><span id="id105">[]</span> relaxed certainty independence Axiom <a class="reference internal" href="#ax:gs1">Axiom 7.4</a> of <span id="id106">[]</span> to obtain preferences with a yet more general representation that they called variational preferences.</p>
<div class="proof axiom admonition" id="ax:mmr2">
<p class="admonition-title"><span class="caption-number">Axiom 7.6 </span></p>
<section class="axiom-content" id="proof-content">
<p>(Weak Certainty Independence) If <span class="math notranslate nohighlight">\(f, g \in \mathcal{A}\)</span>, <span class="math notranslate nohighlight">\(h, k \in \mathcal{A}_o\)</span>, and <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\alpha f +(1-\alpha) h \succsim \alpha g +(1-\alpha) h \Rightarrow \alpha f +(1-\alpha) k \succsim \alpha g +(1-\alpha) k\]</div>
</section>
</div><p>Axiom \ref{ax:mmr2} considers only acts that are mixtures of constant acts that can be represented with a single lottery. The axiom states that altering the constant act from <span class="math notranslate nohighlight">\(h\)</span> to <span class="math notranslate nohighlight">\(k\)</span> does not reverse the decision maker’s preferences. The same <span class="math notranslate nohighlight">\(\alpha\)</span> appears in all three acts being compared. This axiom imparts to preferences a smooth tradeoff between separate contributions that come from an expected utility, on the one hand, and from statistical uncertainty, on the other.</p>
<p><span id="id107">[]</span> showed that preferences that satisfy the weaker Axiom \ref{ax:mmr2} instead of Axiom \ref{ax:gs1} are described by</p>
<div class="math notranslate nohighlight">
\[f \succsim g \iff \min_{\pi \in \Pi} \int_\Theta \left[\int_X u(x) df(x \mid \theta)\right] d\pi(\theta) + c(\pi) \ge \min_{\pi \in \Pi} \int_\Theta \left[\int_X u(x) dg(x \mid \theta)\right] d\pi(\theta) + c(\pi)\]</div>
<p>where <span class="math notranslate nohighlight">\(u\)</span> is uniquely determined up to a linear translation and <span class="math notranslate nohighlight">\(c\)</span> is a convex function that satisfies <span class="math notranslate nohighlight">\(\inf_{\pi \in \Pi} c(\pi) = 0\)</span>. Smaller convex functions, <span class="math notranslate nohighlight">\(c\)</span>, express more aversion to uncertainty. The convex function <span class="math notranslate nohighlight">\(c\)</span> in variational preferences representation \eqref{eq:MMR101} replaces the restricted set of probabilities <span class="math notranslate nohighlight">\(\Pi_c\)</span> that appears in the max-min expected utility representation <code class="xref eq docutils literal notranslate"><span class="pre">eq:GS101</span></code>.</p>
</section>
<section id="scaled-statistical-divergences-as-c-functions">
<span id="sec-statdivergasc"></span><h2><span class="section-number">7.5. </span>Scaled statistical divergences as <span class="math notranslate nohighlight">\(c\)</span> functions<a class="headerlink" href="#scaled-statistical-divergences-as-c-functions" title="Link to this heading">#</a></h2>
<p><em>Scaled statistical divergences</em> give rise to convex <span class="math notranslate nohighlight">\(c\)</span> functions that especially interest us. We use such divergences in two ways, one for distributions over <span class="math notranslate nohighlight">\((W, {\mathfrak W})\)</span>, another for distributions over <span class="math notranslate nohighlight">\((\Pi, {\mathfrak G} )\)</span>. We construct statistical divergences for these two situations in similar ways.</p>
<p>We first consider repercussion distributions over <span class="math notranslate nohighlight">\((W, {\mathfrak W})\)</span>. Consider a family of probabilities represented as densities with respect to <span class="math notranslate nohighlight">\(\upsilon\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-density-set">
<span class="eqno">(7.2)<a class="headerlink" href="#equation-density-set" title="Link to this equation">#</a></span>\[{\mathcal L} := \left\{ \ell \ge 0 : \int   \ell(w) d\upsilon(w) = 1 \right\}\]</div>
<p>For a baseline density <span class="math notranslate nohighlight">\(\ell_o\)</span>, a <em>statistical divergence</em> is a convex function <span class="math notranslate nohighlight">\(D(\ell \mid \ell_o)\)</span> of probability measures <span class="math notranslate nohighlight">\(\ell(w) d \upsilon(w)\)</span> that satisfies</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D(\ell \mid  \ell_o) \geq 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D(\ell \mid  \ell_o) = 0\)</span> implies <span class="math notranslate nohighlight">\(\ell = \ell_o\)</span></p></li>
</ul>
<p>Given <span class="math notranslate nohighlight">\(\ell_o,\)</span> write:</p>
<div class="math notranslate nohighlight">
\[\ell (w) d\upsilon(w) = m(w) \ell_o(w) d \upsilon(w)  \]</div>
<p>for <span class="math notranslate nohighlight">\(m = \frac {\ell}{ \ell_o}\)</span>, where we assume <span class="math notranslate nohighlight">\(m\)</span> is not infinite with positive <span class="math notranslate nohighlight">\(\upsilon\)</span> measure so that the probability measure <span class="math notranslate nohighlight">\(\ell\)</span> is absolutely continuous with respect to <span class="math notranslate nohighlight">\(\ell_o(w) d\upsilon(w)\)</span>.<a class="footnote-reference brackets" href="#divinfinitem" id="id108" role="doc-noteref"><span class="fn-bracket">[</span>25<span class="fn-bracket">]</span></a> The set of such densities is convex as is the set of implied relative densities <span class="math notranslate nohighlight">\(m\)</span>. To define a scaled statistical divergence, we set</p>
<div class="math notranslate nohighlight">
\[D(\ell \mid  \ell_o) = \xi \int_W \phi[m(w) ] \ell_o(w) d \upsilon(w),\]</div>
<p>where <span class="math notranslate nohighlight">\(\xi &gt; 0,\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span> is a convex function defined over the nonnegative real numbers for which <span class="math notranslate nohighlight">\(\phi(1) = 0\)</span> and impose <span class="math notranslate nohighlight">\(\phi''(1) = 1\)</span> as a normalization. Examples of such <span class="math notranslate nohighlight">\(\phi\)</span> functions and the divergences that they lead to are</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\phi(m) &amp;= - \log (m) &amp; \text{Burg entropy}  \\
\phi(m) &amp; = -4  \left( \sqrt{m} - 1 \right) &amp; \text{ Hellinger distance} \\
\phi(m) &amp; = m \log (m) &amp; \text{ relative entropy}\\
\phi(m) &amp; = {\frac 1 2} \left( m^2 - m \right) &amp; \text{quadratic}.
\end{align*}\end{split}\]</div>
<p>When <span class="math notranslate nohighlight">\(\xi = 1\)</span>, the divergence, <span class="math notranslate nohighlight">\(D,\)</span> is often called a <span class="math notranslate nohighlight">\(\phi\)</span> or <span class="math notranslate nohighlight">\(f\)</span>-divergence. When <span class="math notranslate nohighlight">\(\phi(m)  = m \log (m)\)</span> and <span class="math notranslate nohighlight">\(\xi = 1\)</span>, we obtain relative entropy</p>
<div class="math notranslate nohighlight">
\[D_{KL}(\ell | \ell_o) = \int_W m(w)\log[m(w)]  d \upsilon(w)    .\]</div>
<p>Relative entropy is commonly referred to as Kullback-Leibler divergence.</p>
<div class="proof remark admonition" id="remark-19">
<p class="admonition-title"><span class="caption-number">Remark 7.8 </span></p>
<section class="remark-content" id="proof-content">
<p>Other families of divergences can be used in conjunction with preference representations that follow, for instance, from Bregman and Wasserstein divergences.<br />
The family <span class="math notranslate nohighlight">\(\phi\)</span> or <span class="math notranslate nohighlight">\(f\)</span> divergences featured here has very nice duality properties.<br />
as we will see, duality allows us to make formal connections to the extensive literature on smooth ambiguity.<br />
Furthermore, these divergences are invariant to one-to-one transformations of the space over which the probability distributions are defined.  In addition,  some members of this family have useful links  to statistical discrimination procedures. The link to likelihood-based statistical discrimination enables statistical constructions that can help us calibrate concerns about robustness.</p>
</section>
</div></section>
<section id="basic-formulation">
<span id="sec-ourformulation"></span><h2><span class="section-number">7.6. </span>Basic formulation<a class="headerlink" href="#basic-formulation" title="Link to this heading">#</a></h2>
<p>We associate a probability measure <span class="math notranslate nohighlight">\(\tau(w | \theta)d\upsilon(w)\)</span> parametrized by <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span> with a random vector having possible realizations <span class="math notranslate nohighlight">\(w\)</span> in the measurable space <span class="math notranslate nohighlight">\((W, \mathfrak{W})\)</span>. Consider alternative real valued, Borel measurable functions <span class="math notranslate nohighlight">\(\gamma \in \Psi\)</span> that map <span class="math notranslate nohighlight">\(w \in W\)</span> into an <span class="math notranslate nohighlight">\(x \in X\)</span>. Think of <span class="math notranslate nohighlight">\(\gamma\)</span> as a prize rule and <span class="math notranslate nohighlight">\(\gamma(w)\)</span> as an uncertain scalar prize. For each prize rule <span class="math notranslate nohighlight">\(\gamma\)</span>, let <span class="math notranslate nohighlight">\(d \lambda(x \mid \theta)\)</span> be the distribution of the prize <span class="math notranslate nohighlight">\(x\)</span> that is induced by distribution <span class="math notranslate nohighlight">\(\tau(w | \theta) d\upsilon(w)\)</span> and the prize rule <span class="math notranslate nohighlight">\(\gamma\)</span>. The distribution of the prize thus depends both on the prize rule <span class="math notranslate nohighlight">\(\gamma(w)\)</span> and the distribution <span class="math notranslate nohighlight">\(\tau(w \mid \theta) d\upsilon(w).\)</span> Within this setting, a decision <span class="math notranslate nohighlight">\(\delta\)</span> gives rise to a specific pair <span class="math notranslate nohighlight">\((\gamma_\delta, \tau_\delta)\)</span>. To avoid cluttering our notation, we will drop the explicit dependence of <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> on <span class="math notranslate nohighlight">\(\delta\)</span> in much of the following discussion.</p>
<section id="not-knowing-a-prior">
<span id="sec-nonknowingprior"></span><h3><span class="section-number">7.6.1. </span>Not knowing a prior<a class="headerlink" href="#not-knowing-a-prior" title="Link to this heading">#</a></h3>
<p>Like the robust Bayesian decision maker of <span id="id109">[]</span>, <span id="id110">[]</span> and <span id="id111">[]</span>, our decision maker has multiple prior distributions because he does not trust the baseline prior.<a class="footnote-reference brackets" href="#robustbayesian" id="id112" role="doc-noteref"><span class="fn-bracket">[</span>26<span class="fn-bracket">]</span></a> We label such distrust of a single prior “model ambiguity.” Here we describe a static version of what <span id="id113">[]</span> call structured uncertainty. “Structured” refers to a particular way that we reduce the dimension of a set of alternative models relative to the much larger set considered when we explore likelihood or model misspecification.</p>
<p>A baseline <span class="math notranslate nohighlight">\(\pi_o\)</span> anchors a set of priors <span class="math notranslate nohighlight">\(\pi\)</span> over which a decision maker wishes to be robust. We describe the set of priors by</p>
<div class="math notranslate nohighlight">
\[\pi(d\theta) = n(\theta)\pi_o(d\theta) ,\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is in the set <span class="math notranslate nohighlight">\(\mathcal{N}\)</span> defined by:</p>
<div class="math notranslate nohighlight" id="equation-nset">
<span class="eqno">(7.3)<a class="headerlink" href="#equation-nset" title="Link to this equation">#</a></span>\[\mathcal{N} \doteq \left\{ n \ge 0  : n(\theta) \ge 0, \int_\Theta n(\theta)  d\pi_o(\theta) = 1 \right\}.\]</div>
<p>This specification includes a form of “structured” uncertainty in which all models have the same parametric “structure” but in which each is associated with a different vector of parameter values.<a class="footnote-reference brackets" href="#structureduncertainty" id="id114" role="doc-noteref"><span class="fn-bracket">[</span>27<span class="fn-bracket">]</span></a> The decision maker is certain about each of the specific models but is uncertain about a prior to put over them.</p>
<section id="not-knowing-a-prior-i">
<span id="sec-notknowingprior1"></span><h4><span class="section-number">7.6.1.1. </span>Not knowing a prior, I<a class="headerlink" href="#not-knowing-a-prior-i" title="Link to this heading">#</a></h4>
<p>To express a form of ambiguity aversion, the decision maker uses scaled statistical divergence</p>
<div class="math notranslate nohighlight">
\[c(\pi) = \xi \int_\Theta \phi \left[ n(\theta) \right]    d\pi_o(\theta) \]</div>
<p>and has variational preferences ordered by<a class="footnote-reference brackets" href="#cerreiaetalvariational" id="id115" role="doc-noteref"><span class="fn-bracket">[</span>28<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight" id="equation-eqn-minproblem106">
<span class="eqno">(7.4)<a class="headerlink" href="#equation-eqn-minproblem106" title="Link to this equation">#</a></span>\[\min_{n \in \mathcal{N} } \int_\Theta \left(  \int_W u[\gamma(w) ]  \tau( w \mid \theta) d\upsilon(w)  \right) n(\theta) d\pi_o(\theta)    + \xi \int_\Theta \phi[n(\theta)] d \pi_o(\theta)   .\]</div>
<div class="proof remark admonition" id="remark-20">
<p class="admonition-title"><span class="caption-number">Remark 7.9 </span></p>
<section class="remark-content" id="proof-content">
<p>It is convenient to solve the minimization problem <a class="reference internal" href="#equation-eqn-minproblem106">(7.4)</a> by using duality properties of convex functions. Because the objective is separable in <span class="math notranslate nohighlight">\(\theta\)</span>, we first compute</p>
<div class="math notranslate nohighlight" id="equation-eqn-legendre102">
<span class="eqno">(7.15)<a class="headerlink" href="#equation-eqn-legendre102" title="Link to this equation">#</a></span>\[\phi^*({\sf u} \mid \xi ) = \min_{{\sf n} \ge 0} {\sf u} {\sf n} + \xi \phi({\sf n})\]</div>
<p>where <span class="math notranslate nohighlight">\({\sf u} = \int u[\gamma(w)]\tau(w | \theta)d\upsilon(w) + \eta\)</span>, <span class="math notranslate nohighlight">\({\sf n}\)</span> is a nonnegative number, and <span class="math notranslate nohighlight">\(\eta\)</span> is a nonnegative real-valued Lagrange multiplier attached to the constraint
<span class="math notranslate nohighlight">\(\int_\Theta n(\theta) d \pi_o(\theta) = 1\)</span>; <span class="math notranslate nohighlight">\(\phi^*({\sf u} \mid \xi )\)</span> is a concave function of <span class="math notranslate nohighlight">\({\sf u}.\)</span><a class="footnote-reference brackets" href="#legendretransform" id="id116" role="doc-noteref"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></a> The minimizing value of <span class="math notranslate nohighlight">\({\sf n}\)</span> satisfies</p>
<div class="math notranslate nohighlight">
\[{\sf n}^* = \phi'^{-1} \left(- {\frac {\sf u} \xi} \right) .\]</div>
<p>The dual to the minimization problem on the right side
of <a class="reference internal" href="#equation-eqn-minproblem106">(7.4)</a> is</p>
<div class="math notranslate nohighlight" id="equation-eqn-dualproblem106">
<span class="eqno">(7.6)<a class="headerlink" href="#equation-eqn-dualproblem106" title="Link to this equation">#</a></span>\[\max_\eta \int_\Theta \phi^* \left(u[\gamma(w)] \tau(w \mid \theta) d\upsilon(w) +\eta \right) d \pi_o(\theta) - \eta .\]</div>
</section>
</div><div class="proof remark admonition" id="remark-21">
<p class="admonition-title"><span class="caption-number">Remark 7.10 </span></p>
<section class="remark-content" id="proof-content">
<p>(Smooth ambiguity preferences)</p>
<p>When statistical divergence is scaled relative entropy, preferences over <span class="math notranslate nohighlight">\(\gamma(w)\)</span> are ordered by</p>
<div class="math notranslate nohighlight" id="equation-eqn-risksens-1015">
<span class="eqno">(7.7)<a class="headerlink" href="#equation-eqn-risksens-1015" title="Link to this equation">#</a></span>\[- \xi \log \left[  \int_\Theta \exp \left( - {\frac { \int_W u[ \gamma(w) ]  \tau( w  \mid \theta) d\upsilon(w)} \xi}\right) d \pi_o(\theta) \right],\]</div>
<p>a static version of preferences that <span id="id117">[]</span> used to frame a robust dynamic filtering and control problem.</p>
<p>These preferences are also a special case of the smooth ambiguity preferences that <span id="id118">[]</span> justified with a set of axioms different from the ones we have used here. Furthermore, <span id="id119">[]</span> and <span id="id120">[]</span> use this formulation to express concerns about model misspecification.<a class="footnote-reference brackets" href="#footnotestrzalecki" id="id121" role="doc-noteref"><span class="fn-bracket">[</span>30<span class="fn-bracket">]</span></a></p>
<p>In contradistinction, the robustness concerns being represented in this subsection are about a baseline prior over known models and not about possible misspecifications of those models.</p>
</section>
</div><div class="proof remark admonition" id="remark-22">
<p class="admonition-title"><span class="caption-number">Remark 7.11 </span></p>
<section class="remark-content" id="proof-content">
<p>In subsection <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">Not knowing a model</span></a>, we considered a setting in which the state or “parameter vector” <span class="math notranslate nohighlight">\(\theta = m\)</span> and</p>
<div class="math notranslate nohighlight" id="equation-eqn-stateparameter">
<span class="eqno">(7.8)<a class="headerlink" href="#equation-eqn-stateparameter" title="Link to this equation">#</a></span>\[d \tau( w \mid \theta ) = m(w) d \tau_o(w),\]</div>
<p>where <span class="math notranslate nohighlight">\(m \in {\mathcal M}\)</span> and <span class="math notranslate nohighlight">\(d \tau_o (w)\)</span> is a baseline distribution. Suppose that instead of proceeding as we did in subsection <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">Not knowing a model</span></a> we were to posit a baseline prior <span class="math notranslate nohighlight">\(\pi_o\)</span> over a possibly infinite dimensional parameter space <span class="math notranslate nohighlight">\({\mathcal M}\)</span>. If we were then to explore prior robustness by considering alternative <span class="math notranslate nohighlight">\(n\)</span>’s in <span class="math notranslate nohighlight">\({\mathcal N}\)</span> using statistical divergence <a class="reference internal" href="#sec-statdivergasc"><span class="std std-ref">section</span></a>, we would have to specify <span class="math notranslate nohighlight">\(\pi_o\)</span> to be sufficiently “informative” that it would limit the range of alternative distributions <span class="math notranslate nohighlight">\(d \tau(w)\)</span> that the decision maker entertains relative to those in the <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">Not knowing a model</span></a> formulation. The distinct ways in which the <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">Not knowing a model</span></a> and <a class="reference internal" href="#sec-nonknowingprior"><span class="std std-ref">Not knowing a prior</span></a> formulations use statistical discrepancies lead to substantial differences in the resulting variational preferences, namely, representation <a class="reference internal" href="#equation-eqn-minproblem105">(7.14)</a> for the <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">Not knowing a model</span></a> setting of not knowing the distribution of <span class="math notranslate nohighlight">\(d \tau(w)\)</span> and <a class="reference internal" href="#equation-eqn-minproblem106">(7.4)</a> for the <a class="reference internal" href="#sec-nonknowingprior"><span class="std std-ref">Not knowing a prior</span></a> formulation of not knowing a prior over a known set of known models <span class="math notranslate nohighlight">\(d \tau(w \mid \theta)\)</span>. See remark <a class="reference internal" href="#rem:sims">Remark 7.14</a> for more about this issue.</p>
</section>
</div></section>
</section>
<section id="not-knowing-a-prior-ii">
<span id="sec-nonknowingprior2"></span><h3><span class="section-number">7.6.2. </span>Not knowing a prior, II<a class="headerlink" href="#not-knowing-a-prior-ii" title="Link to this heading">#</a></h3>
<p>We modify preferences by using a statistical divergence to constrain a set of prior probabilities. The resulting preferences satisfy axioms of <span id="id122">[]</span>. Consider:</p>
<div class="math notranslate nohighlight" id="equation-pidef">
<span class="eqno">(7.9)<a class="headerlink" href="#equation-pidef" title="Link to this equation">#</a></span>\[\Pi = \{ \pi : d\pi(\theta) = n(\theta) d\pi_o(\theta), n \in {\mathcal N}, \int_\Theta \phi[n(\theta)] d \pi_o(\theta) \le \kappa  \}\]</div>
<p>where <span class="math notranslate nohighlight">\(\kappa &gt; 0\)</span> pins down the size of the set of priors. Preferences over <span class="math notranslate nohighlight">\(\gamma(w)\)</span> are ordered by</p>
<div class="math notranslate nohighlight" id="equation-eqn-minproblem107">
<span class="eqno">(7.10)<a class="headerlink" href="#equation-eqn-minproblem107" title="Link to this equation">#</a></span>\[\min_{\pi \in \Pi } \int_\Theta \left( \int_W u[ \gamma( w )] \tau( w \mid \theta) d\nu(w) \right) d \pi(\theta).\]</div>
<div class="proof remark admonition" id="remark-23">
<p class="admonition-title"><span class="caption-number">Remark 7.12 </span></p>
<section class="remark-content" id="proof-content">
<p>It is convenient to solve the minimization problem on the right side of <a class="reference internal" href="#equation-eqn-minproblem107">(7.10)</a> by using duality properties of convex functions. The minimized objective for problem <a class="reference internal" href="#equation-eqn-minproblem107">(7.10)</a> can again be evaluated using convex duality theory. We now explicitly note the dependence of <span class="math notranslate nohighlight">\(\phi^*\)</span> on <span class="math notranslate nohighlight">\(\xi\)</span> and write the dual problem as:</p>
<div class="math notranslate nohighlight">
\[\max_{\eta, \xi \ge 0}   \int_\Theta \phi^* \left[  \int_W  u[\gamma(w)] \tau(w \mid \theta) d\nu(w)   + \eta  \mid \xi \right] d \pi_o(\theta ) - \eta - \xi \kappa .\]</div>
<p>Maximization over <span class="math notranslate nohighlight">\(\xi \ge 0 \)</span> enforces a constraint on the set of admissible priors.</p>
</section>
</div><div class="proof remark admonition" id="remark-24">
<p class="admonition-title"><span class="caption-number">Remark 7.13 </span></p>
<section class="remark-content" id="proof-content">
<p>Within a setting like that of <a class="reference internal" href="#ex:estimation">Example 7.4</a>, <span id="id123">[]</span> used another approach to compute robust adjustments to posterior expectations. He used this approach to assess the prior sensitivity of empirical measurements of targets of interest to an investigator. <span id="id124">[]</span>’s framework could also be used to define robust preferences defined in terms of posterior expectations. For instance, measurements of interest could be depicted as the maximizer of the negative of an expected loss function of a type common in statistics and econometrics. More formally, <span id="id125">[]</span> used relative entropy divergence to restrict a set of priors. He computed expectations conditioned on a signal and minimized over possible implied posterior distributions given a relative entropy constraint over the priors. The minimizing “prior” from this approach typically depends on the signal,<a class="footnote-reference brackets" href="#hoformula" id="id126" role="doc-noteref"><span class="fn-bracket">[</span>31<span class="fn-bracket">]</span></a> unlike the outcome from solving the <em>ex-ante problem</em> described in <a class="reference internal" href="#remark:Ferguson">Example 7.3</a>. Dependence of a minimizing prior on the signal like that in <span id="id127">[]</span>’s formulation also emerges in some recursive formulations of dynamic problems, a situation that can lead to statistically inadmissible decisions.<a class="footnote-reference brackets" href="#dynamicproblem" id="id128" role="doc-noteref"><span class="fn-bracket">[</span>32<span class="fn-bracket">]</span></a></p>
</section>
</div></section>
</section>
<section id="not-knowing-a-likelihood">
<span id="sec-notknowingmodel"></span><h2><span class="section-number">7.7. </span>Not knowing a likelihood<a class="headerlink" href="#not-knowing-a-likelihood" title="Link to this heading">#</a></h2>
<p>Instead of being about a prior as the previous subsection, we now suppose that the decision maker’s uncertainty is about a likelihood function. We start by supposing that there is a single model that the decision maker fears is misspecified. We then extend the analysis by introducing a parameterized family of probability models that a decision maker thinks might be misspecified.</p>
<section id="a-misspecified-model">
<span id="sec-notknowingmodel1"></span><h3><span class="section-number">7.7.1. </span>A misspecified model<a class="headerlink" href="#a-misspecified-model" title="Link to this heading">#</a></h3>
<p>Consider first a single model that might be misspecified. We study a decision maker who knows a parameter <span class="math notranslate nohighlight">\(theta_o\)</span>. We also fix a decision <span class="math notranslate nohighlight">\(delta\)</span>, a determinant of <span class="math notranslate nohighlight">\(tau\)</span> that we continue to leave implicit in our notation. The decision maker entertains the possible misspecification of</p>
<div class="math notranslate nohighlight">
\[tau_o(w) := tau(\cdot \mid \theta_o)\]</div>
<p>in ways that the decision maker cannot precisely describe. But he can say that the alternative models that he is most worried about are statistically close to his baseline model. The presence of too many statistically nearby models would prevent a Bayesian from deploying a proper prior over them. (Later we will compare our approach here to a robust Bayesian approach that requires a family of priors that are mutually absolutely continuous.)</p>
<p>Notice that <span class="math notranslate nohighlight">\(\tau_o in {\mathcal L} \)</span> where <span class="math notranslate nohighlight">\({\mathcal L}\)</span> is given by</p>
<div class="math notranslate nohighlight" id="equation-misspecified-models">
<span class="eqno">(7.11)<a class="headerlink" href="#equation-misspecified-models" title="Link to this equation">#</a></span>\[m(w) \tau_o(w) \]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[m(w) := \frac{\ell} {\tau_o}\]</div>
<p><span class="math notranslate nohighlight">\(\ell in {\mathcal L}\)</span> for <span class="math notranslate nohighlight">\({\mathcal L}\)</span> given by <a class="reference internal" href="#equation-density-set">(7.2)</a>. We represent the decision maker’s ignorance of specific alternative models by assuming that he entertains a potentially infinite dimensional space <span class="math notranslate nohighlight">\({\mathcal L}\)</span> of what we will call “unstructured” models. A decision maker’s expected utility under alternative model <span class="math notranslate nohighlight">\(\ell \tau_o(w) d\upsilon(w)\)</span> is</p>
<div class="math notranslate nohighlight" id="equation-eqn-exputilmonly2">
<span class="eqno">(7.12)<a class="headerlink" href="#equation-eqn-exputilmonly2" title="Link to this equation">#</a></span>\[\int_W u[\gamma(w)] m(w) \tau_o(w) d\upsilon(w) =  \int_W u[\gamma(w)] \ell (w)  d\upsilon(w).\]</div>
<p>Notice that <a class="reference internal" href="#equation-eqn-exputilmonly2">(7.12)</a> evaluates expected utility for a single choice for <span class="math notranslate nohighlight">\(m\)</span>.</p>
<div class="proof remark admonition" id="rem:sims">
<p class="admonition-title"><span class="caption-number">Remark 7.14 </span></p>
<section class="remark-content" id="proof-content">
<p>Specifying a prior over the infinite dimensional space <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> brings challenges associated with all nonparametric methods, including “nonparametric Bayesian” methods. A Bayesian prior on an infinite dimensional space such as <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> must be more “informative” than is required in finite-dimensional estimation problems.<a class="footnote-reference brackets" href="#sims2010" id="id129" role="doc-noteref"><span class="fn-bracket">[</span>33<span class="fn-bracket">]</span></a> A related “informativeness” requirement carries over to families of priors that are absolutely continuous relative to a baseline prior. The decision maker in this subsection does not want to entertain priors that are “too informative.” In subsection <a class="reference internal" href="#sec:nonknowingprior1"><span class="xref myst">nonknowingprior1</span></a>, we describe a decision maker who is concerned about a set of models that is small enough to proceed with a “robust Bayesian” approach with priors over those models that are not “too informative.”</p>
</section>
</div><p>To complete a description of preferences, we require a scaled statistical divergence. We consider alternative probabilities parameterized by entries in <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. Under this perspective, a probability model corresponds to a choice of <span class="math notranslate nohighlight">\(m \in \mathcal{M}\)</span>. Form a scaled divergence measure:</p>
<div class="math notranslate nohighlight" id="equation-eqn-scaledkl99">
<span class="eqno">(7.13)<a class="headerlink" href="#equation-eqn-scaledkl99" title="Link to this equation">#</a></span>\[c( m) = \xi \int_{W} \phi [m(w) ] \tau_o(w) d\upsilon(w)\]</div>
<p>where <span class="math notranslate nohighlight">\(\xi &gt; 0\)</span> is a real number. Variational preferences that use <a class="reference internal" href="#equation-eqn-scaledkl99">(7.13)</a> as scaled statistical divergence are ordered by</p>
<div class="math notranslate nohighlight" id="equation-eqn-minproblem105">
<span class="eqno">(7.14)<a class="headerlink" href="#equation-eqn-minproblem105" title="Link to this equation">#</a></span>\[\min_{m = \frac{\ell}{\tau_o}, \ell \in \mathcal{L}} \left( \int_{W} u[\gamma(w)] m(w) \tau_o(w) d\upsilon(w) + \xi \int_{W} \phi[m(w)] \tau_o(w) d\upsilon(w) \right).\]</div>
<p>This formulation lets a decision maker evaluate alternative prize rules <span class="math notranslate nohighlight">\(\gamma(w)\)</span> while guarding against a concern that his baseline model <span class="math notranslate nohighlight">\(\tau_o\)</span> is misspecified without having in mind specific alternative models <span class="math notranslate nohighlight">\(\tau\)</span>. Key ingredients are the single baseline probability <span class="math notranslate nohighlight">\(\tau_o\)</span> and a statistical divergence over probability distributions <span class="math notranslate nohighlight">\(m(w) \tau_o(w) d\upsilon(w)\)</span>.</p>
<div class="proof remark admonition" id="rem:dual1">
<p class="admonition-title"><span class="caption-number">Remark 7.15 </span></p>
<section class="remark-content" id="proof-content">
<p>As was the case for robust prior analysis, it is again convenient to solve the minimization problem on the right side of <a class="reference internal" href="#equation-eqn-minproblem105">(7.14)</a> by using duality properties of convex functions. Because the objective is separable in <span class="math notranslate nohighlight">\(w\)</span>, we can first compute</p>
<div class="math notranslate nohighlight" id="equation-eqn-legendre102">
<span class="eqno">(7.15)<a class="headerlink" href="#equation-eqn-legendre102" title="Link to this equation">#</a></span>\[\phi^*(\mathsf{u} \mid \xi ) =  \min_{\mathsf{m} \ge 0}  \mathsf{u} \mathsf{m}  + \xi \phi(\mathsf{m})\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathsf{u} =u[\gamma(w)] + \eta\)</span>, <span class="math notranslate nohighlight">\(\mathsf{m}\)</span> is a nonnegative number, and <span class="math notranslate nohighlight">\(\eta\)</span> is a nonnegative real-valued Lagrange multiplier that we attach to the constraint
<span class="math notranslate nohighlight">\(\int m(w) \tau_o(w )d\upsilon(w) = 1\)</span>; <span class="math notranslate nohighlight">\(\phi^*(\mathsf{u} \mid \xi )\)</span> is a concave function of <span class="math notranslate nohighlight">\(\mathsf{u}\)</span>. The minimizing value of <span class="math notranslate nohighlight">\(\mathsf{m}\)</span> now satisfies</p>
<div class="math notranslate nohighlight">
\[\mathsf{m}^*  =  \phi'^{-1}  \left(- {\frac {\mathsf{u}}  \xi} \right) .\]</div>
<p>The dual problem to the minimization problem on the right side
of <a class="reference internal" href="#equation-eqn-minproblem105">(7.14)</a> is</p>
<div class="math notranslate nohighlight" id="equation-eqn-dualproblem105">
<span class="eqno">(7.16)<a class="headerlink" href="#equation-eqn-dualproblem105" title="Link to this equation">#</a></span>\[\max_\eta \int_W  \phi^* (u[\gamma(w)] +\eta  ) \tau_o(w)d\upsilon(w)  - \eta .\]</div>
</section>
</div><div class="proof remark admonition" id="rem:dual2">
<p class="admonition-title"><span class="caption-number">Remark 7.16 </span></p>
<section class="remark-content" id="proof-content">
<p>We posed a minimum problem <a class="reference internal" href="#equation-eqn-minproblem105">(7.14)</a> in terms of a set of probability measures on the measurable space <span class="math notranslate nohighlight">\((W, \mathfrak{W})\)</span> with baseline probability <span class="math notranslate nohighlight">\(\tau_o(w)d\upsilon(w)\)</span>. Since the integrand in the dual problem <a class="reference internal" href="#equation-eqn-dualproblem105">(7.16)</a> depends on <span class="math notranslate nohighlight">\(w\)</span> only through the control law <span class="math notranslate nohighlight">\(\gamma\)</span>, we could instead have used the same convex function <span class="math notranslate nohighlight">\(\phi\)</span> to pose a minimization in terms of a set of probability distributions <span class="math notranslate nohighlight">\(d\lambda(x)\)</span> with the baseline being the probability distribution over prizes induced <span class="math notranslate nohighlight">\(x = \gamma(w)\)</span> with distribution <span class="math notranslate nohighlight">\(d\lambda_o(x)\)</span>. Doing that would lead to equivalent outcomes. Representations in sections <a class="reference internal" href="#sec-prelim"><span class="std std-ref">Preliminaries</span></a> and <a class="reference internal" href="#sec-varpref1"><span class="std std-ref">Variational Preferences</span></a> are all cast in terms of induced distributions over prizes. Because control problems entail searching over alternative <span class="math notranslate nohighlight">\(\gamma\)</span>’s, it is more convenient to formulate them in terms of a baseline model <span class="math notranslate nohighlight">\(\tau_o(w)d\upsilon(w)\)</span>, as we originally did in subsection <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">Not Knowing the Model</span></a>.</p>
</section>
</div><div class="proof remark admonition" id="rem:dual3">
<p class="admonition-title"><span class="caption-number">Remark 7.17 </span></p>
<section class="remark-content" id="proof-content">
<p>If we use relative entropy as a statistical divergence, then</p>
<div class="math notranslate nohighlight">
\[\phi^*({\sf u} \mid \xi ) =  - \xi  \exp \left( - {\frac {\sf u + \eta } \xi} - 1  \right)\]</div>
<p>and dual problem <a class="reference internal" href="#equation-eqn-dualproblem105">(7.16)</a> becomes<a class="footnote-reference brackets" href="#dupuisellis" id="id130" role="doc-noteref"><span class="fn-bracket">[</span>34<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight" id="equation-eqn-risksens1002">
<span class="eqno">(7.17)<a class="headerlink" href="#equation-eqn-risksens1002" title="Link to this equation">#</a></span>\[\max_\eta  - \xi  \int_W  \exp \left[ - {\frac { u[\gamma(w)]  + \eta } \xi} - 1 \right] \tau_o(w) d \upsilon(w)  - \eta = - \xi \log \left(  \int_{W}  \exp \left[ - {\frac { u[\gamma(w)]} \xi}\right]  \tau_o(w) d\upsilon(w) \right) .\]</div>
<p>The minimizing <span class="math notranslate nohighlight">\(m\)</span> in problem <a class="reference internal" href="#equation-eqn-minproblem105">(7.14)</a> is</p>
<div class="math notranslate nohighlight" id="equation-eq-n">
<span class="eqno">(7.18)<a class="headerlink" href="#equation-eq-n" title="Link to this equation">#</a></span>\[m^*(w) =  \frac {\exp\left[ - {\frac {u[\gamma(w)]} \xi}  \right] } { \int_W \exp\left[ - {\frac {u[\gamma(w)] }  \xi} \right] \tau_o(w) d\upsilon(w)}.\]</div>
<p>The worst-case likelihood ratio <span class="math notranslate nohighlight">\(m^*\)</span> exponentially tilts a lottery toward low-utility outcomes. <span id="id131">[]</span> calls this adverse tilting a statistical version of Murphy’s law:</p>
<blockquote>
<div><p>“The probability of anything happening is in inverse proportion to its desirability.”</p>
</div></blockquote>
</section>
</div><div class="proof remark admonition" id="rem:risksens100">
<p class="admonition-title"><span class="caption-number">Remark 7.18 </span></p>
<section class="remark-content" id="proof-content">
<p>(Risk-sensitive preferences)</p>
<p>The right side of equation <a class="reference internal" href="#equation-eqn-risksens103">(7.19)</a>, namely,</p>
<div class="math notranslate nohighlight" id="equation-eqn-risksens103">
<span class="eqno">(7.19)<a class="headerlink" href="#equation-eqn-risksens103" title="Link to this equation">#</a></span>\[- \xi \log \left[  \int_W \exp \left( - {\frac { u[\gamma(w)]} \xi}\right)  \tau_o(w) d\upsilon(w) \right] ,\]</div>
<p>defines what are known as “risk-sensitive” preferences over control laws <span class="math notranslate nohighlight">\(\gamma\)</span>. Since a logarithm is a monotone function, these are evidently equivalent to <span id="id132">[]</span> expected utility preferences with utility function</p>
<div class="math notranslate nohighlight">
\[- \exp\left[ - {\frac {u(\cdot)} \xi} \right]\]</div>
<p>in conjunction with the baseline distribution <span class="math notranslate nohighlight">\(\tau_o\)</span> over repercussions. Risk-sensitive preferences are widely used in robust control theory (for example, see <span id="id133">[]</span>, <span id="id134">[<a class="reference internal" href="../book/cite.html#id264" title="Peter Whittle. Risk-Sensitive Optimal Control. John Wiley &amp; Sons, New York, 1990.">Whittle, 1990</a>]</span>, and <span id="id135">[]</span>).</p>
</section>
</div><div class="proof remark admonition" id="remark-30">
<p class="admonition-title"><span class="caption-number">Remark 7.19 </span></p>
<section class="remark-content" id="proof-content">
<p>Although our notation suppressed it, the <span class="math notranslate nohighlight">\(m\)</span>’s in the minimization problem can depend on the decision <span class="math notranslate nohighlight">\(\delta\)</span>, as dependence that carries over to implied densities, <span class="math notranslate nohighlight">\(\ell.\)</span></p>
</section>
</div><div class="proof example admonition" id="ex:discrete">
<p class="admonition-title"><span class="caption-number">Example 7.6 </span></p>
<section class="example-content" id="proof-content">
<p>We could say that <a class="reference internal" href="#equation-misspecified-models">(7.11)</a> gives a parameterization of alternative models expressed in terms of <span class="math notranslate nohighlight">\(m\)</span> or <span class="math notranslate nohighlight">\(\ell\)</span>. But since the divergence <a class="reference internal" href="#equation-eqn-minproblem105">(7.14)</a> is not expressed as a divergence in terms of priors over the parameter space, we then could not view preferences <a class="reference internal" href="#equation-eqn-minproblem105">(7.14)</a> as a special case of the robust Bayesian decision theory described in <a class="reference internal" href="#sec-notknowingprior1"><span class="std std-ref">section</span></a>. With potential misspecifications present, we have deliberately avoided imposing a baseline prior over <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.<a class="footnote-reference brackets" href="#divpref" id="id136" role="doc-noteref"><span class="fn-bracket">[</span>35<span class="fn-bracket">]</span></a>
Instead, each <span class="math notranslate nohighlight">\(m\)</span> induces an alternative <span id="id137">[]</span> roulette wheel. For reasons that will become clear in the next subsection, we think of <span class="math notranslate nohighlight">\(m\)</span>s as ways to introduce ambiguities about lotteries, disarming the “roulette wheel” analogy.</p>
</section>
</div><div class="proof remark admonition" id="remark-32">
<p class="admonition-title"><span class="caption-number">Remark 7.20 </span></p>
<section class="remark-content" id="proof-content">
<p>Preferences that use a relative entropy divergence to capture concerns about model misspecification are often referred to as “multiplier preferences.” Because of the different ways that we apply the language of decision theory, the preceding construction of multiplier preferences differs from constructions provided by <span id="id138">[]</span> and <span id="id139">[]</span>. Specifically, <span id="id140">[]</span> define the domain of their cost function to be probabilities over the state space. In our analysis, the state space is <span class="math notranslate nohighlight">\(\Theta\)</span>, which means that their application of variational preferences gives rise to the robust Bayesian approach in <a class="reference internal" href="#sec-notknowingprior1"><span class="std std-ref">section</span></a>.</p>
</section>
</div></section>
</section>
<section id="a-misspecified-likelihood-function">
<span id="misspecified-likelihood"></span><h2><span class="section-number">7.8. </span>A misspecified likelihood function<a class="headerlink" href="#a-misspecified-likelihood-function" title="Link to this heading">#</a></h2>
<p>We now propose a generalization of the previous approach by starting from a parameterized family of probabilities <span class="math notranslate nohighlight">\( \tau(w \mid \theta)\)</span> and prior probability measure <span class="math notranslate nohighlight">\(\pi\)</span>. Typically, a family of parameterized family of probability models is specified so that each model is absolutely continuous with respect to an underlying measure, a condition required to apply likelihood-based methods. Consider relative densities <span class="math notranslate nohighlight">\({\hat m}\)</span> that for each <span class="math notranslate nohighlight">\(\theta\)</span> have been rescaled so that</p>
<div class="math notranslate nohighlight" id="equation-rel-likelihood-set">
<span class="eqno">(7.20)<a class="headerlink" href="#equation-rel-likelihood-set" title="Link to this equation">#</a></span>\[\int_W {\hat m}(w \mid \theta) \tau (w \mid \theta) d\upsilon(w) = 1.\]</div>
<p>To acknowledge misspecification of a model implied by parameter <span class="math notranslate nohighlight">\(\theta\)</span>, let  <span class="math notranslate nohighlight">\({\hat m}(w \mid  \theta)\)</span>  represent an “unstructured” relative perturbation with a parameterized family of densities:</p>
<div class="math notranslate nohighlight">
\[{\hat \ell}( w \mid \theta) = {\hat m}(w \mid  \theta) \tau( w \mid \theta)\]</div>
<p>where <span class="math notranslate nohighlight">\({\hat \ell}(\cdot \mid \theta) \in {\mathcal L}\)</span> for each <span class="math notranslate nohighlight">\(\theta \in \Theta.\)</span> With this in mind, let <span class="math notranslate nohighlight">\({\widehat {\mathcal M}}\)</span> be the space of admissible relative densities <span class="math notranslate nohighlight">\({\hat m}(w \mid \theta)\)</span> associated with model <span class="math notranslate nohighlight">\(\theta\)</span> for each <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>. The pair <span class="math notranslate nohighlight">\(({\hat m}, \theta)\)</span> implies a probability distribution represented as</p>
<div class="math notranslate nohighlight">
\[{\hat m}(w \mid \theta) \tau(w \mid \theta) d\upsilon(w)\]</div>
<p>over <span class="math notranslate nohighlight">\(W\)</span> conditioned on <span class="math notranslate nohighlight">\(\theta\)</span>. When <span class="math notranslate nohighlight">\({\hat m}\)</span> is not identically one, we view this as a misspecified likelihood function. Uncertainty about the nature of this misspecification induces corresponding uncertainty in the induced distribution,  or the lottery in the language of decision theory.</p>
<p>Preferences that acknowledge this form of model misspecification are ordered by solutions to</p>
<div class="math notranslate nohighlight" id="equation-eqn-minproblem108">
<span class="eqno">(7.21)<a class="headerlink" href="#equation-eqn-minproblem108" title="Link to this equation">#</a></span>\[\min_{{\hat m}  \in {\widehat {\mathcal M}}} \left( \int_W u[\gamma(w)] {\hat m}(w \mid \theta) \tau(w \mid \theta) d\upsilon(w)   + \xi \int_W \phi[{\hat m}(w \mid \theta)] \tau(w \mid \theta) d \upsilon(w) \right) d\pi_o(\theta)   ,\]</div>
<div class="proof remark admonition" id="remark-33">
<p class="admonition-title"><span class="caption-number">Remark 7.21 </span></p>
<section class="remark-content" id="proof-content">
<p>Please remember that we have left dependencies of <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(\gamma\)</span> on <span class="math notranslate nohighlight">\(\delta\)</span> implicit. Consequently, constraint <a class="reference internal" href="#equation-rel-likelihood-set">(7.20)</a> holds for each <span class="math notranslate nohighlight">\(\delta\in\Delta\)</span>, where <span class="math notranslate nohighlight">\(\tau\)</span> depends implicitly on <span class="math notranslate nohighlight">\(\delta.\)</span></p>
</section>
</div><div class="proof remark admonition" id="remark-34">
<p class="admonition-title"><span class="caption-number">Remark 7.22 </span></p>
<section class="remark-content" id="proof-content">
<p>Another approach would be to use the baseline prior to construct:</p>
<div class="math notranslate nohighlight">
\[\int_\Theta \tau(w \mid \theta) d \pi_o(\theta)\]</div>
<p>and treat this as the baseline model of <a class="reference internal" href="#sec-robustnesstypesof"><span class="std std-ref">section</span></a>; this would correspond to a predictive distribution provided that learning is not formally incorporated into the analysis or that the “prior” <span class="math notranslate nohighlight">\(d \pi_o\)</span> has already conditioned on what has been learned from available data.<a class="footnote-reference brackets" href="#chamberlain2020" id="id141" role="doc-noteref"><span class="fn-bracket">[</span>36<span class="fn-bracket">]</span></a></p>
</section>
</div></section>
<section id="robustness-reconsidered">
<span id="sec-robustnesstypesof"></span><h2><span class="section-number">7.9. </span>Robustness reconsidered<a class="headerlink" href="#robustness-reconsidered" title="Link to this heading">#</a></h2>
<p>It is useful to compare two approaches to robustness that we have taken. The subsection <a class="reference internal" href="#sec-robex1"><span class="std std-ref">Robust preferences</span></a> decision maker starts with a baseline prior over parameter vectors and considers consequences of misspecifying that prior. This decision maker takes as given the parameterized family of densities <span class="math notranslate nohighlight">\(\tau( w \mid \theta)\)</span> for <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>. In contrast, the <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">section</span></a> decision maker searches over the entire space <span class="math notranslate nohighlight">\(\widehat {\mathcal M}\)</span>, subject to a penalty on a statistical divergence from a baseline parameterized family of models. This decision maker considers only the baseline prior distribution.</p>
<p>Our setup allows the parameter space to be infinite dimensional. Consider a prior <span class="math notranslate nohighlight">\(\pi_o\)</span> that is consistent with a Bayesian approach to “nonparametric” estimation and inference. Since <span class="math notranslate nohighlight">\(\tau(\cdot \mid \theta)\)</span> can be viewed as a mapping from <span class="math notranslate nohighlight">\(\Theta\)</span> into <span class="math notranslate nohighlight">\({\mathcal L}\)</span>, a prior distribution <span class="math notranslate nohighlight">\(\pi_o\)</span> over <span class="math notranslate nohighlight">\(\Theta\)</span> implies a corresponding distribution over <span class="math notranslate nohighlight">\({\mathcal L}\)</span>. This procedure necessarily assigns prior probability zero to a substantial portion of the space <span class="math notranslate nohighlight">\({\mathcal L}\)</span>. Specifying a prior over the infinite dimensional space <span class="math notranslate nohighlight">\({\mathcal L}\)</span> brings challenges associated with all nonparametric methods, including “nonparametric Bayesian” methods that must assign probability one to what is called a “meager set.”<a class="footnote-reference brackets" href="#meagerset" id="id142" role="doc-noteref"><span class="fn-bracket">[</span>37<span class="fn-bracket">]</span></a> A meager set is defined topologically as a countable union of nowhere dense sets and is arguably small within an infinite-dimensional space. This conclusion carries over to situations with families of priors that are absolutely continuous with respect to a baseline prior, as we have here. To us, prior robustness of this form is interesting, although it is distinct from robustness to potential likelihood misspecifications. Indeed, the <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">section</span></a> decision maker who is concerned about model misspecification does not restrict himself to priors that are absolutely continuous with respect to a baseline prior because doing so would exclude many probability distributions he is concerned about.</p>
<p>The distinct ways in which the <a class="reference internal" href="#sec-nonknowingprior"><span class="std std-ref">section</span></a> and <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">section</span></a> formulations use statistical discrepancies lead to substantial differences in the associated variational preferences, namely, representation <a class="reference internal" href="#equation-eqn-minproblem106">(7.4)</a> or <a class="reference internal" href="#equation-eqn-minproblem107">(7.10)</a> for the <a class="reference internal" href="#sec-nonknowingprior"><span class="std std-ref">section</span></a> way of prior ambiguity and representation <a class="reference internal" href="#equation-eqn-minproblem108">(7.21)</a> way of ambiguity about the parameterized family of densities, <span class="math notranslate nohighlight">\(\tau( \cdot \mid \theta)\)</span>.</p>
</section>
<section id="two-examples">
<span id="sec-example"></span><h2><span class="section-number">7.10. </span>Two examples<a class="headerlink" href="#two-examples" title="Link to this heading">#</a></h2>
<p>It is instructive to apply the distinct approaches of <a class="reference internal" href="#sec-nonknowingprior"><span class="std std-ref">sections</span></a> and <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">section</span></a> to simple examples. The first example gives a simple illustration of preference inputs into robust control problems, and the second one explores a forecasting problem.</p>
<section id="robust-preferences">
<span id="sec-robex1"></span><h3><span class="section-number">7.10.1. </span>Robust preferences<a class="headerlink" href="#robust-preferences" title="Link to this heading">#</a></h3>
<p>Assume the following constituents:</p>
<ul class="simple">
<li><p>Baseline model is <span class="math notranslate nohighlight">\(\tau_o(w) \sim \text{Normal} (\mu_o, \sigma_o^2)\)</span></p></li>
<li><p>Alternative structured models <span class="math notranslate nohighlight">\(\tau(w \mid \theta_i) \sim \text{Normal} (\mu_i, \sigma_i^2), i = 1, \ldots, k\)</span>, where potential parameter values (states) are <span class="math notranslate nohighlight">\(\theta_i = (\mu_i, \sigma_i)\)</span> and parameter space <span class="math notranslate nohighlight">\(\Theta = \{\theta_i : i=1,2, \ldots, k\}.\)</span>. The baseline model can be one of these <span class="math notranslate nohighlight">\(k\)</span> models.</p></li>
<li><p>Baseline prior over structured models is a uniform distribution <span class="math notranslate nohighlight">\(\pi_o(\theta_i) = \frac{1}{k}, i = 1, \ldots, k.\)</span></p></li>
<li><p>Prize is the induced distribution of <span class="math notranslate nohighlight">\(c(w) = \gamma(w).\)</span></p></li>
<li><p>Utility function is <span class="math notranslate nohighlight">\(u[c(w)] = \log [c(w)]\)</span>, where <span class="math notranslate nohighlight">\(c(w)\)</span> is consumption</p></li>
<li><p>Prize rule is <span class="math notranslate nohighlight">\(\gamma(w) = \exp(\gamma_0 + \gamma_1 w)\)</span></p></li>
</ul>
<p>To obtain an alternative prior <span class="math notranslate nohighlight">\(\pi_i\)</span> for <span class="math notranslate nohighlight">\(i=1, \ldots, k\)</span>, we set <span class="math notranslate nohighlight">\(n_i = k \pi_i\)</span> so that the product of <span class="math notranslate nohighlight">\(n_i\)</span> times the baseline prior is:</p>
<div class="math notranslate nohighlight">
\[\frac{n_i}{k} = \pi_i.\]</div>
<p>The expected utility conditioned on parameter vector <span class="math notranslate nohighlight">\(\theta_i\)</span> is</p>
<div class="math notranslate nohighlight">
\[\int_{W} u[\exp (\gamma_0 + \gamma_1 w)] \tau(w | \theta)d\upsilon(w) = \gamma_0 + \gamma_1 \mu_i,\]</div>
<p>and a statistical divergence applied to alternative priors is</p>
<div class="math notranslate nohighlight">
\[{\frac{1}{k}} \sum_{i=1}^k \phi(k \pi_i) .\]</div>
<p>A <a class="reference internal" href="#sec-notknowingprior1"><span class="std std-ref">subsection</span></a> decision maker with variational preferences orders prize rules <span class="math notranslate nohighlight">\(\gamma(w) = \exp(\gamma_0 + \gamma_1 w)\)</span> according to</p>
<div class="math notranslate nohighlight">
\[\min_{\pi_i\ge 0, \sum_{i=1}^k \pi_i = 1} \gamma_0 + \gamma_1 \sum_{i=1}^k \pi_i \mu_i +
{\frac{\xi}{k}}  \sum_{i=1}^k \phi(k \pi_i) .\]</div>
<p>For a relative entropy divergence, prize rules are ordered by</p>
<div class="math notranslate nohighlight">
\[-\xi \log \sum_{i=1}^k \left({\frac{1}{k}}\right)  \exp\left[-{\frac{1}{\xi}} \left(\gamma_0 + \gamma_1 \mu_i \right) \right]
= \gamma_0 -\xi \log \sum_{i=1}^k \left({\frac{1}{k}}\right) \exp\left(-{\frac{\gamma_1\mu_i}{\xi}}\right),\]</div>
<p>and the associated minimizing <span class="math notranslate nohighlight">\(\pi_i\)</span> is</p>
<div class="math notranslate nohighlight">
\[{\frac{\exp\left(-{\frac{\gamma_1 \mu_i}{\xi}}\right)}{\sum_{i=1}^k \exp\left(-{\frac{\gamma_1 \mu_i}{\xi}}\right)}}.\]</div>
<p>A <a class="reference internal" href="#sec-nonknowingprior2"><span class="std std-ref">subsection</span></a> decision maker, in effect, chooses the multiplier <span class="math notranslate nohighlight">\(\xi\)</span> to hit a relative entropy constraint on the prior.</p>
<p>A criterion that expresses robustness to prior misspecification with a relative entropy divergence ranks prizes as either</p>
<div class="math notranslate nohighlight">
\[-\xi \log \sum_{i=1}^k \left(\frac{1}{k}\right) \exp\left[-\frac{1}{\xi} \left(\gamma_0 + \gamma_1 \mu_i \right)\right],\]</div>
<p>or,</p>
<div class="math notranslate nohighlight">
\[\max _\xi -\xi \log \sum_{i=1}^k \left({\frac{1}{k}}\right) \exp\left[-\frac{1}{\xi} \left(\gamma_0 + \gamma_1 \mu_i \right)\right] - \xi \kappa\]</div>
<p>When we use relative entropy as a statistical divergence, variational preferences for a <a class="reference internal" href="#sec-notknowingmodel"><span class="std std-ref">subsection</span></a> decision maker are ordered by</p>
<div class="math notranslate nohighlight">
\[\gamma_0 + \gamma_1 \mu_0 - {\frac{1}{2\xi}} (\sigma_0 \gamma_1)^2\]</div>
<p>Larger values of the positive scalar <span class="math notranslate nohighlight">\(\xi\)</span> call for smaller adjustments <span class="math notranslate nohighlight">\(- {\frac{1}{2\xi}} (\sigma_o \gamma_1)^2\)</span> of expected utility <span class="math notranslate nohighlight">\(\gamma_0 + \gamma_1 \mu_o\)</span> for concerns about misspecification of <span class="math notranslate nohighlight">\(\tau_o(w)d\upsilon(w)\)</span>.</p>
</section>
<section id="robust-forecasting">
<h3><span class="section-number">7.10.2. </span>Robust forecasting<a class="headerlink" href="#robust-forecasting" title="Link to this heading">#</a></h3>
<p>Consistent with Example <a class="reference internal" href="#remark:Ferguson">Example 7.3</a>, partition</p>
<div class="math notranslate nohighlight">
\[\begin{split}w = \begin{bmatrix} w_1 \\ w_2 \end{bmatrix},\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(w_1\)</span> is scalar outcome of a variable to be forecast and <span class="math notranslate nohighlight">\(w_2\)</span> constitutes data underlying a forecast. Assume that:</p>
<ul class="simple">
<li><p>The baseline model is <span class="math notranslate nohighlight">\(\tau_o(w)\)</span>.</p></li>
<li><p>Alternative structured models are <span class="math notranslate nohighlight">\(\tau(w \mid \theta)\)</span> for a parameter space <span class="math notranslate nohighlight">\(\Theta = \{\theta_i : i=1,2, \ldots, k\}.\)</span> The baseline model can be one of the <span class="math notranslate nohighlight">\(k\)</span> models.</p></li>
<li><p>The baseline prior over structured models is a uniform distribution <span class="math notranslate nohighlight">\(\pi_o(\theta_i) = \frac{1}{k}, i = 1, \ldots, k.\)</span></p></li>
<li><p>The prize is the induced distribution of the forecast error <span class="math notranslate nohighlight">\(w_1 - \delta(w_2)\)</span>, where <span class="math notranslate nohighlight">\(\delta\)</span> is the forecast rule.</p></li>
<li><p>The utility function is <span class="math notranslate nohighlight">\(-[w_1 - \delta(w_2)]^2.\)</span></p></li>
<li><p>The prize rule is <span class="math notranslate nohighlight">\(\gamma_\delta(w) = w_1 - \delta(w_2).\)</span></p></li>
</ul>
</section>
</section>
<section id="hybrid-models">
<span id="sec-hybrid"></span><h2><span class="section-number">7.11. </span>Hybrid models<a class="headerlink" href="#hybrid-models" title="Link to this heading">#</a></h2>
<p>We now use components described above as inputs into a representation of preferences that includes uncertainty about a prior to put over structured models as well as concerns about possible misspecifications of those structured models. We use probability perturbations in the form of alternative relative densities in <span class="math notranslate nohighlight">\({\widehat {\mathcal M}}\)</span> to capture uncertainty about models and probability perturbations in the form of alternative relative densities <span class="math notranslate nohighlight">\({\mathcal N}\)</span> to capture uncertainty about a prior over models.</p>
<p>Let <span class="math notranslate nohighlight">\(\pi_o(\theta)\)</span> is a baseline prior over <span class="math notranslate nohighlight">\(\theta\)</span>. To conduct a prior robustness analysis, consider alternative priors</p>
<div class="math notranslate nohighlight">
\[d \pi(\theta) = n(\theta) d \pi_o(\theta)\]</div>
<p>for <span class="math notranslate nohighlight">\(n \in {\mathcal N}.\)</span></p>
<p>Consider relative densities <span class="math notranslate nohighlight">\({\hat m}\)</span> that for each <span class="math notranslate nohighlight">\(\theta\)</span> have been rescaled so that</p>
<div class="math notranslate nohighlight">
\[\int_W {\hat m}(w \mid \theta) \tau(w \mid \theta) d\upsilon(w) = 1.\]</div>
<p>To acknowledge misspecification of a model implied by parameter <span class="math notranslate nohighlight">\(\theta\)</span>, let <span class="math notranslate nohighlight">\({\hat m}(w \mid \theta)\)</span> represent an “unstructured” perturbation of that model. With this in mind, let <span class="math notranslate nohighlight">\({\widehat {\mathcal M}}\)</span> be the space of admissible relative densities <span class="math notranslate nohighlight">\({\hat m}(w \mid \theta)\)</span> associated with model <span class="math notranslate nohighlight">\(\theta\)</span> for each <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>. We then consider a composite parameter <span class="math notranslate nohighlight">\(({\hat m}, \theta)\)</span> for <span class="math notranslate nohighlight">\({\hat m} \in {\widehat {\mathcal M}}\)</span> and <span class="math notranslate nohighlight">\(\theta \in \Theta.\)</span> The composite parameter <span class="math notranslate nohighlight">\(({\hat m}, \theta)\)</span> implies a distribution <span class="math notranslate nohighlight">\({\hat m}(w \mid \theta) \ell(w \mid \theta) \tau(w \mid \theta)d\upsilon(w)\)</span> over <span class="math notranslate nohighlight">\(W\)</span> conditioned on <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>To measure a statistical discrepancy that comes from applying <span class="math notranslate nohighlight">\(\hat m\)</span> to the density <span class="math notranslate nohighlight">\(\ell\)</span> of <span class="math notranslate nohighlight">\(w\)</span> conditioned on <span class="math notranslate nohighlight">\(\theta\)</span> and by applying <span class="math notranslate nohighlight">\(n\)</span> to the baseline prior over <span class="math notranslate nohighlight">\(\theta\)</span>, we first acknowledge possible misspecification of each of the <span class="math notranslate nohighlight">\(\theta\)</span> models by computing:</p>
<div class="math notranslate nohighlight">
\[{\mathbb T}_1[\gamma]( \theta)  = \min_{{\hat m} \in {\widehat {\mathcal M}}} \int_W \left(  u[\gamma(w)]{\hat m}(w  \mid \theta)  + \xi_1 \phi_1\left[ {\hat m}(w \mid \theta)  \right] \right) \ell( w \mid \theta)  \tau(w \mid \theta)d\upsilon(w)\]</div>
<p>The <span class="math notranslate nohighlight">\({\mathbb T}_1\)</span> operator maps prize rules <span class="math notranslate nohighlight">\(\gamma\)</span> into functions of <span class="math notranslate nohighlight">\(\theta\)</span>. We use this for both hybrid approaches.</p>
<section id="first-hybrid-model">
<span id="hybrid-one"></span><h3><span class="section-number">7.11.1. </span>First hybrid model<a class="headerlink" href="#first-hybrid-model" title="Link to this heading">#</a></h3>
<p>We can rank alternative prize rules <span class="math notranslate nohighlight">\(\gamma\)</span> by including the following adjustment for possible misspecification of the baseline prior <span class="math notranslate nohighlight">\(\pi_o\)</span>:</p>
<div class="math notranslate nohighlight">
\[{\mathbb T}_2 \circ {\mathbb T}_1[\gamma] = \min_{ n \in {\mathcal N}} \int_\Theta \left({\mathbb T}_1[ \gamma]( \theta) n(\theta) + \xi_2 \phi_2[n(\theta)] \right) d \pi_o(\theta).\]</div>
<p>Here <span class="math notranslate nohighlight">\(\phi_1\)</span> and <span class="math notranslate nohighlight">\(\phi_2\)</span> are possibly distinct convex functions with properties like the ones that we imposed on <span class="math notranslate nohighlight">\(\phi\)</span> in <a class="reference internal" href="#sec-statdivergasc"><span class="std std-ref">section</span></a>.</p>
<p>Such a two-step adjustment for possible misspecification leads to an implied one-step variational representation with a composite divergence that we can define in the following way. For <span class="math notranslate nohighlight">\({\hat m} \in \widehat{\mathcal M}\)</span> and <span class="math notranslate nohighlight">\(n \in {\mathcal N}\)</span>, form a composite scaled statistical discrepancy</p>
<div class="math notranslate nohighlight" id="equation-double-penalty">
<span class="eqno">(7.22)<a class="headerlink" href="#equation-double-penalty" title="Link to this equation">#</a></span>\[{\widehat  D}( {\hat m}, n \mid \tau, \pi_o) = \xi_1 \int_\Theta \left(  \int_W \phi_1\left[ {\hat m}(w \mid \theta) \right] \tau(w \mid \theta)  d\upsilon(\theta) \right) n(\theta) d\pi_o(\theta)  + \xi_2 \int_\Theta \phi_2 \left[ n(\theta) \right] d \pi_o(\theta)\]</div>
<p>for <span class="math notranslate nohighlight">\(\xi_1 &gt; 0, \xi_2 &gt; 0\)</span>. Then variational preferences are ordered by</p>
<div class="math notranslate nohighlight">
\[\min_{{\hat m} \in {\widehat {\mathcal M}}, n \in {\mathcal N} } \int_\Theta \left(\int_W u[\gamma(w)] {\hat m}(w \mid \theta)  \tau( w \mid \theta) d\upsilon(w) \right)  n(\theta) d\pi_o(\theta) + {\widehat D}({\hat m}, n \mid \tau, \pi_o)\]</div>
<p>In <a class="reference internal" href="#app:convexity"><span class="xref myst">Appendix</span></a> we establish that divergence <a class="reference internal" href="#equation-double-penalty">(7.22)</a> is convex over the family of probability measures that concerns the decision maker.</p>
<div class="proof remark admonition" id="remark-35">
<p class="admonition-title"><span class="caption-number">Remark 7.23 </span></p>
<section class="remark-content" id="proof-content">
<p>As noted earlier, <span id="id143">[]</span> posit a state space that includes parameters but also can include what we call repercussions. Thus, think of the state as the pair <span class="math notranslate nohighlight">\((w,\theta)\)</span>. In this setting, one could apply a statistical divergence to a joint distribution over possible realizations of <span class="math notranslate nohighlight">\((w,\theta)\)</span>. Since the joint distribution can be factored into the product of a distribution over <span class="math notranslate nohighlight">\(W\)</span> conditioned on <span class="math notranslate nohighlight">\(\theta\)</span> and a marginal distribution over <span class="math notranslate nohighlight">\(\Theta\)</span>, such an approach can capture robustness in the specification of both <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(\pi_o\)</span>, albeit in a very specific way. For instance, for the relative entropy divergence, this results in the joint divergence measure:</p>
<div class="math notranslate nohighlight">
\[{\widehat D}( {\hat m}, n \mid \tau, \pi_o ) =  \xi_1 \int_\Theta \left[  \int_W {\hat m}(w \mid \theta) \log{\hat m}(w \mid \theta)   \tau(w \mid \theta) d\upsilon(w) \right] n(\theta) d\pi_o(\theta)  + \xi_2
\int_\Theta n(\theta) \log n(\theta)d \pi_o(\theta)\]</div>
<p>for <span class="math notranslate nohighlight">\(\xi_1 = \xi_2\)</span>.</p>
<p>In earlier work, we have demonstrated important limits to such an approach in dynamic settings.<a class="footnote-reference brackets" href="#limits-dynamic-settings" id="id144" role="doc-noteref"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></a> As we have shown here, we find both robustness to model misspecification and robustness to prior specification to be interesting in their own rights and see little reason to group them into a single <span class="math notranslate nohighlight">\(\phi\)</span> divergence.</p>
</section>
</div></section>
</section>
<section id="second-hybrid-model">
<span id="hybrid-two"></span><h2><span class="section-number">7.12. </span>Second hybrid model<a class="headerlink" href="#second-hybrid-model" title="Link to this heading">#</a></h2>
<p>As an alternative to the <a class="reference internal" href="#hybrid-one"><span class="std std-ref">approach</span></a> approach, we could instead constrain the set of priors to satisfy:</p>
<div class="math notranslate nohighlight" id="equation-kappa-constraint">
<span class="eqno">(7.23)<a class="headerlink" href="#equation-kappa-constraint" title="Link to this equation">#</a></span>\[\int_\Theta \phi_2[n(\theta)]  d\pi_o(\theta) \le \kappa\]</div>
<p>so that a decision maker’s preferences over prize rules <span class="math notranslate nohighlight">\(\gamma\)</span> would be ordered by:</p>
<div class="math notranslate nohighlight" id="equation-cvmm103">
<span class="eqno">(7.24)<a class="headerlink" href="#equation-cvmm103" title="Link to this equation">#</a></span>\[\min_{n \in {\mathcal N}} \int_\Theta {\mathbb T}_1\left[ \gamma\right](\theta) n(\theta) d\pi_o(\theta),\]</div>
<p>where minimization is subject to <a class="reference internal" href="#equation-kappa-constraint">(7.23)</a>.</p>
<p>As in <span id="id145">[]</span>, preferences ordered by <a class="reference internal" href="#equation-cvmm103">(7.24)</a> subject to constraint <a class="reference internal" href="#equation-kappa-constraint">(7.23)</a> can be thought of as using a divergence between a potentially misspecified probability distribution and a set of predictive distributions that have been constructed from priors over a parameterized family of probability densities within the constrained set $\Theta`.<a class="footnote-reference brackets" href="#cerreia-2021-axiomatic" id="id146" role="doc-noteref"><span class="fn-bracket">[</span>39<span class="fn-bracket">]</span></a></p>
<p>Notice how the first term in discrepancy measure <a class="reference internal" href="#equation-double-penalty">(7.22)</a> uses a prior <span class="math notranslate nohighlight">\(n d\pi_o\)</span> to construct a weighted averaged over <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span> of the following conditioned-on-<span class="math notranslate nohighlight">\(\theta\)</span> misspecification measure
$<span class="math notranslate nohighlight">\(
\xi_1 \left(  \int_W \phi_1\left[ {\hat m}(w \mid \theta) \right] \tau(w \mid \theta) d \upsilon(w) \right).
\)</span><span class="math notranslate nohighlight">\(
The objective in problem {eq}`CVMM103` is to make the divergence between a given distribution and each of the parameterized probability models small on average by minimizing over how to weight divergence measures indexed by \)</span>\theta<span class="math notranslate nohighlight">\( subject to the constraint that \)</span>\pi \in \Pi<span class="math notranslate nohighlight">\(.[^structured-models] Equivalently, in place of {eq}`double_penalty`, this approach uses cost function
\)</span><span class="math notranslate nohighlight">\(
{\widetilde D} ( {\hat m} \mid \tau, \pi_o) = \xi_1 \min_{n \in {\mathcal N}} \int_{\Theta} \left(  \int_W \phi_1\left[ {\hat m}(w \mid \theta) \right] d\ell(w \mid \theta) \right) n(\theta) d\pi_o(\theta) .
\)</span>$</p>
<div class="proof remark admonition" id="remark-36">
<p class="admonition-title"><span class="caption-number">Remark 7.24 </span></p>
<section class="remark-content" id="proof-content">
<p>It is possible to simplify computations by using dual versions of the hybrid approaches delineated in subsections <a class="reference internal" href="#hybrid-one"><span class="std std-ref">hybrid approaches one</span></a> and <a class="reference internal" href="#hybrid-two"><span class="std std-ref">hybrid approaches two</span></a>. Such formulations closely parallel those described in our discussions of robust prior analysis and potential model misspecification in remarks <a class="reference internal" href="#rem:dual1">Remark 7.15</a>, <a class="reference internal" href="#rem:dual2">Remark 7.16</a>, and <a class="reference internal" href="#rem:dual3">Remark 7.17</a>.</p>
</section>
</div></section>
<section id="dynamic-extension">
<span id="sec-dynext"></span><h2><span class="section-number">7.13. </span>Dynamic extension<a class="headerlink" href="#dynamic-extension" title="Link to this heading">#</a></h2>
<p>Although a complete treatment of dynamics deserves its own paper, here we describe briefly how to extend the familiar recursive utility specification of <span id="id147">[]</span> and <span id="id148">[]</span> to accommodate our two robustness concerns to an intertemporal environment. We accomplish this by using conditional counterparts to the preceding analysis to explore consequences of mis-specifying Markov transition dynamics and prior distributions over unknown parameters. The resulting preferences have a recursive structure. There is an inherent tension between dynamic consistency and statistical consistency in these preferences that we discuss elsewhere (<span id="id149">[]</span>).</p>
<section id="a-deterministic-warm-up">
<h3><span class="section-number">7.13.1. </span>A deterministic warm up<a class="headerlink" href="#a-deterministic-warm-up" title="Link to this heading">#</a></h3>
<p>We represent preferences using recursions that apply to continuation values. Abstracting from uncertainty, a commonly used intertemporal preference specification is captured by the value recursion:</p>
<div class="math notranslate nohighlight">
\[V_t = \left[(1 - \beta) \left(C_t\right)^{1-\rho} + \beta \left( V_{t+1} \right)^{1 - \rho} \right]^{\frac 1 {1-\rho}}\]</div>
<p>for <span class="math notranslate nohighlight">\(0&lt;\beta&lt;1\)</span> and <span class="math notranslate nohighlight">\(\rho&gt; 0\)</span>. <span class="math notranslate nohighlight">\(V_t\)</span> is the date <span class="math notranslate nohighlight">\(t\)</span> continuation value and <span class="math notranslate nohighlight">\(C_t\)</span> is date <span class="math notranslate nohighlight">\(t\)</span> consumption. The parameter <span class="math notranslate nohighlight">\(\beta\)</span> governs discounting and the parameter <span class="math notranslate nohighlight">\(\rho\)</span> is the reciprocal of the intertemporal elasticity of substitution. Applying the recursion over an infinite horizon leads to the following expression for the continuation value:</p>
<div class="math notranslate nohighlight">
\[V_t = \left[ (1-\beta) \sum_{j=0}^\infty \beta^j \left(C_{t+j} \right)^{1-\rho}\right]^{\frac 1 {1-\rho}}\]</div>
<p>Since the logarithmic transformation is increasing, we can use the following recursion in the logarithm <span class="math notranslate nohighlight">\({\widehat V}_t\)</span> of the continuation value to represent preferences:</p>
<div class="math notranslate nohighlight">
\[{\widehat V}_t = \frac 1 {1-\rho} \log 
\left[(1 - \beta) \exp\left[(1-\rho){\widehat C}_t\right] + \beta \exp \left[(1-\rho){\widehat V}_{t+1} \right] \right] \]</div>
<p>where <span class="math notranslate nohighlight">\({\widehat C}_t\)</span> is the logarithm of consumption.</p>
</section>
<section id="introducing-uncertainty">
<h3><span class="section-number">7.13.2. </span>Introducing uncertainty<a class="headerlink" href="#introducing-uncertainty" title="Link to this heading">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\({\mathfrak A}_t\)</span> denote a sigma algebra capturing information available to the decision maker at date <span class="math notranslate nohighlight">\(t\)</span>. Think of the repercussion <span class="math notranslate nohighlight">\(W_{t+1}\)</span> as generating new information relative to <span class="math notranslate nohighlight">\({\mathfrak A}_t\)</span> that is pertinent for constructing <span class="math notranslate nohighlight">\({\mathfrak A}_{t+1}\)</span>. Think of the continuation value, <span class="math notranslate nohighlight">\({\widehat V}_{t+1}\)</span> as the counterpart to a prize that can depend on a repercussion vector <span class="math notranslate nohighlight">\(W_{t+1}.\)</span> A continuation value <span class="math notranslate nohighlight">\({\widehat V}_{t+1}\)</span> is constrained to be measurable with respect to <span class="math notranslate nohighlight">\({\mathfrak A}_{t+1}\)</span>. We explore model misspecification by using nonnegative random variables <span class="math notranslate nohighlight">\(M_{t+1}\)</span> that are <span class="math notranslate nohighlight">\({\mathfrak A}_{t+1}\)</span> measurable and satisfy <span class="math notranslate nohighlight">\({\mathbb E} \left( M_{t+1} \mid {\mathfrak A}_t, \theta\right) = 1.\)</span> We explore prior/posterior misspecification using nonnegative random variables <span class="math notranslate nohighlight">\(N_{t}\)</span> that are measurable with respect <span class="math notranslate nohighlight">\({\mathfrak A}_t\)</span> augmented by knowledge of <span class="math notranslate nohighlight">\(\theta\)</span> and satisfy <span class="math notranslate nohighlight">\({\mathbb E}\left( N_t \mid {\mathfrak A}_t \right) = 1.\)</span></p>
<p>To accommodate robustness concerns in decision making, define preferences with three recursions for updating the continuation value</p>
<div class="math notranslate nohighlight" id="equation-three-recur">
<span class="eqno">(7.25)<a class="headerlink" href="#equation-three-recur" title="Link to this equation">#</a></span>\[\begin{split}\begin{align}
{\widehat V}_t &amp;= \frac 1 {1-\rho} \log 
\left[(1 - \beta) \exp\left[(1-\rho){\widehat C}_t\right] + \beta \exp \left[(1-\rho){\overline R}_t \right] \right] \\
{\widehat R}_t &amp; = \min_{M_{t+1}\ge 0, {\mathbb E} \left(M_{t+1} \vert {\mathfrak A}_t, \theta \right) = 1}  
{\mathbb E} \left[ {M_{t+1} \widehat V}_{t+1} + \xi_1 \phi_m \left(M_{t+1} \right) \mid {\mathfrak A}_t, \theta \right]  \\
{\overline R}_t &amp; = \min_{N_{t}\ge 0, {\mathbb E} \left(N_{t} \vert {\mathfrak A}_t \right) = 1}  
{\mathbb E} \left[ N_{t} {\widehat R}_{t} + \xi_2 \phi_n \left(N_{t} \right) \mid {\mathfrak A}_t \right] 
\end{align}\end{split}\]</div>
<p>The second and third recursions provide a dynamic counterpart to the approach in <a class="reference internal" href="#sec:hybrid_one"><span class="xref myst">section hybrid_one</span></a>. Replacing the third recursion in <a class="reference internal" href="#equation-three-recur">(7.25)</a> with a constrained counterpart gives a dynamic counterpart to the approach in <a class="reference internal" href="#sec:hybrid_two"><span class="xref myst">section hybrid_two</span></a>.<a class="footnote-reference brackets" href="#footnotealtapproach" id="id150" role="doc-noteref"><span class="fn-bracket">[</span>40<span class="fn-bracket">]</span></a></p>
</section>
<section id="shadow-valuation">
<h3><span class="section-number">7.13.3. </span>Shadow valuation<a class="headerlink" href="#shadow-valuation" title="Link to this heading">#</a></h3>
<p>Following <span id="id151">[]</span> and others, we can use stochastic discount factors to value assets having an uncertain one-period ahead payoff. We deduce shadow values by computing a one-period intertemporal marginal rate of substitution. Of particular interest to us are contributions that our model-misspecification operator
<span class="math notranslate nohighlight">\({\widehat R}_t\)</span> and our prior-robustness operator ${\overline R}_t` make to this shadow value.</p>
<p>A contribution to the shadow value that comes from the first recursion in <a class="reference internal" href="#equation-three-recur">(7.25)</a> looks at marginal contributions in adjacent time periods.<br />
Date <span class="math notranslate nohighlight">\(t\)</span> marginal contributions of <span class="math notranslate nohighlight">\(C_t\)</span> and <span class="math notranslate nohighlight">\({\overline R}_t\)</span> to the current period continuation value are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
MC_t &amp; = 
(1-\beta) \exp\left[ (\rho - 1) {\widehat V}_t \right] 
\left(C_t\right)^{-\rho} \\
M{\overline R}_t &amp; = \beta \exp\left[ (\rho - 1) {\widehat V}_t \right] \exp\left[ (1-\rho) {\overline R}_t \right] .
\end{align*}\end{split}\]</div>
<p>Since our aim is to infer the one-period intertemporal marginal rate of substitution, we look across adjacent time periods using consumption at each date as a numeraire:</p>
<div class="math notranslate nohighlight">
\[\frac {{MC_{t+1} M{\overline R}_t }}{MC_t} = \beta \left( \frac {C_{t+1}}{C_t} \right)^{-\rho} \exp\left[(\rho - 1) \left( {\widehat V}_{t+1} - {\overline R}_t \right) \right]. \]</div>
<p>This would give the deterministic intertemporal marginal rate of substitution if we were to substitute <span class="math notranslate nohighlight">\({\widehat V}_{t+1}\)</span> for <span class="math notranslate nohighlight">\({\overline R}_{t}\)</span> in this expression.</p>
<p>For the uncertainty adjustments, we deduce the marginal contributions by applying the Envelope Theorem to the minimization problems in the second and third recursions in <a class="reference internal" href="#equation-three-recur">(7.25)</a>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M{\widehat V}_{t+1} = M_{t+1}^*\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(M {\widehat R}_t = N_{t}^*\)</span></p></li>
</ul>
<p>Thus, the minimizing changes in probabilities contribute directly to the shadow valuation. The resulting increment to a stochastic discount factor process is:</p>
<div class="math notranslate nohighlight">
\[\frac {S_{t+1}}{S_t} = \beta \left( \frac {C_{t+1}}{C_t} \right)^{-\rho} \exp\left[(\rho - 1) \left( {\widehat V}_{t+1} - {\overline R}_{t} \right) \right]M_{t+1}^*N_{t}^*\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M_{t+1}^*\)</span> adjusts for possible model misspecification</p></li>
<li><p><span class="math notranslate nohighlight">\(N_{t}^*\)</span> adjusts for possible prior misspecification</p></li>
</ul>
</section>
</section>
<section id="an-approach-to-uncertainty-quantification">
<span id="sec-uncert-quant"></span><h2><span class="section-number">7.14. </span>An approach to uncertainty quantification<a class="headerlink" href="#an-approach-to-uncertainty-quantification" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="#sec-hybrid"><span class="std std-ref">Subsection</span></a> posed a minimum problem that comes from variational preferences with a two-parameter cost function that we constructed from two statistical divergences. Along with a robust prize rule, the minimum problem produces a worst-case probability distribution that rationalizes that prize rule. Strictly speaking, the decision theory tells us that particular values of cost function parameters <span class="math notranslate nohighlight">\((\xi_1, \xi_2)\)</span> express a decision maker’s concerns about uncertainty, broadly conceived. In the spirit of <span id="id152">[]</span>, it can be enlightening to study how worst-case distributions depend on <span class="math notranslate nohighlight">\((\xi_1, \xi_2)\)</span>. The concluding paragraph of <span id="id153">[]</span> recommends exploring sensitivities with respect to a likelihood and with respect to a prior. Sensitivity of worst-case distributions to <span class="math notranslate nohighlight">\((\xi_1, \xi_2)\)</span> provides evidence about the forms of subjective uncertainty and potential model misspecification that <em>should</em> be of most concern. That can provide decision makers and outside analysts better understandings of the consequences of uncertainty aversion.</p>
<p>Motivated partly by a robust Bayesian approach, we have used decision theory to suggest a new approach to uncertainty quantification. By varying the aversion parameters <span class="math notranslate nohighlight">\((\xi_1, \xi_2),\)</span> we can trace out two-dimensional representations of prize rules and worst-case probabilities. A representation of worst-case probabilities includes both worst-case priors and a worst-case alteration to each member of a parametric family of models. A decision maker can explore alternative choices and associated expected utilities by studying how <span class="math notranslate nohighlight">\((\xi_1, \xi_2)\)</span> trace out a two-dimensional set of worst-case probabilities. In this way, we reduce potentially high-dimensional subjective uncertainties to a two-dimensional collection of alternative probability specifications that should most concern a decision maker along with accompanying robust prize rules for responding to those uncertainties.</p>
</section>
<section id="relation-to-statistical-learning">
<span id="sec-statlearning"></span><h2><span class="section-number">7.15. </span>Relation to statistical learning<a class="headerlink" href="#relation-to-statistical-learning" title="Link to this heading">#</a></h2>
<p>We briefly compare our approach to related analyses coming from statistical learning theory and, in particular, PAC (probably approximately correct) Bayesian analysis. See <span id="id154">[]</span> for a recent survey of PAC Bayesian methods and see <span id="id155">[]</span> and <span id="id156">[]</span>, among others, for fundamental contributions. While their formulations of a decision problem differ from ours, there are intriguing connections.</p>
<p>To understand some of the connections, partition a random vector, <span class="math notranslate nohighlight">\(Y\)</span>, with realization <span class="math notranslate nohighlight">\(y\)</span> as</p>
<div class="math notranslate nohighlight">
\[Y' :=  \begin{bmatrix} {Y_1}' &amp; {Y_2}' &amp;  {Y_2}' &amp; ... &amp; {Y_K}' \end{bmatrix},\]</div>
<p>and regard it as  “training data” for a machine learning method.<br />
For an objective function, construct an “empirical risk” criterion:</p>
<div class="math notranslate nohighlight">
\[{\widehat \Phi }(Y, \theta)  := {\frac 1 K} \sum_{k=1}^K  \Phi (Y_k, \theta) .\]</div>
<p>The object of interest <span class="math notranslate nohighlight">\(\theta\)</span> can be an element of a collection of functions.<br />
Define the population counterpart to <span class="math notranslate nohighlight">\({\widehat \Phi }(Y, \theta)\)</span> as</p>
<div class="math notranslate nohighlight">
\[{\overline \Phi} (\theta ),\]</div>
<p>the Law of Large Numbers limit of <span class="math notranslate nohighlight">\({\widehat \Phi }(W, \theta)\)</span> as <span class="math notranslate nohighlight">\(K \rightarrow \infty\)</span>. Suppose that an idealized target decision solves:</p>
<div class="math notranslate nohighlight">
\[\theta^* = \arg \min_{\theta \in {\Theta}}  {\overline{\Phi}} (\theta ).\]</div>
<p>This estimator appears in an extensive literature on <span class="math notranslate nohighlight">\(M\)</span> estimation; the idealized optimized decision <span class="math notranslate nohighlight">\(\theta^*\)</span> defines a parameter or decision of interest. In this setting, we use decisions and parameters interchangeably, in contrast to our formulation.</p>
<p>A common approach to M estimation is to solve the finite sample analog problem</p>
<div class="math notranslate nohighlight">
\[{\hat \theta} = \arg \min_{\theta \in \Theta} {\widehat \Phi }(Y, \theta) .\]</div>
<p>This approach struggles when the space <span class="math notranslate nohighlight">\(\Theta\)</span> is “large”, the typical case with machine learning methods that fit flexible functional forms with many parameters. More generally, statistical learning often seeks meaningful worst-case bounds of finite sample approximates to a solution of the population problem.</p>
<p>Motivated by concerns for applications when the space <span class="math notranslate nohighlight">\(\Theta\)</span> in standard M estimation is expansive, the PAC Bayesian approach proceeds differently. The approach seeks a probability distribution <span class="math notranslate nohighlight">\(\pi\)</span> over the space <span class="math notranslate nohighlight">\(\Theta\)</span> given the data <span class="math notranslate nohighlight">\(W\)</span>, rather than a single value, <span class="math notranslate nohighlight">\(\theta\)</span>. By analogy to Bayesian methods, such a distribution is referred to as a `generalized posterior.’ The approach imposes a baseline prior distribution <span class="math notranslate nohighlight">\(\pi_o\)</span> over the space <span class="math notranslate nohighlight">\(\Theta\)</span>, and considers generalized posteriors in a family:</p>
<div class="math notranslate nohighlight">
\[d \pi(\theta) = n(\theta) d\pi_o(\theta)\]</div>
<p>for <span class="math notranslate nohighlight">\(\int n d\pi_o = 1.\)</span></p>
<p>Instead of solving the finite sample M estimation problem, consider a family of problems:</p>
<div class="math notranslate nohighlight" id="equation-pac-problem">
<span class="eqno">(7.26)<a class="headerlink" href="#equation-pac-problem" title="Link to this equation">#</a></span>\[min_{n, \int n d\pi_o = 1}   \int_{{\Theta}} {\widehat \Phi }(Y, \theta) d \pi(\theta) + \xi \int_{\Theta} \log n(\theta) n(\theta) d \pi_o(\theta) \]</div>
<p>indexed by <span class="math notranslate nohighlight">\(\xi\)</span>. Applying the same mathematics we have used in previous sections, minimization brings exponential tilting:</p>
<div class="math notranslate nohighlight">
\[n^*(\theta) = \frac{ \exp \left[ - \frac 1 \xi  {\widehat \Phi }(Y, \theta)\right]}
{\int_\Theta  \exp \left[ - \frac 1 \xi  {\widehat \Phi }(Y, {\tilde \theta})\right] d \pi_o({\tilde \theta}) }\]</div>
<p>The Bayesian PAC uses this minimizer to construct an approximation to a minimizer of the underlying (infeasible) population problem.</p>
<p>Problem <a class="reference internal" href="#equation-pac-problem">(7.26)</a> provides a way to incorporate probabilistic restrictions into the M estimation problem. There are some interesting special cases. When <span class="math notranslate nohighlight">\( {\widehat \Phi }(W, \cdot)\)</span> is the negative of the log likelihood function and <span class="math notranslate nohighlight">\(\xi = 1\)</span>, we are led to a standard calculation of a Bayesian posterior. <span id="id157">[]</span>, <span id="id158">[]</span> and others propose and defend a `safe Bayesian framework’ by exploring other values of <span class="math notranslate nohighlight">\(\xi &gt; 1\)</span> based on robustness considerations. The Bayesian PAC approach studies alternative specifications of <span class="math notranslate nohighlight">\({\widehat \Phi }(W, \cdot)\)</span> based on more general loss functions. As in M-estimation more generally, this construction may embed some robustness concerns. When <span class="math notranslate nohighlight">\(\xi\)</span> tends to infinity the generalized posterior collapses to the prior distribution. When <span class="math notranslate nohighlight">\(\xi\)</span> tends to zero the prior becomes inconsequential, and the generalized posterior collapses to the solution the finite-sample M estimation solution. The penalty parameter <span class="math notranslate nohighlight">\(\xi\)</span> governs a tradeoff between the importance of the objective <span class="math notranslate nohighlight">\({\widehat \Phi }(Y, \cdot)\)</span> and the baseline prior <span class="math notranslate nohighlight">\(\pi_o\)</span>. The PAC-Bayesian literature discusses extensively the role of the parameter in approximation.</p>
<p>While our approach shares much mathematical structure with PAC-Bayesian methods, it differs in ways that are significant for applications. The M estimation formulation ties its decision problem directly to an underlying unknown “parameter” and contains no counterpart to the maximization steps that we use to represent uncertainty aversions. Furthermore, the PAC-Bayesian Problem <a class="reference internal" href="#equation-pac-problem">(7.26)</a> conditions on <span class="math notranslate nohighlight">\(W\)</span> and focuses exclusively on uncertainties about unknown states or parameters. Also, PAC-Bayesian methods use Problem <a class="reference internal" href="#equation-pac-problem">(7.26)</a> as a device to approximate a solution to an infeasible population problem, which is not a component of our analysis.</p>
<p>To elaborate more on the differences between PAC-Bayesian methods and our approach, we study decision problems in which parameters are not the objects of ultimate interest but instead are just intermediate “means to ends” of constructing decision rules for making choices of economics quantities that are robust to misspecifications. Rather than replacing a log-likelihood function with an M estimation objective and possibly down-weighting its importance, we introduce potential likelihood misspecifications explicitly; we also formally acknowledge possible misspecification of priors. By appropriately adjusting the divergence “cost” structure, our approach allows us to explore tradeoffs between concerns about misspecifications of likelihoods, on the one hand, and priors, on the other hand.</p>
</section>
<section id="concluding-remarks">
<span id="sec-conclude"></span><h2><span class="section-number">7.16. </span>Concluding remarks<a class="headerlink" href="#concluding-remarks" title="Link to this heading">#</a></h2>
<p>Except for our brief section <a class="reference internal" href="#sec-dynext"><span class="std std-ref">excursion</span></a>, we have confined ourselves to a “static” setting that allowed us to apply and extend a framework created by <span id="id159">[]</span> to distinguish ambiguity about a prior and from concerns for misspecifications of likelihood functions. In doing this we reinterpret objects that appear in the <span id="id160">[]</span> formulation to represent both types of doubts, distinct specification concerns that are familiar to applied statisticians. We intend the present paper as a prolegomenon to a sequel in which we shall extend and reinterpret the dynamic variational preferences of <span id="id161">[]</span>. That dynamic formulation will connect to a dynamic measure of statistical divergence based on relative entropy and the recursive preferences of <span id="id162">[]</span> and <span id="id163">[]</span>. While the issues studied here will arise in that framework, additional ones such as dynamic consistency and appropriate choices of state variables for recursive formulations of preferences also appear.<a class="footnote-reference brackets" href="#dynamicassetpricingnote" id="id164" role="doc-noteref"><span class="fn-bracket">[</span>41<span class="fn-bracket">]</span></a></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="appendix">
<h1><span class="section-number">8. </span>Appendix<a class="headerlink" href="#appendix" title="Link to this heading">#</a></h1>
<section id="convexity-of-composite-divergence">
<span id="app-convesity"></span><h2><span class="section-number">8.1. </span>Convexity of composite divergence<a class="headerlink" href="#convexity-of-composite-divergence" title="Link to this heading">#</a></h2>
<p>To verify convexity of <a class="reference internal" href="#equation-double-penalty">(7.22)</a>, consider two joint probability measures on <span class="math notranslate nohighlight">\(W \times \Theta\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;{\hat m}_0(w \mid \theta) \tau(w \mid \theta) d \upsilon(w) n_0(\theta) d \pi_o(\theta) \\
&amp;{\hat m}_1(w \mid \theta) \tau(w \mid \theta) d \upsilon(w) n_1(\theta) d\pi_o(\theta) .\end{split}\]</div>
<p>A convex combination of these two probability measures is itself a probability measure. Use weights <span class="math notranslate nohighlight">\(1 - \alpha\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span> to construct a convex combination and then factor it in the following way. First, compute the marginal probability distribution for <span class="math notranslate nohighlight">\(\theta\)</span> expressed as <span class="math notranslate nohighlight">\(n_\alpha(\theta) d\pi_o(\theta)\)</span>:</p>
<div class="math notranslate nohighlight">
\[n_\alpha (\theta) = (1- \alpha) n_0(\theta) +\alpha n_1(\theta) .\]</div>
<p>By the convexity of <span class="math notranslate nohighlight">\(\phi_2\)</span>, it follows that</p>
<div class="math notranslate nohighlight" id="equation-first-inequality">
<span class="eqno">(8.1)<a class="headerlink" href="#equation-first-inequality" title="Link to this equation">#</a></span>\[\phi_2[n_\alpha (\theta) ] \le (1 - \alpha) \phi_2 [n_0(\theta)] + \alpha \phi_2[n_1(\theta)] .\]</div>
<p>Next note that</p>
<div class="math notranslate nohighlight">
\[\begin{split}{\hat m}_\alpha(w \mid \theta) = &amp; \left[{\frac {(1-\alpha) n_0(\theta)}  {(1-\alpha) n_0(\theta) + \alpha n_1(\theta)}} \right]
{\hat m}_0(w \mid \theta) \\ &amp; + \left[{\frac { \alpha n_1(\theta)}  {(1-\alpha) n_0(\theta) + \alpha n_1(\theta)}} \right]
{\hat m}_1(w \mid \theta) .\end{split}\]</div>
<p>By the convexity of <span class="math notranslate nohighlight">\(\phi_1\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\phi_1[{\hat m}_\alpha(w \mid \theta)] \le &amp; \left[{\frac {(1-\alpha) n_0(\theta)}  {(1-\alpha) n_0(\theta) + \alpha n_1(\theta)}} \right] \phi_1 [{\hat m}_0 (w \mid \theta) ] \\ &amp; + \left[{\frac { \alpha n_1(\theta)}  {(1-\alpha) n_0(\theta) + \alpha n_1(\theta)}} \right]
\phi_1[  {\hat m}_1(w \mid \theta) ].\end{split}\]</div>
<p>Thus,</p>
<div class="math notranslate nohighlight" id="equation-second-inequality">
<span class="eqno">(8.2)<a class="headerlink" href="#equation-second-inequality" title="Link to this equation">#</a></span>\[\phi_1[{\hat m}_\alpha(w \mid \theta)]n_\alpha(\theta) \le (1-\alpha) n_0(\theta) \phi_1 [{\hat m}_0 (w \mid \theta) ] +  \alpha n_1(\theta)\phi_1[  {\hat m}_1(w \mid \theta) ] .\]</div>
<p>Multiply <a class="reference internal" href="#equation-second-inequality">(8.2)</a> by <span class="math notranslate nohighlight">\(\xi_1\)</span> and <a class="reference internal" href="#equation-first-inequality">(8.1)</a> by <span class="math notranslate nohighlight">\(\xi_2\)</span>, add the resulting two terms, and integrate with respect to <span class="math notranslate nohighlight">\(\tau(w \mid \theta) d \upsilon(w)  d \pi_o(\theta)\)</span> to verify that divergence <a class="reference internal" href="#equation-double-penalty">(7.22)</a> is indeed convex in probability measures that concern the decision maker.</p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="lhansen" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>University of Chicago. Email: <a class="reference external" href="mailto:lhansen&#37;&#52;&#48;uchicago&#46;edu">lhansen<span>&#64;</span>uchicago<span>&#46;</span>edu</a></p>
</aside>
<aside class="footnote brackets" id="tsargent" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>New York University. Email: <a class="reference external" href="mailto:thomas&#46;sargent&#37;&#52;&#48;nyu&#46;edu">thomas<span>&#46;</span>sargent<span>&#64;</span>nyu<span>&#46;</span>edu</a></p>
</aside>
<aside class="footnote brackets" id="deepuncertainties" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Deep uncertainties are defined and discussed by <span id="id165">[]</span>, <span id="id166">[]</span>, <span id="id167">[]</span>, and <span id="id168">[]</span>.</p>
</aside>
<aside class="footnote brackets" id="econometricians" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">4</a><span class="fn-bracket">]</span></span>
<p>Econometricians who explicitly confronted model uncertainty include <span id="id169">[<a class="reference internal" href="../book/cite.html#id303" title="Alexei Onatski and James H Stock. Robust monetary policy under model uncertainty in a small model of the us economy. Macroeconomic Dynamics, 6(1):85–110, 2002.">Onatski and Stock, 2002</a>]</span>, <span id="id170">[<a class="reference internal" href="../book/cite.html#id306" title="William A Brock, Steven N Durlauf, and Kenneth D West. West. 2003.policy evaluation in uncertain economic environments. Brookings Papers on Economic Activity, 1(34):235–322, 2003.">Brock <em>et al.</em>, 2003</a>]</span>, <span id="id171">[<a class="reference internal" href="../book/cite.html#id304" title="James H Stock and Mark W Watson. Forecasting with many predictors. Handbook of economic forecasting, 1:515–554, 2006.">Stock and Watson, 2006</a>]</span>, <span id="id172">[<a class="reference internal" href="../book/cite.html#id305" title="William A Brock, Steven N Durlauf, and Kenneth D West. Model uncertainty and policy evaluation: some theory and empirics. Journal of Econometrics, 136(2):629–664, 2007.">Brock <em>et al.</em>, 2007</a>]</span>, <span id="id173">[<a class="reference internal" href="../book/cite.html#id296" title="Marco Del Negro and Frank Schorfheide. Monetary policy analysis with potentially misspecified models. American Economic Review, 99(4):1415–1450, 2009.">Del Negro and Schorfheide, 2009</a>]</span>, <span id="id174">[<a class="reference internal" href="../book/cite.html#id300" title="Timothy M Christensen. Dynamic models with robust decision makers: identification and estimation. arXiv preprint arXiv:1812.11246, 2018.">Christensen, 2018</a>]</span>, <span id="id175">[<a class="reference internal" href="../book/cite.html#id298" title="Timothy Christensen and Benjamin Connault. Counterfactual sensitivity and robustness. arXiv preprint arXiv:1904.00989, 2019.">Christensen and Connault, 2019</a>]</span>, <span id="id176">[<a class="reference internal" href="../book/cite.html#id299" title="Timothy Christensen, Hyungsik Roger Moon, and Frank Schorfheide. Robust forecasting. arXiv preprint arXiv:2011.03153, 2020.">Christensen <em>et al.</em>, 2020</a>]</span>, <span id="id177">[<a class="reference internal" href="../book/cite.html#id302" title="Isaiah Andrews and Jesse M Shapiro. A model of scientific communication. Econometrica, 89(5):2117–2142, 2021.">Andrews and Shapiro, 2021</a>]</span>, and <span id="id178">[<a class="reference internal" href="../book/cite.html#id297" title="Stephane Bonhomme and Martin Weidner. Minimizing sensitivity to model misspecification. arXiv preprint arXiv:1807.02161, 2021.">Bonhomme and Weidner, 2021</a>]</span>. <span id="id179">[<a class="reference internal" href="../book/cite.html#id292" title="Gary Chamberlain. Econometric applications of maxmin expected utility. Journal of Applied Econometrics, 15(6):625-644, 2000. URL: https://ideas.repec.org/a/jae/japmet/v15y2000i6p625-644.html.">Chamberlain, 2000</a>, <a class="reference internal" href="../book/cite.html#id291" title="Gary Chamberlain. Minimax estimation and forecasting in a stationary autoregression model. American Economic Review, 91(2):55-59, May 2001. URL: https://ideas.repec.org/a/aea/aecrev/v91y2001i2p55-59.html.">Chamberlain, 2001</a>]</span> and <span id="id180">[]</span> used a post Wald-Savage decision theory of <span id="id181">[]</span> to confront model uncertainty in his econometric work.</p>
</aside>
<aside class="footnote brackets" id="likelihoodspriors" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">5</a><span class="fn-bracket">]</span></span>
<p>The term likelihood can have multiple meanings. We shall use it to represent a probability density of prize-relevant outcomes, which we refer to as repercussions, conditioned on parameters. Distinguishing likelihood functions from subjective priors is fundamental to Bayesian formulations of statistical learning. See <span id="id182">[]</span>, who recommended exchangeability as a more suitable assumption than iid (independent and identically distributed) to model situations in which a decision maker wants to learn. Putting subjective probabilities over parameters that index likelihood functions for iid sequences of random vectors generates exchangeable sequences of random variables.</p>
</aside>
<aside class="footnote brackets" id="behavioral" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id21">6</a><span class="fn-bracket">]</span></span>
<p>We put “behavioral” in quotes to emphasize that most economic models are about agents’ behaviors, including models that impose the rational expectations and common knowledge assumptions that “behavioral” economists want to drop. “Behavioral” economics sometimes means work that is linked more or less informally to psychology.</p>
</aside>
<aside class="footnote brackets" id="confidence" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id22">7</a><span class="fn-bracket">]</span></span>
<p>Although we provide no formal links to psychology here, we think that a promising research plan would explore connections between so-called behavior distortions and the inferential challenges that economic decision makers confront. As is often assumed in behavioral models, degrees of confidence could differ across economic agents.</p>
</aside>
<aside class="footnote brackets" id="paramimportance" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id25">8</a><span class="fn-bracket">]</span></span>
<p>Stephen Stigler showed us a short working paper by <span id="id183">[<a class="reference internal" href="../book/cite.html#id289" title="L. J. Savage. An axiomatic theory of reasonable behavior in the face of uncertainty. Statistical Research Center, University of Chicago, 1952.">Savage, 1952</a>]</span> entitled “An Axiomatic Theory of Reasonable Behavior in the Face of Uncertainty,” a prolegomenon to the axiomatic structure presented in <span id="id184">[]</span>. <span id="id185">[<a class="reference internal" href="../book/cite.html#id289" title="L. J. Savage. An axiomatic theory of reasonable behavior in the face of uncertainty. Statistical Research Center, University of Chicago, 1952.">Savage, 1952</a>]</span> wrote this: “The set S represents the conceivable states, or descriptions of the world, or milieu, with which the person is concerned <span class="math notranslate nohighlight">\(\ldots\)</span> “ We think of parameter values or model selection indicators as presenting a “description of the world.”</p>
</aside>
<aside class="footnote brackets" id="dynkinspace" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">9</a><span class="fn-bracket">]</span></span>
<p><span id="id186">[]</span> deploy a “Dynkin space” and an associated sigma algebra of events. Their conditioning on those events is a counterpart to our conditioning on a model. As an alternative, <span id="id187">[]</span> used an axiomatic approach to define a parameterized set of models. While both approaches are interesting, we suppose that models can have scientific or other sources from outside the specific decision problem. In this, we follow <span id="id188">[]</span> who refer to such models as “structured models.”</p>
</aside>
<aside class="footnote brackets" id="anscombeaumann" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id51">10</a><span class="fn-bracket">]</span></span>
<p>For a discussion of the Anscombe-Aumann setup, see <span id="id189">[]</span>, especially chapters 5 and 7.</p>
</aside>
<aside class="footnote brackets" id="basicsetup" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id52">11</a><span class="fn-bracket">]</span></span>
<p>We borrow our basic setup from <span id="id190">[]</span>. Following the leads of de Finetti and Savage, formulations of max-min expected utility and variational preferences initially worked within a tradition in decision theory under uncertainty that restricted probabilities to be finitely additive. However, much of probability theory routinely imposes countable additivity. It simplifies our presentation.</p>
</aside>
<aside class="footnote brackets" id="randomization" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id61">12</a><span class="fn-bracket">]</span></span>
<p>In some special cases, the set of acts induced by decisions may itself be convex. In this case, the randomization of decisions merely replicates the collection of induced acts.</p>
</aside>
<aside class="footnote brackets" id="current-state" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">13</a><span class="fn-bracket">]</span></span>
<p>The vector <span class="math notranslate nohighlight">\({\mathbb A}\)</span> absorbs the current state. In a standard optimal linear regular problem, the controller knows <span class="math notranslate nohighlight">\(({\mathbb A}, {\mathbb B}, {\mathbb C})\)</span>.</p>
</aside>
<aside class="footnote brackets" id="subjective-distribution" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id64">14</a><span class="fn-bracket">]</span></span>
<p>This distribution might depend on past information.</p>
</aside>
<aside class="footnote brackets" id="recursive-formulation" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id66">15</a><span class="fn-bracket">]</span></span>
<p>More generally, it would be input into a recursive formulation.</p>
</aside>
<aside class="footnote brackets" id="footnote-decision-rule" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id70">16</a><span class="fn-bracket">]</span></span>
<p>For <span id="id191">[]</span>, <span class="math notranslate nohighlight">\(\delta\)</span> viewed as a function of <span class="math notranslate nohighlight">\(y\)</span> is a <em>decision rule</em> distinct from our <em>prize rule</em>.</p>
</aside>
<aside class="footnote brackets" id="footnote-prize-rule" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id72">17</a><span class="fn-bracket">]</span></span>
<p><span id="id192">[]</span>’s formulation of the problem introduces a loss function that for us would be the negative of the expectation of a utility function conditioned on <span class="math notranslate nohighlight">\((Y, \theta)\)</span> under the distribution implied by <span class="math notranslate nohighlight">\(\tau( w | \theta) d\upsilon(w)\)</span> and $\zeta`.</p>
</aside>
<aside class="footnote brackets" id="acts-footnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id83">18</a><span class="fn-bracket">]</span></span>
<p>Technically, an act in <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span> is a degenerate Dirac lottery with a mass point at <span class="math notranslate nohighlight">\(s(\theta)\)</span> that is assigned probability one.</p>
</aside>
<aside class="footnote brackets" id="kreps-notes" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id85">19</a><span class="fn-bracket">]</span></span>
<p>See <span id="id193">[]</span> for more about the distinction.</p>
</aside>
<aside class="footnote brackets" id="flexibility" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id89">20</a><span class="fn-bracket">]</span></span>
<p>They did not specifically discuss the statistical linkages that we explore here.</p>
</aside>
<aside class="footnote brackets" id="representation" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id94">21</a><span class="fn-bracket">]</span></span>
<p>More generally, their representation includes an additional curvature adjustment much like the smooth ambiguity model. See Proposition 3 in their appendix.</p>
</aside>
<aside class="footnote brackets" id="anscombeaumannfootnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id98">22</a><span class="fn-bracket">]</span></span>
<p><span id="id194">[]</span> distinguished “horse lotteries” with unknown probability distributions from “roulette lotteries” having known probability distributions. See <span id="id195">[]</span> for more about the distinction. Thus, because the (unknown) “prior” distribution over states <span class="math notranslate nohighlight">\(\theta\)</span> belongs to a nontrivial set <span class="math notranslate nohighlight">\(\Pi\)</span>, there is “subjective” uncertainty about <span class="math notranslate nohighlight">\(\theta\)</span>. But given <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(f(\theta)\)</span> is a known distribution over prizes <span class="math notranslate nohighlight">\(x\)</span>, so there is “objective” uncertainty about <span class="math notranslate nohighlight">\(x \in X\)</span>. According to these distinctions, we can imagine:</p>
</aside>
<aside class="footnote brackets" id="footnotearch" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id100">23</a><span class="fn-bracket">]</span></span>
<p>The Archimedean axiom states: let <span class="math notranslate nohighlight">\(f,g,h\)</span> be acts in <span class="math notranslate nohighlight">\({\mathcal A}\)</span> with <span class="math notranslate nohighlight">\(f \succ g \succ h\)</span>. Then there are <span class="math notranslate nohighlight">\(0 &lt; \alpha_1 &lt; 1\)</span> and <span class="math notranslate nohighlight">\(0 &lt; \alpha_2 &lt; 1\)</span> such that <span class="math notranslate nohighlight">\(\alpha_1 f + (1-\alpha_1) h \succ g \succ \alpha_2 f + (1-\alpha_2) h\)</span>. See <span id="id196">[]</span> for an alternative formulation of a continuity axiom.</p>
</aside>
<aside class="footnote brackets" id="footnotenondeg" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id102">24</a><span class="fn-bracket">]</span></span>
<p>Completeness, transitivity, and the Archimedean axiom carry over directly from <span class="math notranslate nohighlight">\(\succ\)</span> to <span class="math notranslate nohighlight">\(\succ_\Lambda\)</span>, but not necessarily non-degeneracy. Our presentation below presumes non-degeneracy of $\succ_\Lambda`.</p>
</aside>
<aside class="footnote brackets" id="divinfinitem" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id108">25</a><span class="fn-bracket">]</span></span>
<p>For <span class="math notranslate nohighlight">\(\ell\)</span>’s for which the implied <span class="math notranslate nohighlight">\(m\)</span> is infinite with positive <span class="math notranslate nohighlight">\(\upsilon\)</span> measure, we define the divergence to be infinity.</p>
</aside>
<aside class="footnote brackets" id="robustbayesian" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id112">26</a><span class="fn-bracket">]</span></span>
<p>See <span id="id197">[]</span> for a robust Bayesian perspective. By applying a <span id="id198">[]</span> representation of ambiguity aversion to a decision maker who has multiple predictive distributions, <span id="id199">[]</span> forge a link between ambiguity aversion as studied in decision theory and the robust approach to statistics.</p>
</aside>
<aside class="footnote brackets" id="structureduncertainty" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id114">27</a><span class="fn-bracket">]</span></span>
<p>See <span id="id200">[]</span>.</p>
</aside>
<aside class="footnote brackets" id="cerreiaetalvariational" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id115">28</a><span class="fn-bracket">]</span></span>
<p>See Theorem 4 of <span id="id201">[]</span> for their counterpart to this representation.</p>
</aside>
<aside class="footnote brackets" id="legendretransform" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id116">29</a><span class="fn-bracket">]</span></span>
<p>The function <span class="math notranslate nohighlight">\(- \phi^*(-{\sf u} \mid \xi)\)</span> is the Legendre transform of <span class="math notranslate nohighlight">\(\xi \phi({\sf n})\)</span>.</p>
</aside>
<aside class="footnote brackets" id="footnotestrzalecki" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id121">30</a><span class="fn-bracket">]</span></span>
<p><span id="id202">[]</span> showed that when Savage’s Sure Thing Principle augments axioms imposed by <span id="id203">[]</span>, the cost functions capable of representing variational preferences are proportional to scalar multiples of entropy divergence relative to a unique baseline prior. The Sure Thing Principle also plays a significant role in <span id="id204">[]</span>’s axiomatic construction of a parameterized likelihood to be used in <span id="id205">[]</span> preferences.</p>
</aside>
<aside class="footnote brackets" id="hoformula" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id126">31</a><span class="fn-bracket">]</span></span>
<p>See formula (2.7) in <span id="id206">[]</span>.</p>
</aside>
<aside class="footnote brackets" id="dynamicproblem" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id128">32</a><span class="fn-bracket">]</span></span>
<p>See <span id="id207">[]</span> for a formulation of a dynamic choice problem under ambiguity aversion that deploys multiple priors recursively. <span id="id208">[]</span> described a possible tension between admissibility and dynamic consistency.</p>
</aside>
<aside class="footnote brackets" id="sims2010" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id129">33</a><span class="fn-bracket">]</span></span>
<p><span id="id209">[]</span> critically surveys an extensive statistical literature on this issue. Foundational papers are <span id="id210">[]</span>, <span id="id211">[]</span>, and <span id="id212">[]</span>.</p>
</aside>
<aside class="footnote brackets" id="dupuisellis" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id130">34</a><span class="fn-bracket">]</span></span>
<p>See <span id="id213">[]</span> for a closely related connection between relative entropy and a variational formula that occurs in large deviation theory.</p>
</aside>
<aside class="footnote brackets" id="divpref" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id136">35</a><span class="fn-bracket">]</span></span>
<p>Divergence preferences typically are expressed in terms of probabilities distributions over the collection states, which in the present case would be over the set <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>’s.</p>
</aside>
<aside class="footnote brackets" id="chamberlain2020" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id141">36</a><span class="fn-bracket">]</span></span>
<p>See <span id="id214">[]</span> for a discussion of robustness relative to a predictive distribution.</p>
</aside>
<aside class="footnote brackets" id="meagerset" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id142">37</a><span class="fn-bracket">]</span></span>
<p>\citet{sims2010understanding} critically surveys an extensive statistical literature on this issue. Foundational papers are \citet{Freedman_1963}, \citet{SimsAnnals71}, and \citet{Diaconis_Freedman_1986}.</p>
</aside>
<aside class="footnote brackets" id="limits-dynamic-settings" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id144">38</a><span class="fn-bracket">]</span></span>
<p>See <span id="id215">[<a class="reference internal" href="../book/cite.html#id286" title="L.P. Hansen and T.J. Sargent. Robustness and ambiguity in continuous time. Journal of Economic Theory, 146:1195-1223, 2011. doi:10.1016/j.jet.2011.01.004.">Hansen and Sargent, 2011</a>]</span> and <span id="id216">[]</span>.</p>
</aside>
<aside class="footnote brackets" id="cerreia-2021-axiomatic" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id146">39</a><span class="fn-bracket">]</span></span>
<p><span id="id217">[]</span> provide an axiomatic justification of set-based divergences as a way to capture model misspecification within a <span id="id218">[]</span> setup with multiple models.</p>
</aside>
<aside class="footnote brackets" id="footnotealtapproach" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id150">40</a><span class="fn-bracket">]</span></span>
<p>See <span id="id219">[]</span> for elaboration and application of this alternative approach.</p>
</aside>
<aside class="footnote brackets" id="dynamicassetpricingnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id164">41</a><span class="fn-bracket">]</span></span>
<p>To apply quantum methods to dynamic asset pricing models, <span id="id220">[]</span> deploy extensions of the formulation developed here. An interesting notion of a “state” again comes into play.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./decision_theory"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../continuous_global_solution/shockelasticitycontinuous.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Shock Elasticities: Continuous Time</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7. Risk, Ambiguity, and Misspecification: Decision Theory, Robust Control, and Statistics</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">7.1. Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">7.2. Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preliminaries">7.3. Preliminaries</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preferences">7.3.1. Preferences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#objective-probability">7.3.2. Objective probability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subjective-probability">7.3.3. Subjective probability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#max-min-expected-utility">7.3.4. Max-min Expected Utility</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-preferences">7.4. Variational preferences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scaled-statistical-divergences-as-c-functions">7.5. Scaled statistical divergences as <span class="math notranslate nohighlight">\(c\)</span> functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-formulation">7.6. Basic formulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-prior">7.6.1. Not knowing a prior</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-prior-i">7.6.1.1. Not knowing a prior, I</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-prior-ii">7.6.2. Not knowing a prior, II</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#not-knowing-a-likelihood">7.7. Not knowing a likelihood</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-misspecified-model">7.7.1. A misspecified model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-misspecified-likelihood-function">7.8. A misspecified likelihood function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robustness-reconsidered">7.9. Robustness reconsidered</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-examples">7.10. Two examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-preferences">7.10.1. Robust preferences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-forecasting">7.10.2. Robust forecasting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hybrid-models">7.11. Hybrid models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#first-hybrid-model">7.11.1. First hybrid model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#second-hybrid-model">7.12. Second hybrid model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-extension">7.13. Dynamic extension</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-deterministic-warm-up">7.13.1. A deterministic warm up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introducing-uncertainty">7.13.2. Introducing uncertainty</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shadow-valuation">7.13.3. Shadow valuation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-approach-to-uncertainty-quantification">7.14. An approach to uncertainty quantification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relation-to-statistical-learning">7.15. Relation to statistical learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concluding-remarks">7.16. Concluding remarks</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">8. Appendix</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convexity-of-composite-divergence">8.1. Convexity of composite divergence</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lars Peter Hansen
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>