
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Markov Processes &#8212; Quant Macro Finance</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=82c7aad8" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/example_out_c2_v2';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Stationary Increments" href="example_out_c3_v2.html" />
    <link rel="prev" title="1. Stochastic Processes and Laws of Large Numbers" href="example_out_c1_v2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/mfr.png" class="logo__image only-light" alt="Quant Macro Finance - Home"/>
    <script>document.write(`<img src="../_static/mfr.png" class="logo__image only-dark" alt="Quant Macro Finance - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Risk, Uncertainty, and Value</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="example_out_c1_v2.html">1. Stochastic Processes and Laws of Large Numbers</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Markov Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_out_c3_v2.html">3. Stationary Increments</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_out_c4_v2.html">4. Processes with Markovian increments</a></li>
<li class="toctree-l1"><a class="reference internal" href="decision_book_draft.html">5. Risk, Ambiguity, and Misspecification</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_out_c5_v2.html">6. Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_out_c6_v2.html">7. Likelihoods</a></li>
<li class="toctree-l1"><a class="reference internal" href="gmmcurrent_lars_v9.html">8. GMM Estimation </a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Uncertainty Expansion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../theory/uncertainexpansion_update.html">Uncertain Expansion Theory</a></li>





<li class="toctree-l1"><a class="reference internal" href="../theory/quickguide_update.html">Numerical Solution: Expansion Suite</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Shock Elasticity</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../continuous_global_solution/shockelasticity.html">Shock Elasticity: Discrete Time</a></li>




<li class="toctree-l1"><a class="reference internal" href="../continuous_global_solution/shockelasticitycontinuous.html">Shock Elasticities: Continuous Time</a></li>



</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/book/example_out_c2_v2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Markov Processes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constituents">2.1. Constituents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationarity">2.2. Stationarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathcal-l-2-and-eigenfunctions">2.3. <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span> and Eigenfunctions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ergodic-markov-processes">2.4. Ergodic Markov Processes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#invariant-events-for-a-markov-process">2.4.1. Invariant events for a Markov process</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#periodicity">2.5. Periodicity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#finite-state-markov-chains">2.6. Finite-State Markov Chains</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limited-dependence">2.7. Limited Dependence</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limits-of-multi-period-forecasts">2.8. Limits of Multi-Period Forecasts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-autoregressions">2.9. Vector Autoregressions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-vector-autoregressions">2.10. Estimating Vector Autoregressions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inventing-a-past-again">2.11. Inventing a Past Again</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-approximation-of-nonlinear-markov-processes">2.12. Local Approximation of Nonlinear Markov Processes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#order-zero-approximation">2.12.1. Order zero approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#order-one-approximation">2.12.2. Order one approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#order-two-approximation">2.12.3. Order two approximation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="markov-processes">
<span id="chap-markov"></span><h1><span class="section-number">2. </span>Markov Processes<a class="headerlink" href="#markov-processes" title="Link to this heading">#</a></h1>
<p>We call a random vector <span class="math notranslate nohighlight">\(X_t\)</span> the <em>state</em> because it  describes probabilistically the position of a dynamic system at time <span class="math notranslate nohighlight">\(t\)</span> from the perspective of a model builder or an econometrician. We construct a consistent sequence of probability distributions <span class="math notranslate nohighlight">\(Pr_\ell\)</span> for a sequence of random vectors</p>
<div class="math notranslate nohighlight">
\[\begin{split}X^{[\ell]} \doteq \begin{bmatrix} X_0 \\ X_1 \\ \vdots \\ X_\ell \end{bmatrix}\end{split}\]</div>
<p>for all nonnegative integers <span class="math notranslate nohighlight">\(\ell\)</span> by specifying the following two elementary components of a <em>Markov process</em>: (i) a probability distribution for <span class="math notranslate nohighlight">\(X_0\)</span>, and (ii) a time-invariant distribution for <span class="math notranslate nohighlight">\(X_{t+1}\)</span> conditional on <span class="math notranslate nohighlight">\(X_t\)</span> for <span class="math notranslate nohighlight">\(t \geq 0\)</span>.   The vector <span class="math notranslate nohighlight">\(X_t\)</span> suffices for conditioning on the past history of the process.  All other probabilities are functions of these two distributions. By creatively defining the state vector <span class="math notranslate nohighlight">\(X_t\)</span>, a Markov specification includes many models used in applied research.</p>
<section id="constituents">
<h2><span class="section-number">2.1. </span>Constituents<a class="headerlink" href="#constituents" title="Link to this heading">#</a></h2>
<p>Assume a state space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and a transition distribution <span class="math notranslate nohighlight">\(P(dx^*|x)\)</span>. For example, <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> could be <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> or a subset of <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.
The transition distribution <span class="math notranslate nohighlight">\(P\)</span> is a conditional probability measure for each <span class="math notranslate nohighlight">\(X_t = x\)</span> in the state space,
so it satisfies</p>
<div class="math notranslate nohighlight">
\[\int_{\{x^* \in \mathcal{X} \}}P(dx^* | x) = 1\]</div>
<p>for every <span class="math notranslate nohighlight">\(x\)</span> in the state space.
If in addition we specify a marginal distribution <span class="math notranslate nohighlight">\(Q_0\)</span> for the initial state <span class="math notranslate nohighlight">\(x_0\)</span> over <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, then we have completely specified all joint distributions for the
stochastic process <span class="math notranslate nohighlight">\(\{X_t, t = 0, 1, \ldots\}\)</span>.<br />
The notation <span class="math notranslate nohighlight">\(P(dx^*|x)\)</span> denotes a conditional probability measure; integration is over <span class="math notranslate nohighlight">\(x^*\)</span> and conditioning is captured by <span class="math notranslate nohighlight">\(x\)</span>.
Thus, <span class="math notranslate nohighlight">\(x^*\)</span> is a possible realization of next period’s state and <span class="math notranslate nohighlight">\(x\)</span> is a realization of this period’s state.
The conditional probability measure <span class="math notranslate nohighlight">\(P(dx^* |x)\)</span> assigns conditional probabilities to next period’s state given that this period’s state is <span class="math notranslate nohighlight">\(x\)</span>.
Often, but not always, the conditional distributions have densities against a common distribution <span class="math notranslate nohighlight">\(\lambda(dx^*)\)</span> to be used to integrate over states.
That lets us use a <em>transition density</em> to represent the conditional probability measure.</p>
<div class="proof example admonition" id="ex:ex01">
<p class="admonition-title"><span class="caption-number">Example 2.1 </span></p>
<section class="example-content" id="proof-content">
<p>A first-order vector autoregression is a Markov process. In this example, we consider <span class="math notranslate nohighlight">\(n\)</span> such processes, indexed by <span class="math notranslate nohighlight">\(i\)</span>.
The index <span class="math notranslate nohighlight">\(i\)</span> represents a discrete form of parameter uncertainty, and we may include <span class="math notranslate nohighlight">\(i\)</span> as an additional  time-invariant component part of the state.<br />
Here  <span class="math notranslate nohighlight">\(P(dx^*|x, i )\)</span> is a normal distribution with mean <span class="math notranslate nohighlight">\({\mathbb A}_ix\)</span> and covariance matrix <span class="math notranslate nohighlight">\({\mathbb B}_i{{\mathbb B}_i}'\)</span> for square matrices <span class="math notranslate nohighlight">\({\mathbb A}_i\)</span> and  matrices <span class="math notranslate nohighlight">\({\mathbb B}_i\)</span> with full column rank.<a class="footnote-reference brackets" href="#singularity" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> These assumptions imply the vector autoregressive (VAR) representation for <span class="math notranslate nohighlight">\(i=1,2,..., n.\)</span></p>
<div class="math notranslate nohighlight">
\[X_{t+1} = {\mathbb A}_i X_t + {\mathbb B}_i W_{t+1} ,\]</div>
<p>for <span class="math notranslate nohighlight">\(t \geq 0\)</span>, where <span class="math notranslate nohighlight">\(W_{t+1}\)</span> is a multivariate standard normally distributed random vector that is independent of <span class="math notranslate nohighlight">\(X_t, i\)</span>.</p>
</section>
</div><div class="proof example admonition" id="ex:ex02">
<p class="admonition-title"><span class="caption-number">Example 2.2 </span></p>
<section class="example-content" id="proof-content">
<p>A discrete-state Markov chain consists of a
<span class="math notranslate nohighlight">\(Q_0\)</span> represented as a row vector and a transition probability <span class="math notranslate nohighlight">\(P(dx^*|x)\)</span>  represented as a matrix  with one row and one column for each possible value of the state <span class="math notranslate nohighlight">\(x\)</span>.
Rows contain vectors of probabilities of next period’s state conditioned on a realized value of
this period’s state.  As with the VAR example, we include <span class="math notranslate nohighlight">\(n\)</span> such process and augment the state with a time-invariant component that captures which transition matrix captures the actual transitional dynamics.</p>
</section>
</div><p>It is useful to construct an operator by applying a one-step conditional expectation operator to functions of a Markov state. Let <span class="math notranslate nohighlight">\(f:{\mathcal X} \rightarrow {\mathbb R}\)</span>.
For bounded <span class="math notranslate nohighlight">\(f\)</span>, define:</p>
<div class="math notranslate nohighlight" id="equation-eqn-toperatordef">
<span class="eqno">(2.1)<a class="headerlink" href="#equation-eqn-toperatordef" title="Link to this equation">#</a></span>\[{\mathbb T} f (x) = E \left[ f(X_{t+1}) | X_t = x \right] = \int_{\{x^* \in {\mathcal X}\}}  f(x^*) P(d x^*|x).\]</div>
<p>The Law of Iterated Expectations justifies iterating on <span class="math notranslate nohighlight">\({\mathbb T}\)</span>  to form conditional expectations of the function <span class="math notranslate nohighlight">\(f\)</span> of the Markov state over longer horizons:</p>
<div class="math notranslate nohighlight">
\[{\mathbb T}^j f(x) = E  \left[ f(X_{t+j}) | X_t = x \right].\]</div>
<p>The operator <span class="math notranslate nohighlight">\({\mathbb T}\)</span>  gives an alternative way to represent the transitional dynamics fora Markov process. Indeed, by applying <span class="math notranslate nohighlight">\({\mathbb T}\)</span> to a suitable range of test functions <span class="math notranslate nohighlight">\(f\)</span>, we can construct a conditional probability measure.</p>
<div class="proof theorem admonition" id="theorem-2">
<p class="admonition-title"><span class="caption-number">Theorem 2.1 </span></p>
<section class="theorem-content" id="proof-content">
<p>Start with a conditional expectation operator <span class="math notranslate nohighlight">\({\mathbb T}\)</span> that maps a space of bounded functions into itself. We can use <span class="math notranslate nohighlight">\({\mathbb T}\)</span> to construct a conditional probability measure <span class="math notranslate nohighlight">\(P(dx^*|x)\)</span> provided that <span class="math notranslate nohighlight">\({\mathbb T}\)</span> is (a) well-defined on the space of bounded functions, (b) preserves the bound, (c) maps nonnegative functions into nonnegative functions, and (d) maps the unit function into the unit function.</p>
</section>
</div></section>
<section id="stationarity">
<h2><span class="section-number">2.2. </span>Stationarity<a class="headerlink" href="#stationarity" title="Link to this heading">#</a></h2>
<p>We can construct a stationary Markov process by carefully choosing the distribution of the initial state <span class="math notranslate nohighlight">\(X_0\)</span>.</p>
<div class="proof definition admonition" id="def:stationdist">
<p class="admonition-title"><span class="caption-number">Definition 2.1 </span></p>
<section class="definition-content" id="proof-content">
<p>A probability measure <span class="math notranslate nohighlight">\(Q\)</span> over a state space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> for a Markov process with transition probability <span class="math notranslate nohighlight">\(P\)</span> is a <strong>stationary distribution</strong> if it satisfies</p>
<div class="math notranslate nohighlight">
\[\int_{ \{ x \in \mathcal{X} \}} P(d x^*|x) Q(dx) = Q(d x^*).\]</div>
</section>
</div><p>We will sometimes refer to a stationary density <span class="math notranslate nohighlight">\(q\)</span>. A density is always relative to a measure. With this in mind, let <span class="math notranslate nohighlight">\(\lambda\)</span> be a measure used to integrate over possible Markov states on the state space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Then a density <span class="math notranslate nohighlight">\(q\)</span> is a nonnegative (Borel measurable) function of the state for which <span class="math notranslate nohighlight">\(\int q(x) \lambda(dx) = 1\)</span>.</p>
<div class="proof definition admonition" id="definition-4">
<p class="admonition-title"><span class="caption-number">Definition 2.2 </span></p>
<section class="definition-content" id="proof-content">
<p>A <strong>stationary density</strong> over a state space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> for a Markov process
with transition probability <span class="math notranslate nohighlight">\(P\)</span> is a probability density <span class="math notranslate nohighlight">\(q\)</span> with respect to a measure <span class="math notranslate nohighlight">\(\lambda\)</span> over the state space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> that satisfies</p>
<div class="math notranslate nohighlight">
\[\int P(d x^*|x) q(x) \lambda(dx) = q(x^*) \lambda(dx^*).\]</div>
</section>
</div><div class="proof definition admonition" id="def:reversible">
<p class="admonition-title"><span class="caption-number">Definition 2.3 </span></p>
<section class="definition-content" id="proof-content">
<p>A Markov process with stationary density <span class="math notranslate nohighlight">\(q\)</span> and transition density <span class="math notranslate nohighlight">\(P(dx|x^*)\)</span> is said to be <strong>reversible</strong> if</p>
<div class="math notranslate nohighlight" id="equation-eqn-reversible">
<span class="eqno">(2.2)<a class="headerlink" href="#equation-eqn-reversible" title="Link to this equation">#</a></span>\[P(dx^*|x)q(x) \lambda(d x) = P(dx|x^*)q(x^*)  \lambda(d x^*).\]</div>
</section>
</div><div class="proof example admonition" id="example-6">
<p class="admonition-title"><span class="caption-number">Example 2.3 </span></p>
<section class="example-content" id="proof-content">
<p>Various sufficient conditions imply the existence of a stationary distribution. Given a transition distribution <span class="math notranslate nohighlight">\(P\)</span>, one such condition that is widely used to justify some calculations from numerical simulations is that the Markov process be <em>time reversible</em>, which means that</p>
<div class="math notranslate nohighlight" id="equation-eqn-reversiblenew">
<span class="eqno">(2.3)<a class="headerlink" href="#equation-eqn-reversiblenew" title="Link to this equation">#</a></span>\[P(dx^*|x) Q(dx) = P(dx|x^*) Q(dx^*)\]</div>
<p>for some probability distribution <span class="math notranslate nohighlight">\(Q\)</span> on <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Because a transition distribution satisfies <span class="math notranslate nohighlight">\(\int_{\{ x \in \mathcal{X}\}}  P(dx|x^*) =1 \)</span>,</p>
<div class="math notranslate nohighlight">
\[\int_{\{ x \in \mathcal{X}\}} P(dx^*|x) Q(dx)  = \int_{\{ x \in \mathcal{X}\}} P(dx|x^*) Q(dx^*)  = Q(dx^*) ,\]</div>
<p>so <span class="math notranslate nohighlight">\(Q\)</span> is a stationary distribution by <a class="reference internal" href="#def:stationdist">Definition 2.1</a>. Restriction <a class="reference internal" href="#equation-eqn-reversiblenew">(2.3)</a> implies that the process is time reversible in the sense that forward and backward transition distributions coincide. Time reversibility is special, so later we will explore other sufficient conditions for the existence of stationary distributions.<a class="footnote-reference brackets" href="#bayesianmarkov" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
</section>
</div><div class="proof remark admonition" id="remark-7">
<p class="admonition-title"><span class="caption-number">Remark 2.1 </span></p>
<section class="remark-content" id="proof-content">
<p>When a Markov process starts at a stationary distribution, we can construct the process <span class="math notranslate nohighlight">\(\{ X_t : t=1,2,...\}\)</span> with a measure-preserving transformation <span class="math notranslate nohighlight">\({\mathbb S}\)</span> of the type featured in chapter <a class="reference internal" href="example_out_c1_v2.html#chap-process"><span class="std std-ref">Stochastic Processes and Laws of Large Numbers</span></a>, section <a class="reference internal" href="example_out_c1_v2.html#sec-stochprocessconstructioni"><span class="std std-ref">Constructing a Stochastic Process</span></a>.</p>
</section>
</div><p>Given a stationary distribution <span class="math notranslate nohighlight">\(Q\)</span>, form the space of functions <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span></p>
<div class="math notranslate nohighlight">
\[{\mathcal L}^2 = \{ f:{\mathcal X} \rightarrow {\mathbb R} : \int f(x)^2 Q(dx)  &lt; \infty \} .\]</div>
<p>It can be shown that <span class="math notranslate nohighlight">\({\mathbb T} : {\mathcal L}^2 \rightarrow {\mathcal L}^2\)</span>. On this space, a well-defined norm is</p>
<div class="math notranslate nohighlight">
\[\| f \| = \left[\int f(x)^2 Q(dx)\right]^{1/2} .\]</div>
</section>
<section id="mathcal-l-2-and-eigenfunctions">
<span id="sec-eigfns"></span><h2><span class="section-number">2.3. </span><span class="math notranslate nohighlight">\({\mathcal L}^2\)</span> and Eigenfunctions<a class="headerlink" href="#mathcal-l-2-and-eigenfunctions" title="Link to this heading">#</a></h2>
<p>We connected ergodicity to a statistical notion of invariance in chapter <a class="reference internal" href="example_out_c1_v2.html#chap-process"><span class="std std-ref">Stochastic Processes and Laws of Large Numbers</span></a>.  The word invariance brings to mind a generalization of eigenvectors called eigenfunctions. Eigenfunctions of a linear mapping characterize an invariant subspace of functions such that the application of a linear mapping to any element of that space remains in the same subspace.  Eigenfunctions associated with a unit eigenvalue are themselves invariant under the mapping.  So perhaps it is not surprising that such eigenfunctions of <span class="math notranslate nohighlight">\({\mathbb T}\)</span> come in handy for studying ergodicity of Markov processes.</p>
<p>Given a stationary distribution <span class="math notranslate nohighlight">\(Q\)</span>, form the space of functions</p>
<div class="math notranslate nohighlight">
\[{\mathcal L}^2 = \{ f:{\mathcal X} \rightarrow {\mathbb R} : \int f(x)^2 Q(dx)  &lt; \infty \} .\]</div>
<p>It can be verified that <span class="math notranslate nohighlight">\({\mathbb T} : {\mathcal L}^2 \rightarrow {\mathcal L}^2\)</span> and that</p>
<div class="math notranslate nohighlight">
\[\| f \| = \left[\int f(x)^2 Q(dx)\right]^{1/2} \]</div>
<p>is a well-defined norm on <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span>.</p>
<p>We now study eigenfunctions of the conditional expectation operator <span class="math notranslate nohighlight">\({\mathbb T}\)</span>.</p>
<div class="proof definition admonition" id="definition-8">
<p class="admonition-title"><span class="caption-number">Definition 2.4 </span></p>
<section class="definition-content" id="proof-content">
<p>A function <span class="math notranslate nohighlight">\(f \in \mathcal{L}^2\)</span> that solves  <span class="math notranslate nohighlight">\(\mathbb{T}  f =  f\)</span>
is  an eigenfunction of <span class="math notranslate nohighlight">\(\mathbb{T}\)</span>  associated with a unit eigenvalue.<a class="footnote-reference brackets" href="#eigenfunctionnote" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a></p>
</section>
</div><p>The following proposition asserts that an eigenfunction  <span class="math notranslate nohighlight">\(\tilde{f}(X_t)\)</span> associated with a unit eigenvalue is constant as <span class="math notranslate nohighlight">\(X_t\)</span> moves through time.</p>
<div class="proof proposition admonition" id="lem:uniteigen">
<p class="admonition-title"><span class="caption-number">Proposition 2.1 </span></p>
<section class="proposition-content" id="proof-content">
<p>Suppose that <span class="math notranslate nohighlight">\(\tilde{f}\)</span> is an eigenfunction of <span class="math notranslate nohighlight">\(\mathbb{T}\)</span> associated with a unit eigenvalue. Then <span class="math notranslate nohighlight">\(\{\tilde{f}(X_t) : t=0,1,...\}\)</span> is constant over time with probability one.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof.</p>
<div class="math notranslate nohighlight">
\[E \left[\tilde{f}(X_{t+1}) \tilde{f}(X_t)\right] = \int (\mathbb{T}\tilde{f})(x) \tilde{f}(x) Q(dx) = \int \tilde{f}(x)^2 Q(dx) =
E \left[\tilde{f}(X_t)^2\right]\]</div>
<p>where the first equality follows from the Law of Iterated Expectations. Then because <span class="math notranslate nohighlight">\(Q\)</span> is a stationary distribution,</p>
<div class="math notranslate nohighlight">
\[\begin{eqnarray*}
E\left([\tilde{f}(X_{t+1}) - \tilde{f}(X_t)]^2\right)  &amp; = &amp; E\left[\tilde{f}(X_{t+1})^2\right] + E \left[\tilde{f}(X_t)^2\right] \cr &amp;&amp;- 2 E\left[ \tilde{f}(X_{t+1})\tilde{f}(X_t) \right] \cr
  &amp; = &amp; 0. \end{eqnarray*}\]</div>
</div>
</section>
<section id="ergodic-markov-processes">
<span id="sec-markergodic"></span><h2><span class="section-number">2.4. </span>Ergodic Markov Processes<a class="headerlink" href="#ergodic-markov-processes" title="Link to this heading">#</a></h2>
<p>Chapter <a class="reference internal" href="example_out_c1_v2.html#chap-process"><span class="std std-ref">Stochastic Processes and Laws of Large Numbers</span></a> studied special statistical models that, because they are ergodic, are affiliated with a Law of Large Numbers in which limit points are constant across sample points <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>. Section <a class="reference internal" href="example_out_c1_v2.html#sec-ergodic-decomp"><span class="std std-ref">Ergodic Decomposition</span></a> described other statistical models that are not ergodic and that are components of more general probability specifications that we used to express the idea that a statistical model is unknown.<a class="footnote-reference brackets" href="#unknownparameters" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> As we described, even when the statistical model is unknowns, ergodic processes remain of interest as they are building blocks (specific statistical models) that revealed over time.  We now explore ergodicity in the context of Markov processes.</p>
<p>From <a class="reference internal" href="#lem:uniteigen">Proposition 2.1</a> we know that time-series averages of an eigenfunction <span class="math notranslate nohighlight">\({\mathbb T} \tilde f = \tilde f\)</span> are invariant over time, so</p>
<div class="math notranslate nohighlight">
\[{\frac 1 N} \sum_{t=1}^N \tilde f(X_t) = \tilde f(X).\]</div>
<p>However, when <span class="math notranslate nohighlight">\({\tilde f}(x)\)</span> varies across sets of states <span class="math notranslate nohighlight">\(x\)</span> that occur with positive probability under <span class="math notranslate nohighlight">\(Q\)</span>, a time series average <span class="math notranslate nohighlight">\({\frac 1 N} \sum_{t=1}^N \tilde f(X_t)\)</span> can differ from <span class="math notranslate nohighlight">\(\int \tilde f(x) Q(dx)\)</span>. This happens when observations of <span class="math notranslate nohighlight">\(\tilde f(X_t)\)</span> along a sample path for <span class="math notranslate nohighlight">\(\{X_t\}\)</span> convey an inaccurate impression of how <span class="math notranslate nohighlight">\(f(X)\)</span> varies across the stationary distribution <span class="math notranslate nohighlight">\(Q(dx)\)</span>. See <a class="reference internal" href="#ex:MC2">Example 2.5</a> below. We can exclude the possibility of such inaccurate impressions by imposing a restriction on the eigenfunction equation <span class="math notranslate nohighlight">\({\mathbb T}f = f\)</span>. % to state a sufficient condition for ergodicity.</p>
<div class="proof proposition admonition" id="prop:ergo">
<p class="admonition-title"><span class="caption-number">Proposition 2.2 </span></p>
<section class="proposition-content" id="proof-content">
<p>When a unique solution to the equation</p>
<div class="math notranslate nohighlight">
\[{\mathbb T}f = f\]</div>
<p>is a constant function (with <span class="math notranslate nohighlight">\(Q\)</span> measure one), then it is possible to construct <span class="math notranslate nohighlight">\(\{ X_t : t=0,1,2,...\}\)</span>
as a stationary and ergodic Markov process with <span class="math notranslate nohighlight">\({\mathbb T}\)</span> as
the one-period conditional expectation operator and <span class="math notranslate nohighlight">\(Q\)</span> as the initial distribution for
<span class="math notranslate nohighlight">\(X_0\)</span>.<a class="footnote-reference brackets" href="#ergo-footnote" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a></p>
</section>
</div><p>Evidently, ergodicity is a property that obtains relative to a stationary distribution <span class="math notranslate nohighlight">\(Q\)</span> of the Markov process. If there are multiple stationary distributions, it is possible that there is a unique constant function <span class="math notranslate nohighlight">\(f\)</span> that solves <span class="math notranslate nohighlight">\({\mathbb T}f = f\)</span> problem for one stationary distribution and that non-constant solutions exist for other stationary distributions.</p>
<section id="invariant-events-for-a-markov-process">
<h3><span class="section-number">2.4.1. </span>Invariant events for a Markov process<a class="headerlink" href="#invariant-events-for-a-markov-process" title="Link to this heading">#</a></h3>
<p>Consider an eigenfunction <span class="math notranslate nohighlight">\({\tilde f}\)</span> of <span class="math notranslate nohighlight">\({\mathbb T}\)</span> associated with a unit eigenvalue. Let <span class="math notranslate nohighlight">\(\phi : {\mathbb R} \rightarrow {\mathbb R}\)</span> be a bounded Borel measurable function. Since <span class="math notranslate nohighlight">\(\{ {\tilde f}(X_t) : t=0,1,2,... \}\)</span> is invariant over time, so is <span class="math notranslate nohighlight">\(\left\{ \phi\left[{\tilde f}(X_t)\right] : t=0,1,2, \ldots \right\}\)</span> and it is necessarily true that</p>
<div class="math notranslate nohighlight">
\[{\mathbb T} (\phi \circ {\tilde f}) = \phi \circ {\tilde f}.\]</div>
<p>Therefore, from an eigenfunction <span class="math notranslate nohighlight">\({\tilde f}\)</span> associated with a unit eigenvalue, we can construct other eigenfunctions,<a class="footnote-reference brackets" href="#eigen-footnote" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a> for example</p>
<div class="math notranslate nohighlight" id="equation-newjunk1">
<span class="eqno">(2.4)<a class="headerlink" href="#equation-newjunk1" title="Link to this equation">#</a></span>\[\begin{split}\phi[{\tilde f}(x)] = \begin{cases} 
1 &amp; \text{if} \ {\tilde f}(x) \in {\tilde {\mathfrak b}} \\
0 &amp; \text{if} \ {\tilde f}(x) \notin {\tilde {\mathfrak b}} \end{cases}\end{split}\]</div>
<p>for some Borel set <span class="math notranslate nohighlight">\({\tilde {\mathfrak b}}\)</span> in <span class="math notranslate nohighlight">\({\mathbb R}\)</span>.</p>
<p>It follows that</p>
<div class="math notranslate nohighlight">
\[\Lambda = \{ \omega \in \Omega : {\tilde f}[X_0(\omega)] \in {\tilde {\mathfrak b}} \}\]</div>
<p>is an invariant event in <span class="math notranslate nohighlight">\(\Omega\)</span>. Note that by constructing the Borel set, <span class="math notranslate nohighlight">\({\mathfrak b}\)</span> in <span class="math notranslate nohighlight">\(\mathcal X\)</span></p>
<div class="math notranslate nohighlight">
\[{\mathfrak b} = \{ x : {\tilde f}(x) \in {\tilde {\mathfrak b}}  \}\]</div>
<p>we can represent <span class="math notranslate nohighlight">\(\Lambda\)</span> as</p>
<div class="math notranslate nohighlight" id="equation-invariantrep">
<span class="eqno">(2.5)<a class="headerlink" href="#equation-invariantrep" title="Link to this equation">#</a></span>\[\Lambda = \{ \omega \in \Omega : X_0(\omega) \in {\mathfrak b} \}.\]</div>
<p>Thus we have shown how to construct many non-degenerate eigenfunctions, starting from an initial such function.</p>
<p>For Markov processes, all invariant events can be represented as in <a class="reference internal" href="#equation-invariantrep">(2.5)</a>, which is expressed in terms of the initial state <span class="math notranslate nohighlight">\(X_0\)</span>. See <span id="id7">Doob [<a class="reference internal" href="cite.html#id124" title="J. L. Doob. Stochastic Processes. John Wiley and Sons, New York, 1953.">1953</a>]</span>. Thus, associated with an invariant event is a Borel set in <span class="math notranslate nohighlight">\({\mathcal X}\)</span>. Let <span class="math notranslate nohighlight">\({\mathfrak J}\)</span> denote the collection of Borel subsets of <span class="math notranslate nohighlight">\({\mathcal X}\)</span> for which <span class="math notranslate nohighlight">\(\Lambda\)</span> constructed as in <a class="reference internal" href="#equation-invariantrep">(2.5)</a> is an invariant event. From these invariant events, we can also construct many non-degenerate eigenfunctions as indicator functions of sets in <span class="math notranslate nohighlight">\({\mathfrak J}\)</span>. Formally, if <span class="math notranslate nohighlight">\({\tilde {\mathfrak b}} \in {\mathfrak J}\)</span>, then the indicator function</p>
<div class="math notranslate nohighlight" id="equation-neweigen">
<span class="eqno">(2.6)<a class="headerlink" href="#equation-neweigen" title="Link to this equation">#</a></span>\[\begin{split}f(x) = \begin{cases} 
1 &amp; \text{if} \ x \in {\mathfrak b} \\
0 &amp; \text{if} \ x \notin {\mathfrak b} \end{cases}\end{split}\]</div>
<p>satisfies</p>
<div class="math notranslate nohighlight">
\[{\mathbb T} f = f\]</div>
<p>with <span class="math notranslate nohighlight">\(Q\)</span> probability one. Provided that the probability of <span class="math notranslate nohighlight">\(\Lambda\)</span> is neither zero nor one, then we have constructed a nonnegative function <span class="math notranslate nohighlight">\(f\)</span> that is strictly positive on a set of positive <span class="math notranslate nohighlight">\(Q\)</span> measure and zero on a set with strictly positive <span class="math notranslate nohighlight">\(Q\)</span> measure.</p>
<p>More generally, when a Markov process <span class="math notranslate nohighlight">\(\left\{X_t: t \geq 0\right\}\)</span> is not ergodic, there exist bounded eigenfunctions with unit eigenvalues that are not constant with <span class="math notranslate nohighlight">\(Q\)</span> measure one. For a non-degenerate eigenfunction <span class="math notranslate nohighlight">\(\tilde{f}\)</span> with unit eigenvalue to be constant with <span class="math notranslate nohighlight">\(Q\)</span> measure one, it shouldn’t be possible for the Markov process permanently to get stuck in a subset of the state space which has probability different from one or zero.</p>
<p>Suppose now we consider any Borel set <span class="math notranslate nohighlight">\(\mathfrak{b}\)</span> of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> that has <span class="math notranslate nohighlight">\(Q\)</span> measure that is neither zero nor one. Let <span class="math notranslate nohighlight">\(f\)</span> be constructed as in <a class="reference internal" href="#equation-neweigen">(2.6)</a> without restricting <span class="math notranslate nohighlight">\(\mathfrak{b}\)</span> to be in <span class="math notranslate nohighlight">\(\mathfrak{J}\)</span>. Then <span class="math notranslate nohighlight">\(\mathbb{T}^j\)</span> applied to <span class="math notranslate nohighlight">\(f\)</span> is the conditional probability of <span class="math notranslate nohighlight">\(\left\{X_j \in \mathfrak{b}\right\}\)</span> as of date zero. If we want time series averages to converge to unconditional expectations, we must require that the set <span class="math notranslate nohighlight">\(\mathfrak{b}\)</span> be visited eventually with positive probability. To account properly for all possible future dates we use a mathematically convenient resolvent operator defined by</p>
<div class="math notranslate nohighlight">
\[\mathbb{M} f(x)=(1-\lambda) \sum_{j=0}^{\infty} \lambda^j \mathbb{T}^j f.\]</div>
<p>for some constant discount factor <span class="math notranslate nohighlight">\(0&lt;\lambda&lt;1\)</span>. Notice that If <span class="math notranslate nohighlight">\(\tilde{f}\)</span> is an eigenfunction of <span class="math notranslate nohighlight">\(\mathbb{T}\)</span> associated with a unit eigenvalue, then the same is true for <span class="math notranslate nohighlight">\(\mathbb{T}^j\)</span> and hence for <span class="math notranslate nohighlight">\(\mathbb{M}\)</span>. We translate the requirement that <span class="math notranslate nohighlight">\(X_j\)</span> be eventually visited to a restriction that applying <span class="math notranslate nohighlight">\(\mathbb{M}\)</span> the indicator function <span class="math notranslate nohighlight">\(f\)</span> yields a strictly positive function. The following statement extends this restriction to all nonnegative functions that are distinct from zero.</p>
<div class="proof proposition admonition" id="prop:ergod100">
<p class="admonition-title"><span class="caption-number">Proposition 2.3 </span></p>
<section class="proposition-content" id="proof-content">
<p>Suppose that for any <span class="math notranslate nohighlight">\(f \ge 0\)</span>
such that <span class="math notranslate nohighlight">\(\int f(x) Q(dx) &gt; 0\)</span>, <span class="math notranslate nohighlight">\({\mathbb M} f(x) &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(x \in {\mathcal X}\)</span> with <span class="math notranslate nohighlight">\(Q\)</span> measure one.  Then
any solution <span class="math notranslate nohighlight">\({\tilde f}\)</span> to
<span class="math notranslate nohighlight">\({\mathbb T}  f =  f\)</span> is necessarily constant with  <span class="math notranslate nohighlight">\(Q\)</span> measure one.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. Consider an eigenfunction <span class="math notranslate nohighlight">\({\tilde f}\)</span> associated with a unit eigenvalue.  The function <span class="math notranslate nohighlight">\(f = \phi \circ {\tilde f}\)</span> necessarily satisfies:</p>
<div class="math notranslate nohighlight">
\[{\mathbb M}f = f\]</div>
<p>for any <span class="math notranslate nohighlight">\(\phi\)</span> of the form <a class="reference internal" href="#equation-newjunk1">(2.4)</a>.  If such an <span class="math notranslate nohighlight">\(f\)</span> also satisfies <span class="math notranslate nohighlight">\(\int f(x) Q(dx) &gt; 0\)</span>, then <span class="math notranslate nohighlight">\(f(x)=1\)</span>
with <span class="math notranslate nohighlight">\(Q\)</span> probability one.  Since this holds for any Borel set <span class="math notranslate nohighlight">\({\mathfrak b}\)</span> in <span class="math notranslate nohighlight">\({\mathbb R}\)</span>, <span class="math notranslate nohighlight">\({\tilde f}\)</span> must be constant with <span class="math notranslate nohighlight">\(Q\)</span> probability one.</p>
</div>
<p><a class="reference internal" href="#prop:ergod100">Proposition 2.3</a> supplies a sufficient condition for ergodicity. A more restrictive  sufficient condition is that there exists an integer <span class="math notranslate nohighlight">\(m \geq 1\)</span> such that</p>
<div class="math notranslate nohighlight">
\[{\mathbb T}^{m} f(x) &gt; 0\]</div>
<p>for any <span class="math notranslate nohighlight">\(f \ge 0\)</span> such that <span class="math notranslate nohighlight">\(\int f(x) Q(dx) &gt; 0\)</span>
on a set with <span class="math notranslate nohighlight">\(Q\)</span> measure one.</p>
<div class="proof remark admonition" id="remark-12">
<p class="admonition-title"><span class="caption-number">Remark 2.2 </span></p>
<section class="remark-content" id="proof-content">
<p>The sufficient conditions imposed in <a class="reference internal" href="#prop:ergod100">Proposition 2.3</a> imply a property called <em>irreducibility</em> relative to the probability measure <span class="math notranslate nohighlight">\(Q\)</span>. While this proposition presumes that <span class="math notranslate nohighlight">\(Q\)</span> is a stationary distribution, <em>irreducibility</em> allows for a more general specification of <span class="math notranslate nohighlight">\(Q\)</span>.</p>
</section>
</div><p><a class="reference internal" href="#prop:ergod100">Proposition 2.3</a> provides a way to verify ergodicity. As discussed in chapter <a class="reference internal" href="example_out_c1_v2.html#chap-process"><span class="std std-ref">Stochastic Processes and Laws of Large Numbers</span></a>, ergodicity is a property of a statistical model. As statisticians or econometricians we often entertain a set of Markov models, each of which is ergodic. For each model, we can build a probability <span class="math notranslate nohighlight">\(Pr\)</span> using the canonical construction given at the outset of chapter <a class="reference internal" href="example_out_c1_v2.html#chap-process"><span class="std std-ref">Stochastic Processes and Laws of Large Numbers</span></a>. Convex combinations of these probabilities are measure-preserving but not necessarily ergodic when used in conjunction with the shift transformation <span class="math notranslate nohighlight">\({\mathbb S}\)</span>. We can take the ergodic Markov models to be the building blocks for a specification to be used in a statistical investigation. There can be a finite number of these building blocks or even a continuum of them represented in terms of an unknown parameter vector.</p>
<div class="proof definition admonition" id="definition-13">
<p class="admonition-title"><span class="caption-number">Definition 2.5 </span></p>
<section class="definition-content" id="proof-content">
<p>The process <span class="math notranslate nohighlight">\(\{ X_t \}\)</span> is said to be irreducible with respect to <span class="math notranslate nohighlight">\(\widetilde{Q}\)</span> if for any <span class="math notranslate nohighlight">\(f \ge 0\)</span> such that <span class="math notranslate nohighlight">\(\int f(x) \widetilde{Q}(dx) &gt; 0\)</span>,
<span class="math notranslate nohighlight">\({\mathbb{M}} f(x) &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(x \in {\mathcal{X}}\)</span> with <span class="math notranslate nohighlight">\({\widetilde{Q}}\)</span> measure one.</p>
</section>
</div><div class="proof proposition admonition" id="proposition-14">
<p class="admonition-title"><span class="caption-number">Proposition 2.4 </span></p>
<section class="proposition-content" id="proof-content">
<p>When <span class="math notranslate nohighlight">\({\widetilde Q}\)</span> is a stationary distribution and <span class="math notranslate nohighlight">\(\left\{ X_t \right\}\)</span> is irreducible with respect to <span class="math notranslate nohighlight">\(\widetilde Q\)</span>, the process is necessarily ergodic.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. By imitating the proof of <a class="reference internal" href="#prop:ergod100">Proposition 2.3</a>, we can establish that irreducibility rules out bounded eigenfunctions that are not constant with <span class="math notranslate nohighlight">\({\widetilde Q}\)</span> measure one.</p>
</div>
</section>
</section>
<section id="periodicity">
<h2><span class="section-number">2.5. </span>Periodicity<a class="headerlink" href="#periodicity" title="Link to this heading">#</a></h2>
<p>Next, we study a notion of periodicity of a stationary and ergodic Markov process.<a class="footnote-reference brackets" href="#periodicity-footnote" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> To define periodicity of a Markov process, for a given positive integer <span class="math notranslate nohighlight">\(p\)</span> we construct a new Markov process by sampling an original process every <span class="math notranslate nohighlight">\(p\)</span> time periods. This is sometimes called ‘skip-sampling’ at sampling interval <span class="math notranslate nohighlight">\(p\)</span>.<a class="footnote-reference brackets" href="#skip-sampling-footnote" id="id9" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a> With a view toward applying <a class="reference internal" href="#lem:uniteigen">Proposition 2.1</a> to <span class="math notranslate nohighlight">\({\mathbb T}^p\)</span>, solve</p>
<div class="math notranslate nohighlight" id="equation-perioddef">
<span class="eqno">(2.7)<a class="headerlink" href="#equation-perioddef" title="Link to this equation">#</a></span>\[{\mathbb T}^p f = f\]</div>
<p>for a function <span class="math notranslate nohighlight">\({\tilde f}\)</span>. We know from <a class="reference internal" href="#lem:uniteigen">Proposition 2.1</a> that for an <span class="math notranslate nohighlight">\(\tilde f\)</span> that solves <a class="reference internal" href="#equation-perioddef">(2.7)</a>, <span class="math notranslate nohighlight">\(\{ {\tilde f}(X_t) : t=0, p, 2p, \ldots \}\)</span>
is invariant and so is <span class="math notranslate nohighlight">\(\{ {\tilde f}(X_t) : t=1,p+1,2p+1,...\}\)</span>. The process <span class="math notranslate nohighlight">\({\tilde f}(X_t)\)</span> is periodic with period <span class="math notranslate nohighlight">\(p\)</span> or <span class="math notranslate nohighlight">\(np\)</span> for any positive integer <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="proof definition admonition" id="definition-15">
<p class="admonition-title"><span class="caption-number">Definition 2.6 </span></p>
<section class="definition-content" id="proof-content">
<p>The <em>periodicity</em> of an irreducible Markov process <span class="math notranslate nohighlight">\(\left\{ X_t \right\}\)</span> with respect to <span class="math notranslate nohighlight">\({\widetilde Q}\)</span> is the smallest positive integer <span class="math notranslate nohighlight">\(p\)</span> such that there is a solution to equation <a class="reference internal" href="#equation-perioddef">(2.7)</a> that is not constant with <span class="math notranslate nohighlight">\({\widetilde Q}\)</span> measure one. When there is no such integer <span class="math notranslate nohighlight">\(p\)</span>, we say that the process is <em>aperiodic</em>.</p>
</section>
</div></section>
<section id="finite-state-markov-chains">
<span id="subsec-chain"></span><h2><span class="section-number">2.6. </span>Finite-State Markov Chains<a class="headerlink" href="#finite-state-markov-chains" title="Link to this heading">#</a></h2>
<p>Suppose that <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> consists of <span class="math notranslate nohighlight">\(n\)</span> possible states. We can label these states in a variety of ways, but for now we suppose that state <span class="math notranslate nohighlight">\(x_j\)</span> is the coordinate vector consisting entirely of zeros except in position <span class="math notranslate nohighlight">\(j\)</span>, where there is a one. Let <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> be an <span class="math notranslate nohighlight">\(n\)</span> by <span class="math notranslate nohighlight">\(n\)</span> transition matrix, where entry <span class="math notranslate nohighlight">\({i,j}\)</span> is the probability of moving from state <span class="math notranslate nohighlight">\(i\)</span> to state <span class="math notranslate nohighlight">\(j\)</span> in a single period. Thus, the entries of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> are all nonnegative and</p>
<div class="math notranslate nohighlight">
\[\mathbb{P} \textbf{1}_n = \textbf{1}_n,\]</div>
<p>where <span class="math notranslate nohighlight">\(\textbf{1}_n\)</span> is an <span class="math notranslate nohighlight">\(n\)</span>-dimensional vector of ones.</p>
<p>Let <span class="math notranslate nohighlight">\(\textbf{q}\)</span> be an <span class="math notranslate nohighlight">\(n\)</span>-dimensional vector of probabilities. Stationarity requires that</p>
<div class="math notranslate nohighlight" id="equation-qstab">
<span class="eqno">(2.8)<a class="headerlink" href="#equation-qstab" title="Link to this equation">#</a></span>\[\textbf{q}'\mathbb{P} = \textbf{q}',\]</div>
<p>where <span class="math notranslate nohighlight">\(\textbf{q}\)</span> is a row eigenvector (also called a left eigenvector) of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> associated with a unit eigenvalue.</p>
<p>We use a vector <span class="math notranslate nohighlight">\(\textbf{f}\)</span> to represent a function from the state space to the real line. Each coordinate of <span class="math notranslate nohighlight">\(\textbf{f}\)</span> gives the value of the function at the corresponding coordinate vector. Then the conditional expectation operator <span class="math notranslate nohighlight">\(\mathbb{T}\)</span> can be represented in terms of the transition matrix <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>:</p>
<div class="math notranslate nohighlight">
\[E(\textbf{f} \cdot X_{t+1} | X_t = x) = (\mathbb{T}\textbf{f}) \cdot x = x'\mathbb{P} \textbf{f}.\]</div>
<p>Now consider column eigenvectors called “right eigenvectors” of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> that are associated with a unit eigenvalue.</p>
<div class="proof theorem admonition" id="prop:finiteP1">
<p class="admonition-title"><span class="caption-number">Theorem 2.2 </span></p>
<section class="theorem-content" id="proof-content">
<p>Suppose that the only solutions to</p>
<div class="math notranslate nohighlight">
\[{\mathbb T} {\bf f} = {\bf f}\]</div>
<p>are of the form <span class="math notranslate nohighlight">\({\bf f} \propto \textbf{1}_n\)</span>, where <span class="math notranslate nohighlight">\(\propto\)</span> means ‘proportional to’.
Then we can construct a process that is stationary and ergodic by initializing the process with density <span class="math notranslate nohighlight">\({\bf q}\)</span> determined by equation <a class="reference internal" href="#equation-qstab">(2.8)</a>.</p>
</section>
</div><p>We can weaken the <a class="reference internal" href="#prop:finiteP1">Theorem 2.2</a> sufficient condition for stationarity and ergodicity to allow nonconstant right eigenvectors. This weakening is of interest when there are multiple stationary distributions.</p>
<div class="proof theorem admonition" id="prop:finiteP2">
<p class="admonition-title"><span class="caption-number">Theorem 2.3 </span></p>
<section class="theorem-content" id="proof-content">
<p>Assume that there exists a real number <span class="math notranslate nohighlight">\(\mathbf{r}\)</span> such that the right eigenvector <span class="math notranslate nohighlight">\(\mathbf{f}\)</span> and a stationary distribution <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> satisfy</p>
<div class="math notranslate nohighlight">
\[\min_{\sf r} \sum_{i=1}^n ({\sf f}_i - {\sf r})^2 {\sf q}_i = 0.\]</div>
<p>Then the process is stationary and ergodic.</p>
</section>
</div><p>Notice that if <span class="math notranslate nohighlight">\({\sf q}_i\)</span> is zero, the contribution of <span class="math notranslate nohighlight">\({\sf f}_i\)</span> to the least squares objective can be neglected. This allows for non-constant <span class="math notranslate nohighlight">\(\mathbf{f}\)</span>’s, albeit in a limited way.</p>
<p>Three examples illustrate ideas in these propositions.</p>
<div class="proof example admonition" id="ex:MC1">
<p class="admonition-title"><span class="caption-number">Example 2.4 </span></p>
<section class="example-content" id="proof-content">
<p>Recast <a class="reference internal" href="example_out_c1_v2.html#ex:period">Example 1.2</a> as a Markov chain with transition matrix
<span class="math notranslate nohighlight">\({\mathbb P}=\begin{bmatrix}0 &amp; 1 \cr 1 &amp; 0\end{bmatrix}\)</span>. This chain has a unique stationary distribution <span class="math notranslate nohighlight">\( q=\begin{bmatrix}.5 &amp; .5 \end{bmatrix}'\)</span> and the invariant functions are <span class="math notranslate nohighlight">\(\begin{bmatrix} {\sf r} &amp; {\sf r} \end{bmatrix}'\)</span> for any scalar <span class="math notranslate nohighlight">\({\sf r}\)</span>. Therefore, the process initiated from the stationary distribution is ergodic. The process is periodic with period two since the matrix <span class="math notranslate nohighlight">\({\mathbb P}^2\)</span> is an identity matrix and all two dimensional vectors are eigenvectors associated with a unit eigenvalue.</p>
</section>
</div><div class="proof example admonition" id="ex:MC2">
<p class="admonition-title"><span class="caption-number">Example 2.5 </span></p>
<section class="example-content" id="proof-content">
<p>Recast <a class="reference internal" href="example_out_c1_v2.html#ex:invariant">Example 1.3</a> as a Markov chain with transition matrix
<span class="math notranslate nohighlight">\({\mathbb P}=\begin{pmatrix}1 &amp; 0 \\ 0 &amp; 1\end{pmatrix}\)</span>. This chain has a continuum of stationary distributions <span class="math notranslate nohighlight">\(\pi \begin{pmatrix}1 \\ 0 \end{pmatrix}+ (1- \pi )\begin{pmatrix}0 \\ 1 \end{pmatrix}\)</span> for any <span class="math notranslate nohighlight">\(\pi \in [0,1]\)</span> and invariant functions <span class="math notranslate nohighlight">\(\begin{pmatrix} {\sf r}_1 \\ {\sf r}_2 \end{pmatrix}\)</span> for any scalars <span class="math notranslate nohighlight">\({\sf r}_1, {\sf r}_2\)</span>. Therefore, when <span class="math notranslate nohighlight">\(\pi \in (0,1)\)</span> the process is not ergodic because if <span class="math notranslate nohighlight">\({\sf r}_1 \ne {\sf r}_2\)</span> the resulting invariant function fails to be constant across states that have positive probability under the stationary distribution associated with <span class="math notranslate nohighlight">\(\pi \in (0,1)\)</span>. When <span class="math notranslate nohighlight">\(\pi \in (0,1)\)</span>, nature chooses state <span class="math notranslate nohighlight">\(i=1\)</span> or <span class="math notranslate nohighlight">\(i=2\)</span> with probabilities <span class="math notranslate nohighlight">\(\pi, 1-\pi\)</span>, respectively, at time <span class="math notranslate nohighlight">\(0\)</span>. Thereafter, the chain remains stuck in the realized time <span class="math notranslate nohighlight">\(0\)</span> state. Its failure ever to visit the unrealized state prevents the sample average from converging to the population mean of an arbitrary function of the state.</p>
</section>
</div><div class="proof example admonition" id="ex:MC3">
<p class="admonition-title"><span class="caption-number">Example 2.6 </span></p>
<section class="example-content" id="proof-content">
<p>A Markov chain with transition matrix</p>
<div class="math notranslate nohighlight">
\[{\mathbb P}=\begin{bmatrix}.8 &amp; .2 &amp; 0  \cr .1  &amp; .9 &amp; 0 \cr
               0 &amp; 0 &amp; 1\end{bmatrix}\]</div>
<p>has a continuum of stationary distributions</p>
<div class="math notranslate nohighlight">
\[\pi \begin{bmatrix} {1\over 3} &amp; {2 \over 3} &amp; 0 \end{bmatrix}'
+(1- \pi) \begin{bmatrix} 0 &amp; 0 &amp; 1 \end{bmatrix}'\]</div>
<p>for <span class="math notranslate nohighlight">\(\pi \in [0,1]\)</span> and invariant functions</p>
<div class="math notranslate nohighlight">
\[\begin{bmatrix} {\sf r}_1  &amp;  {\sf r}_1 &amp; {\sf r}_2 \end{bmatrix}'\]</div>
<p>for any scalars <span class="math notranslate nohighlight">\({\sf r}_1, {\sf r}_2\)</span>. Under any stationary distribution associated with <span class="math notranslate nohighlight">\(\pi \in (0,1)\)</span>,
the chain is not ergodic because some invariant functions are not constant with probability one. But under stationary distributions associated with <span class="math notranslate nohighlight">\(\pi =1\)</span> or <span class="math notranslate nohighlight">\(\pi=0\)</span>, the
chain is ergodic.</p>
</section>
</div></section>
<section id="limited-dependence">
<h2><span class="section-number">2.7. </span>Limited Dependence<a class="headerlink" href="#limited-dependence" title="Link to this heading">#</a></h2>
<p>Recall the conditional expectations operator <span class="math notranslate nohighlight">\({\mathbb T}\)</span> defined in equation <a class="reference internal" href="#equation-eqn-toperatordef">(2.1)</a> for a space <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span> of functions <span class="math notranslate nohighlight">\(f\)</span> of a Markov process with transition probability <span class="math notranslate nohighlight">\(P\)</span> and stationary distribution <span class="math notranslate nohighlight">\(Q\)</span> and for which <span class="math notranslate nohighlight">\(f(X_t)\)</span> has a finite second moment under <span class="math notranslate nohighlight">\(Q\)</span>:</p>
<div class="math notranslate nohighlight">
\[{\mathbb T} f (x) = E \left[ f(X_{t+1}) \mid  X_t = x \right] = \int_{\{x^* \in {\mathcal X}\}}  f(x^*) P(d x^*|x) .\]</div>
<p>We suppose that under the stationary distribution <span class="math notranslate nohighlight">\(Q\)</span>, the process is ergodic.</p>
<p>Because it is often useful to work with random variables that have been ‘centered’ by subtracting out their means, we define the following subspace of <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-def-n">
<span class="eqno">(2.9)<a class="headerlink" href="#equation-def-n" title="Link to this equation">#</a></span>\[{\mathcal N} = \left\{ f \in {\mathcal L}^2 :  \int f(x) Q(dx)   = 0 \right\}.\]</div>
<p>We use the same norm <span class="math notranslate nohighlight">\(\| f \| = \left[ \int f(x)^2 Q(dx)\right]^{1/2}\)</span> on both <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span> and <span class="math notranslate nohighlight">\({\mathcal N}\)</span> too.</p>
<div class="proof theorem admonition" id="theorem-21">
<p class="admonition-title"><span class="caption-number">Theorem 2.4 </span></p>
<section class="theorem-content" id="proof-content">
<p>The conditional expectation operator <span class="math notranslate nohighlight">\(\mathbb{T}\)</span> is said to be a <em>strong contraction</em> on <span class="math notranslate nohighlight">\(\mathcal{N}\)</span> if there exists <span class="math notranslate nohighlight">\(0 &lt; \rho &lt; 1\)</span> such that</p>
<div class="math notranslate nohighlight">
\[\| \mathbb{T} f \| \le \rho \| f \|\]</div>
<p>for all <span class="math notranslate nohighlight">\(f \in \mathcal{N}\)</span>.</p>
</section>
</div><p>When <span class="math notranslate nohighlight">\(\mathbb{T}^m\)</span> is a strong contraction for some positive integer <span class="math notranslate nohighlight">\(m\)</span> and some <span class="math notranslate nohighlight">\(\rho \in (0,1)\)</span>, the Markov process is said to be <span class="math notranslate nohighlight">\(\rho\)</span>-mixing conditioned on the invariant events.</p>
<div class="proof remark admonition" id="remark-22">
<p class="admonition-title"><span class="caption-number">Remark 2.3 </span></p>
<section class="remark-content" id="proof-content">
<p><span class="math notranslate nohighlight">\({\mathbb T}\)</span> being a strong contraction on <span class="math notranslate nohighlight">\({\mathcal N}\)</span> limits intertemporal dependence of the Markov process <span class="math notranslate nohighlight">\(\{X_t\}\)</span>.</p>
</section>
</div><p>Let <span class="math notranslate nohighlight">\({\mathbb I}\)</span> be the identity operator. When the conditional expectation operator <span class="math notranslate nohighlight">\({\mathbb T}\)</span> is a strong contraction, the operator <span class="math notranslate nohighlight">\(({\mathbb I} - {\mathbb T})^{-1}\)</span> is well defined, bounded on <span class="math notranslate nohighlight">\({\mathcal N}\)</span>, and equal to the geometric sum:<a class="footnote-reference brackets" href="#geometricseries" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight">
\[\left({\mathbb I} - {\mathbb T}\right)^{-1} f(x) = \sum_{j=0}^\infty {\mathbb T}^j f(x) = \sum_{j=0}^\infty E \left[ f(X_{t+j}) \vert X_t = x \right].\]</div>
<div class="proof example admonition" id="example-23">
<p class="admonition-title"><span class="caption-number">Example 2.7 </span></p>
<section class="example-content" id="proof-content">
<p>Consider the Markov chain setting of subsection <a class="reference internal" href="#subsec-chain"><span class="std std-ref">Finite-State Markov Chains</span></a> with a transition matrix <span class="math notranslate nohighlight">\({\mathbb P}\)</span>.
A stationary density <span class="math notranslate nohighlight">\({\bf q}\)</span> is a nonnegative vector that satisfies</p>
<div class="math notranslate nohighlight">
\[{\bf q}' {\mathbb P} = {\bf q}'\]</div>
<p>and <span class="math notranslate nohighlight">\({\bf q} \cdot \textbf{1}_n = 1 \)</span>.
If the only column eigenvector of <span class="math notranslate nohighlight">\({\mathbb T}\)</span> associated with a unit eigenvalue is constant over states <span class="math notranslate nohighlight">\(i\)</span> for which <span class="math notranslate nohighlight">\({\sf q}_i &gt; 0\)</span>, then the process is ergodic.
If in addition, the only eigenvector of <span class="math notranslate nohighlight">\({\mathbb P}\)</span> that is associated with an eigenvalue that has a unit norm
(the unit eigenvalue might be complex) is constant over states <span class="math notranslate nohighlight">\(i\)</span> for which <span class="math notranslate nohighlight">\({\sf q}_i &gt; 0\)</span>, then <span class="math notranslate nohighlight">\({\mathbb T}^m\)</span> is a strong contraction for
some integer <span class="math notranslate nohighlight">\(m \geq 1\)</span>.<a class="footnote-reference brackets" href="#gelfand" id="id11" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a>
This implies that the process is ergodic. It also rules out the presence of periodic components that can be forecast perfectly.</p>
</section>
</div></section>
<section id="limits-of-multi-period-forecasts">
<span id="sec-limitapprox"></span><h2><span class="section-number">2.8. </span>Limits of Multi-Period Forecasts<a class="headerlink" href="#limits-of-multi-period-forecasts" title="Link to this heading">#</a></h2>
<p>When a Markov process is aperiodic, there are interesting situations in which</p>
<div class="math notranslate nohighlight" id="equation-limitexp">
<span class="eqno">(2.10)<a class="headerlink" href="#equation-limitexp" title="Link to this equation">#</a></span>\[\lim_{j \rightarrow \infty} {\mathbb T}^j f(x) =  {\sf r}\]</div>
<p>for some <span class="math notranslate nohighlight">\({\sf r} \in {\mathbb R}\)</span>, where convergence is either pointwise in <span class="math notranslate nohighlight">\(x\)</span> or in the <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span> norm.
Limit <a class="reference internal" href="#equation-limitexp">(2.10)</a> asserts that long-run forecasts do not depend on the current Markov state. <span id="id12">Meyn and Tweedie [<a class="reference internal" href="cite.html#id333" title="S. Meyn and R. Tweedie. Markov Chains and Stochastic Stability. Springer-Verlag, London, 1993.">1993</a>]</span> provide a comprehensive treatment of such convergence.
Let <span class="math notranslate nohighlight">\(Q\)</span> be a stationary distribution. Then it is necessarily true that</p>
<div class="math notranslate nohighlight">
\[\int {\mathbb T}^j f(x) Q(dx)  = \int f(x) Q(dx)\]</div>
<p>for all <span class="math notranslate nohighlight">\(j\)</span>. Thus,</p>
<div class="math notranslate nohighlight">
\[{\sf r} = \int f(x) Q (dx),\]</div>
<p>so that the limiting forecast is necessarily the mathematical expectation of <span class="math notranslate nohighlight">\(f(x)\)</span> under a stationary distribution.
Here we have assumed that the limit point is a number and not a random variable; we have not assumed that the stationary distribution is unique.</p>
<p>Notice that if <a class="reference internal" href="#equation-limitexp">(2.10)</a> is satisfied, then any function <span class="math notranslate nohighlight">\(f\)</span> that satisfies</p>
<div class="math notranslate nohighlight">
\[{\mathbb T} f = f\]</div>
<p>is necessarily constant with probability one. Also, if <span class="math notranslate nohighlight">\(\int f(x) Q(dx) = 0\)</span> and convergence is sufficiently fast, then</p>
<div class="math notranslate nohighlight" id="equation-eq-sum-limit">
<span class="eqno">(2.11)<a class="headerlink" href="#equation-eq-sum-limit" title="Link to this equation">#</a></span>\[\lim_{N \rightarrow \infty} \sum_{j=0}^N {\mathbb T}^j f(x)\]</div>
<p>is a well-defined function of the Markov state. We shall construct the limit in <a class="reference internal" href="#equation-eq-sum-limit">(2.11)</a> when we extract martingales from additive functionals in chapter <a class="reference internal" href="example_out_c4_v2.html#chap-add"><span class="std std-ref">Processes with Markovian increments</span></a>.</p>
<p>A set of sufficient conditions for the convergence outcome</p>
<div class="math notranslate nohighlight" id="equation-converge">
<span class="eqno">(2.12)<a class="headerlink" href="#equation-converge" title="Link to this equation">#</a></span>\[\lim_{j \rightarrow \infty} {\mathbb T}^j f (x^*) \rightarrow \int f(x) Q(dx)\]</div>
<p>for each <span class="math notranslate nohighlight">\(x^* \in {\mathcal X}\)</span> and each bounded <span class="math notranslate nohighlight">\(f\)</span> is:<a class="footnote-reference brackets" href="#convergence-footnote" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a></p>
<p id="cond-suffice"><strong>Conditions:</strong></p>
<p>A Markov process with stationary distribution <span class="math notranslate nohighlight">\(Q\)</span> satisfies:</p>
<p id="condi">(i) For any <span class="math notranslate nohighlight">\(f \ge 0\)</span> such that <span class="math notranslate nohighlight">\(\int f(x) Q(dx) &gt; 0\)</span>, <span class="math notranslate nohighlight">\({\mathbb M}_p f(x) &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(x \in {\mathcal X}\)</span> with <span class="math notranslate nohighlight">\(Q\)</span> measure one and all positive integers <span class="math notranslate nohighlight">\(p \ge 0\)</span>, where the operator <span class="math notranslate nohighlight">\({\mathbb M}_p\)</span> is defined in equation not provided.</p>
<p id="fellercond">(ii) <span class="math notranslate nohighlight">\({\mathbb T}\)</span> maps bounded continuous functions into bounded continuous functions, i.e., the Markov process is said to satisfy the Feller property.</p>
<p id="condsupport">(iii) The support of <span class="math notranslate nohighlight">\(Q\)</span> has a nonempty interior in <span class="math notranslate nohighlight">\({\mathcal X}\)</span>.</p>
<p id="drift">(iv) <span class="math notranslate nohighlight">\({\mathbb T} V(x) - V(x) \le -1\)</span> outside a compact subset of <span class="math notranslate nohighlight">\({\mathcal X}\)</span> for some nonnegative function <span class="math notranslate nohighlight">\(V\)</span>.</p>
<p>We encountered condition <a class="reference internal" href="#condi"><span class="std std-ref">(i)</span></a> in our section <a class="reference internal" href="#sec-markergodic"><span class="std std-ref">Ergodic Markov Processes</span></a> of Markov processes that are ergodic and aperiodic.
Condition <a class="reference internal" href="#drift"><span class="std std-ref">(iv)</span></a> is a <strong>drift condition</strong> for stability that requires that we find a function <span class="math notranslate nohighlight">\(V\)</span> that satisfies the requisite inequality. Heuristically, the drift condition says that outside a compact subset of the state space, application of the conditional expectation operator pushes the function inward. The choice of <span class="math notranslate nohighlight">\(-1\)</span> as a comparison point is made only for convenience, since we can always multiply the function <span class="math notranslate nohighlight">\(V\)</span> by a number greater than one. Thus, <span class="math notranslate nohighlight">\(-1\)</span> could be replaced by any strictly negative number. In section <a class="reference internal" href="#sec-var44"><span class="std std-ref">Vector Autoregressions</span></a>, we will apply <a class="reference internal" href="#cond-suffice"><span class="std std-ref">Conditions</span></a> to verify ergodicity of a vector autoregression.</p>
</section>
<section id="vector-autoregressions">
<span id="sec-var44"></span><h2><span class="section-number">2.9. </span>Vector Autoregressions<a class="headerlink" href="#vector-autoregressions" title="Link to this heading">#</a></h2>
<p>A square matrix <span class="math notranslate nohighlight">\(\mathbb{A}\)</span> is said to be <em>stable</em> when all of its eigenvalues have absolute values that are strictly less than one. For a stable <span class="math notranslate nohighlight">\(\mathbb{A}\)</span>, suppose that</p>
<div class="math notranslate nohighlight">
\[X_{t+1} = \mathbb{A} X_t + \mathbb{B} W_{t+1},\]</div>
<p>where <span class="math notranslate nohighlight">\(\{ W_{t+1} : t = 1,2,... \}\)</span> is an i.i.d.~sequence of multivariate normally distributed random vectors with mean vector zero and covariance matrix <span class="math notranslate nohighlight">\(I\)</span> and that <span class="math notranslate nohighlight">\(X_0 \sim \mathcal{N}(\mu_0, \Sigma_0)\)</span>. This specification constitutes a first-order <em>vector autoregression</em>.</p>
<p>Let <span class="math notranslate nohighlight">\(\mu_t = E X_t\)</span>. Notice that</p>
<div class="math notranslate nohighlight">
\[\mu_{t+1} = \mathbb{A} \mu_t.\]</div>
<p>The mean <span class="math notranslate nohighlight">\(\mu\)</span> of a stationary distribution satisfies</p>
<div class="math notranslate nohighlight">
\[\mu = \mathbb{A} \mu.\]</div>
<p>Because we have assumed that <span class="math notranslate nohighlight">\(\mathbb{A}\)</span> is a stable matrix, <span class="math notranslate nohighlight">\(\mu =0\)</span> is the only solution of <span class="math notranslate nohighlight">\((\mathbb{A} - \mathbb{I}) \mu =0\)</span>, so the mean of the stationary distribution is <span class="math notranslate nohighlight">\(\mu = 0\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(\Sigma_{t} = E(X_t - \mu_t) (X_t - \mu_t)'\)</span> be the covariance matrix of <span class="math notranslate nohighlight">\(X_t\)</span>. Then</p>
<div class="math notranslate nohighlight">
\[\Sigma_{t+1} = \mathbb{A} \Sigma_t \mathbb{A}' + \mathbb{B}\mathbb{B}'.\]</div>
<p>For <span class="math notranslate nohighlight">\(\Sigma_t = \Sigma\)</span> to be invariant over time, it must satisfy the discrete Lyapunov equation</p>
<div class="math notranslate nohighlight" id="equation-eq-sylvester">
<span class="eqno">(2.13)<a class="headerlink" href="#equation-eq-sylvester" title="Link to this equation">#</a></span>\[\Sigma = \mathbb{A} \Sigma \mathbb{A}' + \mathbb{B}\mathbb{B}'.\]</div>
<p>When <span class="math notranslate nohighlight">\(\mathbb{A}\)</span> is a stable matrix, this equation has a unique solution for a positive semidefinite matrix <span class="math notranslate nohighlight">\(\Sigma\)</span>.</p>
<p>Suppose that <span class="math notranslate nohighlight">\(\Sigma_0 = 0\)</span> (a matrix of zeros) and for <span class="math notranslate nohighlight">\(t \geq 1\)</span> define the matrix</p>
<div class="math notranslate nohighlight">
\[\Sigma_t = \sum_{j=0}^{t-1} \mathbb{A}^j \mathbb{B}\mathbb{B}'(\mathbb{A}^j)'.\]</div>
<p>The limit of the sequence <span class="math notranslate nohighlight">\(\{\Sigma_t\}_{t=0}^{\infty}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\Sigma = \sum_{j=0}^{\infty} \mathbb{A}^j \mathbb{B}\mathbb{B}'(\mathbb{A}^j)',\]</div>
<p>which can be verified to satisfy Lyapunov equation <a class="reference internal" href="#equation-eq-sylvester">(2.13)</a>. Thus, <span class="math notranslate nohighlight">\(\Sigma\)</span> equals the covariance matrix of the stationary distribution.<a class="footnote-reference brackets" href="#covmatrix" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight">
\[\mu_t = \mathbb{A}^t \mu_0,\]</div>
<p>converges to zero, the mean of the stationary distribution.</p>
<p>The linear structure implies that the stationary distribution is Gaussian with mean <span class="math notranslate nohighlight">\(\mu\)</span> and covariance matrix <span class="math notranslate nohighlight">\(\Sigma\)</span>. To verify ergodicity, we suppose that the covariance matrix <span class="math notranslate nohighlight">\(\Sigma\)</span> of the stationary distribution has full rank and verify <a class="reference internal" href="#cond-suffice"><span class="std std-ref">Conditions</span></a>. Restriction (condition <a class="reference internal" href="#condsupport"><span class="std std-ref">(iii)</span></a>) of <a class="reference internal" href="#cond-suffice"><span class="std std-ref">Conditions</span></a> is satisfied. Furthermore, <span class="math notranslate nohighlight">\(\Sigma_t\)</span> has full rank for some <span class="math notranslate nohighlight">\(t\)</span>, which guarantees that the process is irreducible and aperiodic so that restriction (condition <a class="reference internal" href="#condi"><span class="std std-ref">(i)</span></a>) is satisfied. As a candidate for <span class="math notranslate nohighlight">\(V(x)\)</span> in condition <a class="reference internal" href="#drift"><span class="std std-ref">(iv)</span></a>, take <span class="math notranslate nohighlight">\(V(x) = |x|^2\)</span>. Then</p>
<div class="math notranslate nohighlight">
\[\mathbb{T} V(x) = x'\mathbb{A}'\mathbb{A} x + \text{trace}(\mathbb{B}'\mathbb{B})\]</div>
<p>so</p>
<div class="math notranslate nohighlight">
\[\mathbb{T} V(x) - V(x) = x'(\mathbb{A}'\mathbb{A} - \mathbb{I})x + \text{trace}(\mathbb{B}'\mathbb{B}).\]</div>
<p>That <span class="math notranslate nohighlight">\(\mathbb{A}\)</span> is a stable matrix implies that <span class="math notranslate nohighlight">\(\mathbb{A}'\mathbb{A} - \mathbb{I}\)</span> is negative definite, so that drift restriction (condition <a class="reference internal" href="#drift"><span class="std std-ref">iv</span></a>) of <a class="reference internal" href="#cond-suffice"><span class="std std-ref">Conditions</span></a> is satisfied for <span class="math notranslate nohighlight">\(|x|\)</span> sufficiently large.<a class="footnote-reference brackets" href="#feller" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></a></p>
<p>Thus, having verified <a class="reference internal" href="#cond-suffice"><span class="std std-ref">Conditions</span></a>, we have verified the ergodicity of the VAR.</p>
</section>
<section id="estimating-vector-autoregressions">
<h2><span class="section-number">2.10. </span>Estimating Vector Autoregressions<a class="headerlink" href="#estimating-vector-autoregressions" title="Link to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(Y_{t+1}\)</span> be one of the entries of <span class="math notranslate nohighlight">\(X_{t+1}\)</span>, and consider the regression equation:</p>
<div class="math notranslate nohighlight">
\[Y_{t+1} = \beta \cdot X_{t} + U_{t+1},\]</div>
<p>where <span class="math notranslate nohighlight">\(U_{t+1}\)</span> is a least squares residual. To express uncertainty about <span class="math notranslate nohighlight">\(\beta\)</span> in the spirit of chapter <a class="reference internal" href="example_out_c1_v2.html#chap-process"><span class="std std-ref">Stochastic Processes and Laws of Large Numbers</span></a>, we allow it to be random. Letting <span class="math notranslate nohighlight">\({\mathfrak J}\)</span> be the set of invariant events, we presume that the <em>random vector</em> <span class="math notranslate nohighlight">\(\beta\)</span> is measurable with respect to <span class="math notranslate nohighlight">\({\mathfrak J}\)</span>, meaning that it is revealed by events in <span class="math notranslate nohighlight">\({\mathfrak J}\)</span>.  For the case in which we have <span class="math notranslate nohighlight">\(n\)</span> possibly different models, the invariant events reveal which of the models generates the data.</p>
<p>The first-order condition for minimizing the expected value of <span class="math notranslate nohighlight">\(U_{t+1}^2\)</span> requires that the regression residual <span class="math notranslate nohighlight">\(U_{t+1}\)</span> be orthogonal to <span class="math notranslate nohighlight">\(X_t\)</span>:</p>
<div class="math notranslate nohighlight">
\[E\left( X_t U_{t+1} \vert {\mathfrak J} \right) = 0.\]</div>
<p>Then</p>
<div class="math notranslate nohighlight" id="equation-eq-lsorth101">
<span class="eqno">(2.14)<a class="headerlink" href="#equation-eq-lsorth101" title="Link to this equation">#</a></span>\[E\left( X_{t}Y_{t+1} \vert {\mathfrak J} \right) = E\left[ X_{t} (X_{t})' \vert {\mathfrak J} \right] \beta ,\]</div>
<p>which uniquely pins down the regression coefficient <span class="math notranslate nohighlight">\(\beta\)</span> provided that the matrix <span class="math notranslate nohighlight">\(E\left[ X_t (X_t)' \vert {\mathfrak J} \right]\)</span> is nonsingular with probability one. Notice that</p>
<div class="math notranslate nohighlight">
\[{\frac 1 N}\sum_{t=1}^N  X_{t} Y_{t+1} \rightarrow E\left( X_{t} Y_{t+1} \vert {\mathfrak J} \right)  \]</div>
<div class="math notranslate nohighlight">
\[{\frac 1 N}\sum_{t=1}^N  X_{t} (X_{t})' \rightarrow E\left( X_{t} (X_{t})' \vert {\mathfrak J} \right),\]</div>
<p>where convergence is with probability one. Thus, from equation <a class="reference internal" href="#equation-eq-lsorth101">(2.14)</a> it follows that a consistent estimator of <span class="math notranslate nohighlight">\(\beta\)</span> is a <span class="math notranslate nohighlight">\(b_N\)</span> that satisfies</p>
<div class="math notranslate nohighlight">
\[{\frac 1 N}\sum_{t=1}^N  X_{t} Y_{t+1} = {\frac 1 N}\sum_{t=1}^N  X_{t} (X_{t})' b_N.\]</div>
<p>Solving for <span class="math notranslate nohighlight">\(b_N\)</span> gives the familiar least squares formula:</p>
<div class="math notranslate nohighlight">
\[b_N = \left[\sum_{t=1}^N  X_{t} (X_{t})' \right]^{-1} \sum_{t=1}^N  X_{t} Y_{t+1}.\]</div>
<p>Note how statements about the consistency of <span class="math notranslate nohighlight">\(b_N\)</span> are conditioned on <span class="math notranslate nohighlight">\({\mathfrak J}\)</span>.  This conditioning is necessary when we do not which among a family vector autoregressions generates the data.</p>
</section>
<section id="inventing-a-past-again">
<span id="sec-var-inf-past"></span><h2><span class="section-number">2.11. </span>Inventing a Past Again<a class="headerlink" href="#inventing-a-past-again" title="Link to this heading">#</a></h2>
<p>In section <a class="reference internal" href="example_out_c1_v2.html#sec-inventing-past"><span class="std std-ref">Inventing an Infinite Past</span></a>, we invented an infinite past for a stochastic process. Here we invent an infinite past for a vector autoregression in a way that is equivalent to drawing an initial condition <span class="math notranslate nohighlight">\(X_0\)</span> at time <span class="math notranslate nohighlight">\(t=0\)</span> from the stationary distribution <span class="math notranslate nohighlight">\({\mathcal N}(0, \Sigma_\infty)\)</span>, where <span class="math notranslate nohighlight">\(\Sigma_\infty\)</span> solves the discrete Lyapunov equation <a class="reference internal" href="#equation-eq-sylvester">(2.13)</a>, namely, <span class="math notranslate nohighlight">\(\Sigma_\infty = {\mathbb A} \Sigma_\infty {\mathbb A}' + {\mathbb B} {\mathbb B}' \)</span>.</p>
<p>Thus, consider the vector autoregression</p>
<div class="math notranslate nohighlight">
\[X_{t+1} = {\mathbb A} X_t + {\mathbb B} W_{t+1}\]</div>
<p>where <span class="math notranslate nohighlight">\({\mathbb A}\)</span> is a stable matrix, <span class="math notranslate nohighlight">\(\{W_{t+1}\}_{t=-\infty}^\infty\)</span> is now a two-sided infinite sequence of i.i.d. <span class="math notranslate nohighlight">\({\mathcal N}(0,I)\)</span> random vectors, and <span class="math notranslate nohighlight">\(t\)</span> is an integer. We can solve this difference equation backwards to get the moving average representation</p>
<div class="math notranslate nohighlight">
\[X_{t} = \sum_{j=0}^\infty {\mathbb A}^j {\mathbb B} W_{t -j} .\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[E\left[X_t \left(X_t \right)'\right] = \sum_{j=0}^\infty {\mathbb A}^j {\mathbb B} {\mathbb B}' \left( {\mathbb A}^j \right)' = \Sigma_\infty\]</div>
<p>where  <span class="math notranslate nohighlight">\(\Sigma_\infty\)</span> is also the unique positive semidefinite matrix that solves <span class="math notranslate nohighlight">\(\Sigma_\infty = {\mathbb A} \Sigma_\infty {\mathbb A}' + {\mathbb B} {\mathbb B}'\)</span>.</p>
</section>
<section id="local-approximation-of-nonlinear-markov-processes">
<h2><span class="section-number">2.12. </span>Local Approximation of Nonlinear Markov Processes<a class="headerlink" href="#local-approximation-of-nonlinear-markov-processes" title="Link to this heading">#</a></h2>
<p>We utilize the small noise expansion method described by <span id="id16">Lombardo and Uhlig [<a class="reference internal" href="cite.html#id307" title="G Lombardo and H Uhlig. A Theory of Pruning. International Economic Review, 59(4):1825–1836, jul 2018.">2018</a>]</span>. This technique recursively generates linear difference equations at each order of approximation. We present steps leading to a second-order approximation for a scalar Markov process <span class="math notranslate nohighlight">\(\{X_t\}\)</span>.</p>
<p>We start with a multivariate nonlinear Markov process:</p>
<div class="math notranslate nohighlight">
\[X_{t+1} = \psi(X_t, W_{t+1})  \]</div>
<p>where <span class="math notranslate nohighlight">\(\{ W_{t+1} : t \ge 0\}\)</span> is an i.i.d. multivariate sequence of shocks. To set the stage for constructing our approximations to the Markov process, we first create a <em>family</em> of processes in which the process is embedded. The family is indexed by a scalar parameter <span class="math notranslate nohighlight">\({\sf q}\)</span> and created via the following equation</p>
<div class="math notranslate nohighlight" id="equation-embed">
<span class="eqno">(2.15)<a class="headerlink" href="#equation-embed" title="Link to this equation">#</a></span>\[X_{t+1} = \psi(X_t, {\sf q} W_{t+1}).    \]</div>
<p>A process <span class="math notranslate nohighlight">\(\{ X_t : t\ge 0\}\)</span> defined in this way depends on <span class="math notranslate nohighlight">\({\sf q}\)</span>, so as we vary <span class="math notranslate nohighlight">\({\sf q}\)</span> we sweep out a family of Markov processes. We shall compute an approximation to the original <span class="math notranslate nohighlight">\(\{X_t\}\)</span> process that takes the form</p>
<div class="math notranslate nohighlight">
\[X_t \approx X_t^0 + {\sf q} X_t^1 + \frac {({\sf q})^2} 2 X_t^2\]</div>
<p>for <span class="math notranslate nohighlight">\(t \ge 0\)</span>. Here for each <span class="math notranslate nohighlight">\(j=0,1,2\)</span>, <span class="math notranslate nohighlight">\(\{X_t^j : t \ge 0\}\)</span> is itself a stationary process. Our calculations are recursive in the sense that first we construct an autonomous invariant process <span class="math notranslate nohighlight">\(\{X_t^0\}\)</span>. Next we construct a process <span class="math notranslate nohighlight">\(\{X_t^1\}\)</span> that depends on <span class="math notranslate nohighlight">\(\{X_t^0\}\)</span> and the shock process <span class="math notranslate nohighlight">\(\{W_{t+1}\}\)</span> and takes the form of a vector autoregression; finally, we construct process <span class="math notranslate nohighlight">\(\{X_t^2\}\)</span> as a solution to a nonlinear difference equation with forcing functions that depend on the <span class="math notranslate nohighlight">\(\{X_t^1\}\)</span> process and the shock process <span class="math notranslate nohighlight">\(\{W_{t+1}\}\)</span>.</p>
<section id="order-zero-approximation">
<h3><span class="section-number">2.12.1. </span>Order zero approximation<a class="headerlink" href="#order-zero-approximation" title="Link to this heading">#</a></h3>
<p>We begin with an order zero approximation obtained by setting <span class="math notranslate nohighlight">\({\sf q} = 0\)</span> and studying:</p>
<div class="math notranslate nohighlight">
\[X_{t+1}^0 = \psi(X_t^0 , 0).  \]</div>
<p>We look for an invariant solution <span class="math notranslate nohighlight">\(X_t^0 = {\overline x}\)</span> for <span class="math notranslate nohighlight">\(t \ge 0\)</span> where</p>
<div class="math notranslate nohighlight">
\[{\overline x} = \psi\left({\overline x}, 0\right) \]</div>
<p>Moreover, suppose that this solution is “locally” stable in the sense that the matrix</p>
<div class="math notranslate nohighlight">
\[\psi_x  = \frac {\partial \psi}{\partial x} \left( {\overline x},0 \right) \]</div>
<p>is stable. In applications to be studied below, we shall encounter some situations in which the invariant point <span class="math notranslate nohighlight">\({\overline x}\)</span> is unique, and others in which it is not. Both entail interesting economics.</p>
</section>
<section id="order-one-approximation">
<h3><span class="section-number">2.12.2. </span>Order one approximation<a class="headerlink" href="#order-one-approximation" title="Link to this heading">#</a></h3>
<p>We obtain a recursive representation for <span class="math notranslate nohighlight">\(\{ X_t^1 : t\ge 0\}\)</span> by differentiating <a class="reference internal" href="#equation-embed">(2.15)</a> and applying the chain rule</p>
<div class="math notranslate nohighlight">
\[\frac {d X_{t+1}}{d {\sf q}} = \frac {\partial \psi}{\partial x} \frac {d X_{t}}{d {\sf q}} + \frac {\partial \psi}{\partial w} 
 W_{t+1}.\]</div>
<p>Evaluating terms at <span class="math notranslate nohighlight">\({\sf q} = 0\)</span>, gives</p>
<div class="math notranslate nohighlight">
\[X_{t+1}^1 = \psi_x X_{t+1}^1 + \psi_w W_{t+1}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\psi_x  = \frac {\partial \psi}{\partial x} \left( {\overline x},0 \right)\]</div>
<p>and similarly for <span class="math notranslate nohighlight">\(\psi_w\)</span>. Since <span class="math notranslate nohighlight">\(\psi_x\)</span> is a stable matrix, the first-order approximation is a stationary vector autoregression.</p>
</section>
<section id="order-two-approximation">
<h3><span class="section-number">2.12.3. </span>Order two approximation<a class="headerlink" href="#order-two-approximation" title="Link to this heading">#</a></h3>
<p>For applications including asset pricing, it is important to move to a higher than first-order approximation, for example, to capture effects of risk aversion. For a multivariate process <span class="math notranslate nohighlight">\(\{X_t\}\)</span>, extensive notation and bookkeeping is required for a second order approximation. To simplify the presentation and the associated notation, we consider the case of a single state variable and a single shock each time period. The argument for the case with a state vector and shock vector is conceptually similar, just notationally less pleasant. To deduce a recursive representation, first write</p>
<div class="math notranslate nohighlight">
\[\frac {d^2 X_{t+1}}{d {\sf q}^2} = \frac {\partial \psi}{\partial x} \frac {d^2 X_{t}}{d^2 {\sf q}} + 
\frac {\partial^2 \psi}{\partial x^2} \left(\frac {d X_{t}}{d {\sf q}}\right)^2 
+ 2 \frac {\partial^2 \psi}{\partial x \partial w}  \frac {d X_{t}}{d {\sf q}} W_{t+1}
+  \frac {\partial^2 \psi}{\partial w^2}  \left( W_{t+1} \right) ^2\]</div>
<p>Evaluating the derivatives at <span class="math notranslate nohighlight">\({\sf q} = 0\)</span> gives</p>
<div class="math notranslate nohighlight">
\[X_{t+1}^2 = \psi_x X_t^2 + \psi_{xx} \left( X_{t}^1 \right)^2 + 2 \psi_{xw} \left(X_{t}^1W_{t+1}\right)  + \psi_{ww} \left( W_{t+1}  \right)^2\]</div>
<p>where the subscripts on the <span class="math notranslate nohighlight">\(\psi\)</span>’s tell us which variables have been differentiated with respect to the derivatives evaluated at <span class="math notranslate nohighlight">\( \left( {\overline x},0 \right)\)</span>. Thus, the second-order approximation has a recursive representation that is quadratic in <span class="math notranslate nohighlight">\(\left( X_t^1, W_{t+1}\right)\)</span>. Since <span class="math notranslate nohighlight">\(\psi_x\)</span> is stable (in this scalar case <span class="math notranslate nohighlight">\(|\psi_x|&lt;1\)</span>), the second-order dynamics are stable and <span class="math notranslate nohighlight">\(\{X_t^2 : t \ge 0\}\)</span> has a stationary solution.</p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="singularity" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>When <span class="math notranslate nohighlight">\(B-i{B_i}'\)</span> is singular, a density may not exist with respect to Lebesgue measure. The covariance matrix <span class="math notranslate nohighlight">\(B_i{B_i}'\)</span> is typically singular for a first-order vector autoregression constructed by rewriting a higher-order vector autoregression.</p>
</aside>
<aside class="footnote brackets" id="bayesianmarkov" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Numerical Bayesian statistical analysis often computes a posterior probability distribution by iterating to convergence a reversible Markov process whose stationary distribution is that posterior distribution.</p>
</aside>
<aside class="footnote brackets" id="eigenfunctionnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>For Markov processes, all invariant events depend only on the initial <span class="math notranslate nohighlight">\(X\)</span>.  A reference  is <span id="id17">Doob [<a class="reference internal" href="cite.html#id124" title="J. L. Doob. Stochastic Processes. John Wiley and Sons, New York, 1953.">1953</a>]</span>, Theorem 1.1, page 460.  Indicator functions of these are events are thus representable as eigenfunctions associated with unit eigenvalues.</p>
</aside>
<aside class="footnote brackets" id="unknownparameters" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p>Unknown parameters manifest themselves as unknown statistical models.</p>
</aside>
<aside class="footnote brackets" id="ergo-footnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>In particular, the process can be represented using a probability measure <span class="math notranslate nohighlight">\(Pr\)</span> defined over events in <span class="math notranslate nohighlight">\({\mathfrak F}\)</span>, a transformation <span class="math notranslate nohighlight">\({\mathbb S}\)</span> for which<span class="math notranslate nohighlight">\(({\mathbb S}, Pr)\)</span> is measure preserving, and ergodic and a measurement function <span class="math notranslate nohighlight">\({\widetilde X}\)</span> such that <span class="math notranslate nohighlight">\(\left\{ {\widetilde X}\circ {\mathbb S}^t : t=0,1, \ldots \right\}\)</span> has the same induced distribution as the process <span class="math notranslate nohighlight">\(\{X_t : t=0,1,2, \ldots \}\)</span>.</p>
</aside>
<aside class="footnote brackets" id="eigen-footnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">6</a><span class="fn-bracket">]</span></span>
<p>This construction also works for unbounded functions <span class="math notranslate nohighlight">\(\phi\)</span> provided that <span class="math notranslate nohighlight">\(\phi \circ \tilde f\)</span> is square integrable under the <span class="math notranslate nohighlight">\(Q\)</span> measure.</p>
</aside>
<aside class="footnote brackets" id="periodicity-footnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">7</a><span class="fn-bracket">]</span></span>
<p>Our definition of periodicity is confined to a stationary distribution. Actually, periodicity can be defined more generally. We limit our treatment of periodicity to specifications of transition probabilities for which there exist stationary distributions for convenience here.</p>
</aside>
<aside class="footnote brackets" id="skip-sampling-footnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">8</a><span class="fn-bracket">]</span></span>
<p>See <span id="id18">Hansen and Sargent [<a class="reference internal" href="cite.html#id191" title="Lars Peter Hansen and Thomas J. Sargent. Seasonality and approximation errors in rational expectations models. Journal of Econometrics, 55(1-2):21-55, 1993. URL: http://ideas.repec.org/a/eee/econom/v55y1993i1-2p21-55.html.">1993</a>]</span> and <span id="id19">Hansen and Sargent [<a class="reference internal" href="cite.html#id208" title="Lars Peter Hansen and Thomas J. Sargent. Recursive Models of Dynamic Linear Economies. Princeton University Press, Princeton, New Jersey, 2013.">2013</a>]</span>.</p>
</aside>
<aside class="footnote brackets" id="geometricseries" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">9</a><span class="fn-bracket">]</span></span>
<p>The geometric series after the first equality sign is well defined under the weaker restriction that <span class="math notranslate nohighlight">\({\mathbb T}^m\)</span> is a strong contraction for some integer <span class="math notranslate nohighlight">\(m\geq 1\)</span>.</p>
</aside>
<aside class="footnote brackets" id="gelfand" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">10</a><span class="fn-bracket">]</span></span>
<p>This follows from Gelfand’s Theorem, which asserts the following. Let <span class="math notranslate nohighlight">\({\mathcal N}\)</span> be the <span class="math notranslate nohighlight">\(n-1\)</span> dimensional
space of vectors that are orthogonal to <span class="math notranslate nohighlight">\({\bf q}\)</span>. <span class="math notranslate nohighlight">\({\mathbb T}\)</span> maps <span class="math notranslate nohighlight">\({\mathcal N}\)</span> into itself.
The spectral radius of <span class="math notranslate nohighlight">\({\mathbb T}\)</span> restricted to <span class="math notranslate nohighlight">\({\mathcal N}\)</span> is the maximum of the
absolute values of the eigenvalues.
Gelfand’s Theorem asserts that the spectral radius governs the behavior as <span class="math notranslate nohighlight">\(m\)</span> gets large of the decay factor of the <span class="math notranslate nohighlight">\({\mathbb T}\)</span> transformation applied <span class="math notranslate nohighlight">\(m\)</span> times. Provided that the spectral radius is less than one,
the strong contraction property prevails for any <span class="math notranslate nohighlight">\(\rho &lt; 1\)</span> that is larger than the spectral radius.</p>
</aside>
<aside class="footnote brackets" id="convergence-footnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">11</a><span class="fn-bracket">]</span></span>
<p>Restriction <a class="reference internal" href="#equation-converge">(2.12)</a> is stronger than ergodicity. It rules out periodic processes, although we know that periodic processes can be ergodic.</p>
</aside>
<aside class="footnote brackets" id="covmatrix" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">12</a><span class="fn-bracket">]</span></span>
<p>To verify the asserted equality, notice that <span class="math notranslate nohighlight">\(\sum_{j=0}^\infty \mathbb{A}^j \mathbb{B}\mathbb{B}' \mathbb{A}^{j \prime} = \mathbb{A} ( \sum_{j=0}^\infty \mathbb{A}^j \mathbb{B}\mathbb{B}' \mathbb{A}^{j \prime} )\mathbb{A}' + \mathbb{B} \mathbb{B}'\)</span>. Similarly, for all <span class="math notranslate nohighlight">\(\mu_0 = E X_0\)</span></p>
</aside>
<aside class="footnote brackets" id="feller" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">13</a><span class="fn-bracket">]</span></span>
<p>The Feller property (condition <a class="reference internal" href="#fellercond"><span class="std std-ref">(ii)</span></a>) of <a class="reference internal" href="#cond-suffice"><span class="std std-ref">Conditions</span></a> can also be verified.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="example_out_c1_v2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Stochastic Processes and Laws of Large Numbers</p>
      </div>
    </a>
    <a class="right-next"
       href="example_out_c3_v2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Stationary Increments</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constituents">2.1. Constituents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationarity">2.2. Stationarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathcal-l-2-and-eigenfunctions">2.3. <span class="math notranslate nohighlight">\({\mathcal L}^2\)</span> and Eigenfunctions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ergodic-markov-processes">2.4. Ergodic Markov Processes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#invariant-events-for-a-markov-process">2.4.1. Invariant events for a Markov process</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#periodicity">2.5. Periodicity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#finite-state-markov-chains">2.6. Finite-State Markov Chains</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limited-dependence">2.7. Limited Dependence</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limits-of-multi-period-forecasts">2.8. Limits of Multi-Period Forecasts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-autoregressions">2.9. Vector Autoregressions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-vector-autoregressions">2.10. Estimating Vector Autoregressions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inventing-a-past-again">2.11. Inventing a Past Again</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-approximation-of-nonlinear-markov-processes">2.12. Local Approximation of Nonlinear Markov Processes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#order-zero-approximation">2.12.1. Order zero approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#order-one-approximation">2.12.2. Order one approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#order-two-approximation">2.12.3. Order two approximation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lars Peter Hansen
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>